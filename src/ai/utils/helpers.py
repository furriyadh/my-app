#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ› ï¸ Helpers - Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¹Ø§Ù…Ø©
=============================

Ù…Ø¬Ù…ÙˆØ¹Ø© Ø´Ø§Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù†Ø­Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…:
- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª
- Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
- ØªØ´ÙÙŠØ± ÙˆÙÙƒ ØªØ´ÙÙŠØ±
- ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- Ø¹Ù…Ù„ÙŠØ§Øª Ø±ÙŠØ§Ø¶ÙŠØ© ÙˆØ¥Ø­ØµØ§Ø¦ÙŠØ©
- Ø¯ÙˆØ§Ù„ Ø´Ø¨ÙƒØ© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© URLs

Ø§Ù„Ù…Ø·ÙˆØ±: Google Ads AI Platform Team
Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-07-07
Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 1.0.0
"""

import logging
import asyncio
import json
import re
import os
import hashlib
import base64
import uuid
import time
import math
import statistics
from typing import Dict, Any, List, Optional, Union, Tuple, Callable
from datetime import datetime, timedelta, timezone
from urllib.parse import urlparse, urljoin, quote, unquote
from pathlib import Path
import mimetypes
import gzip
import zipfile
import tarfile

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
try:
    from .logger import setup_logger
    logger = setup_logger(__name__)
except ImportError:
    logger = logging.getLogger(__name__)

# ==================== Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ====================

def clean_text(text: str, remove_extra_spaces: bool = True) -> str:
    """
    ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø£Ø­Ø±Ù ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø©
    
    Args:
        text: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙ†Ø¸ÙŠÙÙ‡
        remove_extra_spaces: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        
    Returns:
        str: Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙÙ†Ø¸Ù
    """
    if not isinstance(text, str):
        text = str(text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ©
    text = re.sub(r'[^\w\s\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF-]', '', text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    if remove_extra_spaces:
        text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def truncate_text(text: str, max_length: int, suffix: str = "...") -> str:
    """
    Ø§Ù‚ØªØ·Ø§Ø¹ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø·ÙˆÙ„ Ù…Ø­Ø¯Ø¯
    
    Args:
        text: Ø§Ù„Ù†Øµ
        max_length: Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰
        suffix: Ø§Ù„Ù„Ø§Ø­Ù‚Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù‚ØªØ·Ø§Ø¹
        
    Returns:
        str: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ·Ø¹
    """
    if len(text) <= max_length:
        return text
    
    return text[:max_length - len(suffix)] + suffix

def extract_numbers(text: str) -> List[float]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù…Ù† Ø§Ù„Ù†Øµ
    
    Args:
        text: Ø§Ù„Ù†Øµ
        
    Returns:
        List[float]: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
    """
    pattern = r'-?\d+\.?\d*'
    matches = re.findall(pattern, text)
    return [float(match) for match in matches if match]

def extract_emails(text: str) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù…Ù† Ø§Ù„Ù†Øµ
    
    Args:
        text: Ø§Ù„Ù†Øµ
        
    Returns:
        List[str]: Ù‚Ø§Ø¦Ù…Ø© Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
    """
    pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    return re.findall(pattern, text)

def extract_urls(text: str) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ù†Øµ
    
    Args:
        text: Ø§Ù„Ù†Øµ
        
    Returns:
        List[str]: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    """
    pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
    return re.findall(pattern, text)

def slugify(text: str, max_length: int = 50) -> str:
    """
    ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ slug ØµØ§Ù„Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ URLs
    
    Args:
        text: Ø§Ù„Ù†Øµ
        max_length: Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰
        
    Returns:
        str: Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ­ÙˆÙ„
    """
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø©
    text = text.lower()
    
    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØ§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø´Ø±Ø·Ø§Øª
    text = re.sub(r'[^\w\s-]', '', text)
    text = re.sub(r'[-\s]+', '-', text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø´Ø±Ø·Ø§Øª Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©
    text = text.strip('-')
    
    # Ø§Ù‚ØªØ·Ø§Ø¹ Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯
    return text[:max_length]

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª ====================

def now_utc() -> datetime:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¨ØªÙˆÙ‚ÙŠØª UTC"""
    return datetime.now(timezone.utc)

def format_datetime(dt: datetime, format_str: str = "%Y-%m-%d %H:%M:%S") -> str:
    """
    ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª
    
    Args:
        dt: Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª
        format_str: Ù†Ù…Ø· Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
        
    Returns:
        str: Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ÙÙ†Ø³Ù‚
    """
    return dt.strftime(format_str)

def parse_datetime(date_str: str, format_str: str = "%Y-%m-%d %H:%M:%S") -> Optional[datetime]:
    """
    ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª
    
    Args:
        date_str: Ù†Øµ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª
        format_str: Ù†Ù…Ø· Ø§Ù„ØªØ­Ù„ÙŠÙ„
        
    Returns:
        Optional[datetime]: Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ÙØ­Ù„Ù„ Ø£Ùˆ None
    """
    try:
        return datetime.strptime(date_str, format_str)
    except ValueError:
        return None

def time_ago(dt: datetime) -> str:
    """
    Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠ Ù…Ù†Ø° ØªØ§Ø±ÙŠØ® Ù…Ø¹ÙŠÙ†
    
    Args:
        dt: Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª
        
    Returns:
        str: Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠ Ø¨ØµÙŠØºØ© Ù†ØµÙŠØ©
    """
    now = datetime.now(dt.tzinfo) if dt.tzinfo else datetime.now()
    diff = now - dt
    
    seconds = diff.total_seconds()
    
    if seconds < 60:
        return f"{int(seconds)} Ø«Ø§Ù†ÙŠØ©"
    elif seconds < 3600:
        return f"{int(seconds // 60)} Ø¯Ù‚ÙŠÙ‚Ø©"
    elif seconds < 86400:
        return f"{int(seconds // 3600)} Ø³Ø§Ø¹Ø©"
    elif seconds < 2592000:  # 30 days
        return f"{int(seconds // 86400)} ÙŠÙˆÙ…"
    elif seconds < 31536000:  # 365 days
        return f"{int(seconds // 2592000)} Ø´Ù‡Ø±"
    else:
        return f"{int(seconds // 31536000)} Ø³Ù†Ø©"

def get_date_range(
    start_date: Optional[datetime] = None,
    end_date: Optional[datetime] = None,
    days: int = 30
) -> Tuple[datetime, datetime]:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ ØªØ§Ø±ÙŠØ®
    
    Args:
        start_date: ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
        end_date: ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
        days: Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… (Ø¥Ø°Ø§ Ù„Ù… ØªÙØ­Ø¯Ø¯ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®)
        
    Returns:
        Tuple[datetime, datetime]: ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©
    """
    if end_date is None:
        end_date = now_utc()
    
    if start_date is None:
        start_date = end_date - timedelta(days=days)
    
    return start_date, end_date

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ====================

def ensure_dir(path: Union[str, Path]) -> Path:
    """
    Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙˆØ¥Ù†Ø´Ø§Ø¤Ù‡ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    
    Args:
        path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¬Ù„Ø¯
        
    Returns:
        Path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¬Ù„Ø¯
    """
    path = Path(path)
    path.mkdir(parents=True, exist_ok=True)
    return path

def get_file_size(file_path: Union[str, Path]) -> int:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ù„Ø¨Ø§ÙŠØª
    
    Args:
        file_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù
        
    Returns:
        int: Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ù„Ø¨Ø§ÙŠØª
    """
    return Path(file_path).stat().st_size

def format_file_size(size_bytes: int) -> str:
    """
    ØªÙ†Ø³ÙŠÙ‚ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø¨ÙˆØ­Ø¯Ø© Ù…Ù†Ø§Ø³Ø¨Ø©
    
    Args:
        size_bytes: Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ù„Ø¨Ø§ÙŠØª
        
    Returns:
        str: Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙÙ†Ø³Ù‚
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = int(math.floor(math.log(size_bytes, 1024)))
    p = math.pow(1024, i)
    s = round(size_bytes / p, 2)
    
    return f"{s} {size_names[i]}"

def get_file_extension(file_path: Union[str, Path]) -> str:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„Ù…Ù„Ù
    
    Args:
        file_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù
        
    Returns:
        str: Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„Ù…Ù„Ù
    """
    return Path(file_path).suffix.lower()

def get_mime_type(file_path: Union[str, Path]) -> str:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ MIME Ù„Ù„Ù…Ù„Ù
    
    Args:
        file_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù
        
    Returns:
        str: Ù†ÙˆØ¹ MIME
    """
    mime_type, _ = mimetypes.guess_type(str(file_path))
    return mime_type or 'application/octet-stream'

def compress_file(input_path: Union[str, Path], output_path: Union[str, Path]) -> bool:
    """
    Ø¶ØºØ· Ù…Ù„Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… gzip
    
    Args:
        input_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ø®Ù„
        output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ·
        
    Returns:
        bool: Ù†Ø¬Ø­ Ø§Ù„Ø¶ØºØ· Ø£Ù… Ù„Ø§
    """
    try:
        with open(input_path, 'rb') as f_in:
            with gzip.open(output_path, 'wb') as f_out:
                f_out.writelines(f_in)
        return True
    except Exception as e:
        logger.error(f"ÙØ´Ù„ ÙÙŠ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù: {e}")
        return False

def decompress_file(input_path: Union[str, Path], output_path: Union[str, Path]) -> bool:
    """
    ÙÙƒ Ø¶ØºØ· Ù…Ù„Ù gzip
    
    Args:
        input_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ·
        output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙÙƒÙˆÙƒ
        
    Returns:
        bool: Ù†Ø¬Ø­ ÙÙƒ Ø§Ù„Ø¶ØºØ· Ø£Ù… Ù„Ø§
    """
    try:
        with gzip.open(input_path, 'rb') as f_in:
            with open(output_path, 'wb') as f_out:
                f_out.writelines(f_in)
        return True
    except Exception as e:
        logger.error(f"ÙØ´Ù„ ÙÙŠ ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù: {e}")
        return False

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ´ÙÙŠØ± ÙˆØ§Ù„Ø£Ù…Ø§Ù† ====================

def generate_uuid() -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ UUID ÙØ±ÙŠØ¯"""
    return str(uuid.uuid4())

def generate_random_string(length: int = 32, include_symbols: bool = False) -> str:
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ù†Øµ Ø¹Ø´ÙˆØ§Ø¦ÙŠ
    
    Args:
        length: Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ
        include_symbols: ØªØ¶Ù…ÙŠÙ† Ø±Ù…ÙˆØ² Ø®Ø§ØµØ©
        
    Returns:
        str: Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠ
    """
    import random
    import string
    
    chars = string.ascii_letters + string.digits
    if include_symbols:
        chars += "!@#$%^&*"
    
    return ''.join(random.choice(chars) for _ in range(length))

def hash_string(text: str, algorithm: str = 'sha256') -> str:
    """
    ØªØ´ÙÙŠØ± Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… hash
    
    Args:
        text: Ø§Ù„Ù†Øµ
        algorithm: Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªØ´ÙÙŠØ±
        
    Returns:
        str: Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ´ÙØ±
    """
    hash_obj = hashlib.new(algorithm)
    hash_obj.update(text.encode('utf-8'))
    return hash_obj.hexdigest()

def encode_base64(data: Union[str, bytes]) -> str:
    """
    ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Base64
    
    Args:
        data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        
    Returns:
        str: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙØ´ÙØ±Ø©
    """
    if isinstance(data, str):
        data = data.encode('utf-8')
    
    return base64.b64encode(data).decode('utf-8')

def decode_base64(encoded_data: str) -> bytes:
    """
    ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Base64
    
    Args:
        encoded_data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙØ´ÙØ±Ø©
        
    Returns:
        bytes: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙÙƒÙˆÙƒØ©
    """
    return base64.b64decode(encoded_data)

def mask_sensitive_data(data: str, mask_char: str = "*", visible_chars: int = 4) -> str:
    """
    Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©
    
    Args:
        data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        mask_char: Ø­Ø±Ù Ø§Ù„Ø¥Ø®ÙØ§Ø¡
        visible_chars: Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù…Ø±Ø¦ÙŠØ© Ù…Ù† Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
        
    Returns:
        str: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙØ®ÙØ§Ø©
    """
    if len(data) <= visible_chars:
        return mask_char * len(data)
    
    return mask_char * (len(data) - visible_chars) + data[-visible_chars:]

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ====================

def is_valid_email(email: str) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
    
    Args:
        email: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
        
    Returns:
        bool: ØµØ­ÙŠØ­ Ø£Ù… Ù„Ø§
    """
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, email))

def is_valid_url(url: str) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø±Ø§Ø¨Ø·
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø·
        
    Returns:
        bool: ØµØ­ÙŠØ­ Ø£Ù… Ù„Ø§
    """
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

def is_valid_phone(phone: str, country_code: str = "SA") -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ
    
    Args:
        phone: Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ
        country_code: Ø±Ù…Ø² Ø§Ù„Ø¯ÙˆÙ„Ø©
        
    Returns:
        bool: ØµØ­ÙŠØ­ Ø£Ù… Ù„Ø§
    """
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ù‚Ù…
    phone = re.sub(r'[^\d+]', '', phone)
    
    # Ø£Ù†Ù…Ø§Ø· Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡Ø§ØªÙ Ø­Ø³Ø¨ Ø§Ù„Ø¯ÙˆÙ„Ø©
    patterns = {
        "SA": r'^(\+966|966|0)?[5][0-9]{8}$',  # Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©
        "US": r'^(\+1|1)?[2-9]\d{2}[2-9]\d{2}\d{4}$',  # Ø£Ù…Ø±ÙŠÙƒØ§
        "UK": r'^(\+44|44|0)?[1-9]\d{8,9}$'  # Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ§
    }
    
    pattern = patterns.get(country_code, r'^\+?[1-9]\d{1,14}$')
    return bool(re.match(pattern, phone))

def validate_json(json_str: str) -> Tuple[bool, Optional[Dict]]:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© JSON
    
    Args:
        json_str: Ù†Øµ JSON
        
    Returns:
        Tuple[bool, Optional[Dict]]: ØµØ­ÙŠØ­ Ø£Ù… Ù„Ø§ØŒ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙØ­Ù„Ù„Ø©
    """
    try:
        data = json.loads(json_str)
        return True, data
    except json.JSONDecodeError:
        return False, None

def sanitize_input(input_str: str, max_length: int = 1000) -> str:
    """
    ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù…Ù† Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø¶Ø§Ø±Ø©
    
    Args:
        input_str: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„
        max_length: Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰
        
    Returns:
        str: Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙÙ†Ø¸Ù
    """
    # Ø¥Ø²Ø§Ù„Ø© HTML tags
    input_str = re.sub(r'<[^>]+>', '', input_str)
    
    # Ø¥Ø²Ø§Ù„Ø© JavaScript
    input_str = re.sub(r'<script.*?</script>', '', input_str, flags=re.DOTALL | re.IGNORECASE)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø·ÙŠØ±Ø©
    dangerous_chars = ['<', '>', '"', "'", '&', ';']
    for char in dangerous_chars:
        input_str = input_str.replace(char, '')
    
    # Ø§Ù‚ØªØ·Ø§Ø¹ Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯
    return input_str[:max_length]

# ==================== Ø¯ÙˆØ§Ù„ Ø±ÙŠØ§Ø¶ÙŠØ© ÙˆØ¥Ø­ØµØ§Ø¦ÙŠØ© ====================

def safe_divide(a: float, b: float, default: float = 0.0) -> float:
    """
    Ù‚Ø³Ù…Ø© Ø¢Ù…Ù†Ø© ØªØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
    
    Args:
        a: Ø§Ù„Ø¨Ø³Ø·
        b: Ø§Ù„Ù…Ù‚Ø§Ù…
        default: Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
        
    Returns:
        float: Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù‚Ø³Ù…Ø©
    """
    return a / b if b != 0 else default

def percentage(part: float, total: float) -> float:
    """
    Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©
    
    Args:
        part: Ø§Ù„Ø¬Ø²Ø¡
        total: Ø§Ù„ÙƒÙ„
        
    Returns:
        float: Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©
    """
    return safe_divide(part * 100, total)

def round_to_precision(number: float, precision: int = 2) -> float:
    """
    ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„Ø±Ù‚Ù… Ø¥Ù„Ù‰ Ø¯Ù‚Ø© Ù…Ø­Ø¯Ø¯Ø©
    
    Args:
        number: Ø§Ù„Ø±Ù‚Ù…
        precision: Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø´Ø±ÙŠØ©
        
    Returns:
        float: Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù…ÙÙ‚Ø±Ø¨
    """
    return round(number, precision)

def calculate_statistics(numbers: List[float]) -> Dict[str, float]:
    """
    Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø±Ù‚Ø§Ù…
    
    Args:
        numbers: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        
    Returns:
        Dict[str, float]: Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    """
    if not numbers:
        return {}
    
    return {
        'count': len(numbers),
        'sum': sum(numbers),
        'mean': statistics.mean(numbers),
        'median': statistics.median(numbers),
        'mode': statistics.mode(numbers) if len(set(numbers)) < len(numbers) else None,
        'min': min(numbers),
        'max': max(numbers),
        'range': max(numbers) - min(numbers),
        'std_dev': statistics.stdev(numbers) if len(numbers) > 1 else 0,
        'variance': statistics.variance(numbers) if len(numbers) > 1 else 0
    }

def normalize_list(numbers: List[float], min_val: float = 0, max_val: float = 1) -> List[float]:
    """
    ØªØ·Ø¨ÙŠØ¹ Ù‚Ø§Ø¦Ù…Ø© Ø£Ø±Ù‚Ø§Ù… Ø¥Ù„Ù‰ Ù†Ø·Ø§Ù‚ Ù…Ø­Ø¯Ø¯
    
    Args:
        numbers: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        min_val: Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¯Ù†ÙŠØ§
        max_val: Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹Ù„ÙŠØ§
        
    Returns:
        List[float]: Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙØ·Ø¨Ø¹Ø©
    """
    if not numbers:
        return []
    
    min_num = min(numbers)
    max_num = max(numbers)
    
    if min_num == max_num:
        return [min_val] * len(numbers)
    
    range_num = max_num - min_num
    range_target = max_val - min_val
    
    return [
        min_val + (num - min_num) * range_target / range_num
        for num in numbers
    ]

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„Ø´Ø¨ÙƒØ© ÙˆØ§Ù„Ù€ URLs ====================

def build_url(base_url: str, path: str = "", params: Optional[Dict[str, Any]] = None) -> str:
    """
    Ø¨Ù†Ø§Ø¡ Ø±Ø§Ø¨Ø· ÙƒØ§Ù…Ù„
    
    Args:
        base_url: Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        path: Ø§Ù„Ù…Ø³Ø§Ø±
        params: Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
        
    Returns:
        str: Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„ÙƒØ§Ù…Ù„
    """
    url = urljoin(base_url, path)
    
    if params:
        query_string = "&".join([f"{k}={quote(str(v))}" for k, v in params.items()])
        url += f"?{query_string}"
    
    return url

def parse_url(url: str) -> Dict[str, Any]:
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø· Ø¥Ù„Ù‰ Ù…ÙƒÙˆÙ†Ø§ØªÙ‡
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø·
        
    Returns:
        Dict[str, Any]: Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø±Ø§Ø¨Ø·
    """
    parsed = urlparse(url)
    
    return {
        'scheme': parsed.scheme,
        'netloc': parsed.netloc,
        'hostname': parsed.hostname,
        'port': parsed.port,
        'path': parsed.path,
        'params': parsed.params,
        'query': parsed.query,
        'fragment': parsed.fragment,
        'username': parsed.username,
        'password': parsed.password
    }

def extract_domain(url: str) -> str:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ø·Ø§Ù‚ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø·
        
    Returns:
        str: Ø§Ù„Ù†Ø·Ø§Ù‚
    """
    parsed = urlparse(url)
    return parsed.netloc

async def check_url_status(url: str, timeout: int = 10) -> Tuple[bool, int]:
    """
    ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø±Ø§Ø¨Ø·
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø·
        timeout: Ù…Ù‡Ù„Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±
        
    Returns:
        Tuple[bool, int]: Ù…ØªØ§Ø­ Ø£Ù… Ù„Ø§ØŒ Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©
    """
    if not REQUESTS_AVAILABLE:
        logger.warning("Ù…ÙƒØªØ¨Ø© requests ØºÙŠØ± Ù…ØªØ§Ø­Ø©")
        return False, 0
    
    try:
        response = requests.head(url, timeout=timeout, allow_redirects=True)
        return response.status_code < 400, response.status_code
    except Exception as e:
        logger.warning(f"ÙØ´Ù„ ÙÙŠ ÙØ­Øµ Ø§Ù„Ø±Ø§Ø¨Ø· {url}: {e}")
        return False, 0

# ==================== Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ====================

def flatten_dict(d: Dict[str, Any], parent_key: str = '', sep: str = '.') -> Dict[str, Any]:
    """
    ØªØ³Ø·ÙŠØ­ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…ØªØ¯Ø§Ø®Ù„
    
    Args:
        d: Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
        parent_key: Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø£Ø¨
        sep: ÙØ§ØµÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
        
    Returns:
        Dict[str, Any]: Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…ÙØ³Ø·Ø­
    """
    items = []
    
    for k, v in d.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        
        if isinstance(v, dict):
            items.extend(flatten_dict(v, new_key, sep=sep).items())
        else:
            items.append((new_key, v))
    
    return dict(items)

def unflatten_dict(d: Dict[str, Any], sep: str = '.') -> Dict[str, Any]:
    """
    Ø¥Ù„ØºØ§Ø¡ ØªØ³Ø·ÙŠØ­ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
    
    Args:
        d: Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…ÙØ³Ø·Ø­
        sep: ÙØ§ØµÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
        
    Returns:
        Dict[str, Any]: Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…ØªØ¯Ø§Ø®Ù„
    """
    result = {}
    
    for key, value in d.items():
        keys = key.split(sep)
        current = result
        
        for k in keys[:-1]:
            if k not in current:
                current[k] = {}
            current = current[k]
        
        current[keys[-1]] = value
    
    return result

def merge_dicts(*dicts: Dict[str, Any]) -> Dict[str, Any]:
    """
    Ø¯Ù…Ø¬ Ø¹Ø¯Ø© Ù‚ÙˆØ§Ù…ÙŠØ³
    
    Args:
        *dicts: Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³
        
    Returns:
        Dict[str, Any]: Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬
    """
    result = {}
    
    for d in dicts:
        if isinstance(d, dict):
            result.update(d)
    
    return result

def filter_dict(d: Dict[str, Any], keys: List[str], include: bool = True) -> Dict[str, Any]:
    """
    ØªØµÙÙŠØ© Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø­Ø³Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
    
    Args:
        d: Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
        keys: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙØ§ØªÙŠØ­
        include: ØªØ¶Ù…ÙŠÙ† Ø£Ù… Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
        
    Returns:
        Dict[str, Any]: Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…ÙØµÙÙ‰
    """
    if include:
        return {k: v for k, v in d.items() if k in keys}
    else:
        return {k: v for k, v in d.items() if k not in keys}

def chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:
    """
    ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡
    
    Args:
        lst: Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
        chunk_size: Ø­Ø¬Ù… Ø§Ù„Ø¬Ø²Ø¡
        
    Returns:
        List[List[Any]]: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
    """
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def remove_duplicates(lst: List[Any], key: Optional[Callable] = None) -> List[Any]:
    """
    Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
    
    Args:
        lst: Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
        key: Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙØªØ§Ø­ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        
    Returns:
        List[Any]: Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø±Ø§Øª
    """
    if key is None:
        return list(dict.fromkeys(lst))
    
    seen = set()
    result = []
    
    for item in lst:
        item_key = key(item)
        if item_key not in seen:
            seen.add(item_key)
            result.append(item)
    
    return result

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ====================

class Timer:
    """Ù…Ø¤Ù‚Øª Ù„Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    
    def __init__(self):
        self.start_time = None
        self.end_time = None
    
    def start(self):
        """Ø¨Ø¯Ø¡ Ø§Ù„ØªÙˆÙ‚ÙŠØª"""
        self.start_time = time.time()
        return self
    
    def stop(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªÙˆÙ‚ÙŠØª"""
        self.end_time = time.time()
        return self
    
    @property
    def elapsed(self) -> float:
        """Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ù†Ù‚Ø¶ÙŠ Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ"""
        if self.start_time is None:
            return 0
        
        end = self.end_time or time.time()
        return end - self.start_time
    
    def __enter__(self):
        return self.start()
    
    def __exit__(self, *args):
        self.stop()

def measure_time(func: Callable) -> Callable:
    """
    Decorator Ù„Ù‚ÙŠØ§Ø³ ÙˆÙ‚Øª ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ù„Ø©
    
    Args:
        func: Ø§Ù„Ø¯Ø§Ù„Ø©
        
    Returns:
        Callable: Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ø¹ Ù‚ÙŠØ§Ø³ Ø§Ù„ÙˆÙ‚Øª
    """
    async def async_wrapper(*args, **kwargs):
        with Timer() as timer:
            result = await func(*args, **kwargs)
        
        logger.debug(f"â±ï¸ {func.__name__} Ø§Ø³ØªØºØ±Ù‚ {timer.elapsed:.3f}s")
        return result
    
    def sync_wrapper(*args, **kwargs):
        with Timer() as timer:
            result = func(*args, **kwargs)
        
        logger.debug(f"â±ï¸ {func.__name__} Ø§Ø³ØªØºØ±Ù‚ {timer.elapsed:.3f}s")
        return result
    
    if asyncio.iscoroutinefunction(func):
        return async_wrapper
    else:
        return sync_wrapper

def memory_usage() -> Dict[str, float]:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    
    Returns:
        Dict[str, float]: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    """
    try:
        import psutil
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,  # Resident Set Size
            'vms_mb': memory_info.vms / 1024 / 1024,  # Virtual Memory Size
            'percent': process.memory_percent()
        }
    except ImportError:
        return {'error': 'psutil not available'}

# ==================== Ø¯ÙˆØ§Ù„ Ù…ØªÙ†ÙˆØ¹Ø© ====================

def retry_async(max_attempts: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """
    Decorator Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ù„Ø¯ÙˆØ§Ù„ ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
    
    Args:
        max_attempts: Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø£Ù‚ØµÙ‰
        delay: Ø§Ù„ØªØ£Ø®ÙŠØ± Ø§Ù„Ø£ÙˆÙ„ÙŠ
        backoff: Ù…Ø¹Ø§Ù…Ù„ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ£Ø®ÙŠØ±
    """
    def decorator(func):
        async def wrapper(*args, **kwargs):
            last_exception = None
            current_delay = delay
            
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    
                    if attempt < max_attempts - 1:
                        logger.warning(f"Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1} ÙØ´Ù„ØªØŒ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø®Ù„Ø§Ù„ {current_delay}s: {e}")
                        await asyncio.sleep(current_delay)
                        current_delay *= backoff
            
            raise last_exception
        
        return wrapper
    return decorator

def get_system_info() -> Dict[str, Any]:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    
    Returns:
        Dict[str, Any]: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    """
    import platform
    
    info = {
        'platform': platform.platform(),
        'system': platform.system(),
        'release': platform.release(),
        'version': platform.version(),
        'machine': platform.machine(),
        'processor': platform.processor(),
        'python_version': platform.python_version(),
        'hostname': platform.node()
    }
    
    # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªØ§Ø­Ø©
    memory_info = memory_usage()
    if 'error' not in memory_info:
        info['memory'] = memory_info
    
    return info

# ØªØµØ¯ÙŠØ± Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
__all__ = [
    # Ø¯ÙˆØ§Ù„ Ø§Ù„Ù†ØµÙˆØµ
    'clean_text', 'truncate_text', 'extract_numbers', 'extract_emails', 
    'extract_urls', 'slugify',
    
    # Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª
    'now_utc', 'format_datetime', 'parse_datetime', 'time_ago', 'get_date_range',
    
    # Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª
    'ensure_dir', 'get_file_size', 'format_file_size', 'get_file_extension',
    'get_mime_type', 'compress_file', 'decompress_file',
    
    # Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ´ÙÙŠØ±
    'generate_uuid', 'generate_random_string', 'hash_string', 'encode_base64',
    'decode_base64', 'mask_sensitive_data',
    
    # Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ­Ù‚Ù‚
    'is_valid_email', 'is_valid_url', 'is_valid_phone', 'validate_json',
    'sanitize_input',
    
    # Ø¯ÙˆØ§Ù„ Ø±ÙŠØ§Ø¶ÙŠØ©
    'safe_divide', 'percentage', 'round_to_precision', 'calculate_statistics',
    'normalize_list',
    
    # Ø¯ÙˆØ§Ù„ Ø§Ù„Ø´Ø¨ÙƒØ©
    'build_url', 'parse_url', 'extract_domain', 'check_url_status',
    
    # Ø¯ÙˆØ§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    'flatten_dict', 'unflatten_dict', 'merge_dicts', 'filter_dict',
    'chunk_list', 'remove_duplicates',
    
    # Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡
    'Timer', 'measure_time', 'memory_usage', 'retry_async', 'get_system_info'
]

