"""
Google Ads Campaigns Management
Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø­Ù…Ù„Ø§Øª Google Ads Ø§Ù„Ù…ØªØ·ÙˆØ± ÙˆØ§Ù„Ø°ÙƒÙŠ

ÙŠÙˆÙØ± ÙˆØ¸Ø§Ø¦Ù Ø¥Ø¯Ø§Ø±Ø© Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ØªØ·ÙˆØ±Ø© Ù„Ø­Ù…Ù„Ø§Øª Google Ads Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ:
- Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ­Ø±ÙŠØ± Ø§Ù„Ø­Ù…Ù„Ø§Øª Ø¨Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ©
- Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø¹Ø±ÙˆØ¶ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ
- Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø³ØªÙ…Ø± Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
- ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©

Author: Google Ads AI Platform Team
Version: 2.1.0
Security Level: Enterprise
Performance: AI-Optimized Campaign Management
"""

import os
import asyncio
import aiohttp
import json
import time
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any, Tuple, Union, Set, Callable
from dataclasses import dataclass, field, asdict
from enum import Enum, auto
from functools import wraps, lru_cache
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from collections import defaultdict, Counter
import hashlib
import uuid
import math

# Flask imports
from flask import Blueprint, request, jsonify, current_app

# ==================== Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ø¢Ù…Ù†Ø© ====================

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ python-jose Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† PyJWT
try:
    from jose import jwt
    from jose.exceptions import JWTError, ExpiredSignatureError, JWTClaimsError
    JWT_AVAILABLE = True
    JWT_LIBRARY = 'python-jose'
except ImportError:
    JWT_AVAILABLE = False
    JWT_LIBRARY = 'ØºÙŠØ± Ù…ØªØ§Ø­'
    jwt = None
    JWTError = Exception
    ExpiredSignatureError = Exception
    JWTClaimsError = Exception

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ passlib Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† bcrypt
try:
    from passlib.hash import bcrypt as passlib_bcrypt
    from passlib.context import CryptContext
    BCRYPT_AVAILABLE = True
    BCRYPT_LIBRARY = 'passlib'
    # Ø¥Ù†Ø´Ø§Ø¡ context Ù„Ù„ØªØ´ÙÙŠØ±
    pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
except ImportError:
    BCRYPT_AVAILABLE = False
    BCRYPT_LIBRARY = 'ØºÙŠØ± Ù…ØªØ§Ø­'
    passlib_bcrypt = None
    pwd_context = None

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ pycryptodome Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† cryptography
try:
    from Crypto.Hash import SHA256, SHA512, HMAC
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    from Crypto.Protocol.KDF import PBKDF2
    from Crypto.Util.Padding import pad, unpad
    CRYPTO_AVAILABLE = True
    CRYPTO_LIBRARY = 'pycryptodome'
except ImportError:
    CRYPTO_AVAILABLE = False
    CRYPTO_LIBRARY = 'ØºÙŠØ± Ù…ØªØ§Ø­'
    SHA256 = None
    SHA512 = None
    HMAC = None
    AES = None
    get_random_bytes = None
    PBKDF2 = None
    pad = None
    unpad = None

# Third-party imports
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor

# Local imports
import logging

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
logger = logging.getLogger(__name__)

# ØªØ³Ø¬ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
logger.info(f"ğŸ” JWT Library: {JWT_LIBRARY} ({'âœ…' if JWT_AVAILABLE else 'âŒ'})")
logger.info(f"ğŸ”’ Bcrypt Library: {BCRYPT_LIBRARY} ({'âœ…' if BCRYPT_AVAILABLE else 'âŒ'})")
logger.info(f"ğŸ”‘ Crypto Library: {CRYPTO_LIBRARY} ({'âœ…' if CRYPTO_AVAILABLE else 'âŒ'})")

# Ø¥Ù†Ø´Ø§Ø¡ Blueprint Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
google_ads_campaigns_bp = Blueprint(
    'google_ads_campaigns',
    __name__,
    url_prefix='/api/google-ads/campaigns',
    static_folder=None,
    template_folder=None
)

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
CAMPAIGNS_SERVICES_STATUS = {
    'google_ads_client': False,
    'oauth_manager': False,
    'database': False,
    'redis': False,
    'validators': False,
    'helpers': False,
    'ai_services': False,
    'optimization_engine': False
}

try:
    from services.google_ads_client import GoogleAdsClientManager
    CAMPAIGNS_SERVICES_STATUS['google_ads_client'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ GoogleAdsClientManager ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from backend.routes.google_ads.auth_jwt import oauth_manager
    CAMPAIGNS_SERVICES_STATUS['oauth_manager'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ OAuth Manager ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from utils.database import DatabaseManager
    CAMPAIGNS_SERVICES_STATUS['database'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ DatabaseManager ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from utils.redis_config import cache_set, cache_get, cache_delete
    CAMPAIGNS_SERVICES_STATUS['redis'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ Redis ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from utils.validators import validate_customer_id, validate_campaign_data
    CAMPAIGNS_SERVICES_STATUS['validators'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ Validators ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from utils.helpers import (
        generate_unique_id, sanitize_text, format_currency,
        calculate_performance_score, validate_budget_amount
    )
    CAMPAIGNS_SERVICES_STATUS['helpers'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ Helpers ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from services.ai_services import AIOptimizationService, BudgetOptimizer, BidOptimizer
    CAMPAIGNS_SERVICES_STATUS['ai_services'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ AI Services ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from services.optimization_engine import OptimizationEngine, PerformancePredictor
    CAMPAIGNS_SERVICES_STATUS['optimization_engine'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ Optimization Engine ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

# ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª
CAMPAIGNS_SERVICES_AVAILABLE = any(CAMPAIGNS_SERVICES_STATUS.values())
logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø®Ø¯Ù…Ø§Øª Campaigns - Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©: {sum(CAMPAIGNS_SERVICES_STATUS.values())}/8")

# Ø¥Ø¹Ø¯Ø§Ø¯ Thread Pool Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©
campaigns_executor = ThreadPoolExecutor(max_workers=25, thread_name_prefix="campaigns_worker")

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„ØªØ´ÙÙŠØ± ====================

class SecurityManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„ØªØ´ÙÙŠØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ø¢Ù…Ù†Ø©"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù†"""
        self.jwt_secret = os.getenv('JWT_SECRET_KEY', 'default_secret_key_change_in_production')
        self.encryption_key = self._derive_encryption_key()
        self.session_timeout = timedelta(hours=24)
        
    def _derive_encryption_key(self) -> bytes:
        """Ø§Ø´ØªÙ‚Ø§Ù‚ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ´ÙÙŠØ±"""
        if CRYPTO_AVAILABLE:
            try:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… PBKDF2 Ù…Ù† pycryptodome
                password = self.jwt_secret.encode('utf-8')
                salt = b'google_ads_campaigns_salt_2024'
                key = PBKDF2(password, salt, 32, count=100000, hmac_hash_module=SHA256)
                return key
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø´ØªÙ‚Ø§Ù‚ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ´ÙÙŠØ±: {e}")
        
        # fallback Ø¥Ù„Ù‰ hashlib
        import hashlib
        return hashlib.sha256(self.jwt_secret.encode('utf-8')).digest()
    
    def create_jwt_token(self, payload: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ JWT token Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… python-jose"""
        if not JWT_AVAILABLE:
            logger.warning("JWT ØºÙŠØ± Ù…ØªØ§Ø­ - Ø§Ø³ØªØ®Ø¯Ø§Ù… fallback")
            return self._create_fallback_token(payload)
        
        try:
            if expires_delta:
                expire = datetime.utcnow() + expires_delta
            else:
                expire = datetime.utcnow() + self.session_timeout
            
            payload.update({
                'exp': expire,
                'iat': datetime.utcnow(),
                'jti': str(uuid.uuid4())
            })
            
            token = jwt.encode(payload, self.jwt_secret, algorithm='HS256')
            return token if isinstance(token, str) else token.decode('utf-8')
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ JWT token: {e}")
            return self._create_fallback_token(payload)
    
    def verify_jwt_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT token Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… python-jose"""
        if not JWT_AVAILABLE:
            return self._verify_fallback_token(token)
        
        try:
            payload = jwt.decode(token, self.jwt_secret, algorithms=['HS256'])
            return payload
        except ExpiredSignatureError:
            logger.warning("JWT token Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©")
            return None
        except JWTError as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT token: {e}")
            return None
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT token: {e}")
            return None
    
    def _create_fallback_token(self, payload: Dict[str, Any]) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ token Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
        import base64
        import json
        
        try:
            payload_str = json.dumps(payload, default=str)
            encoded_payload = base64.b64encode(payload_str.encode('utf-8')).decode('utf-8')
            return f"fallback_{encoded_payload}_{uuid.uuid4().hex}"
        except Exception:
            return f"emergency_token_{uuid.uuid4().hex}"
    
    def _verify_fallback_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† token Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
        try:
            if token.startswith('fallback_'):
                parts = token.split('_', 2)
                if len(parts) >= 2:
                    import base64
                    import json
                    payload_str = base64.b64decode(parts[1]).decode('utf-8')
                    return json.loads(payload_str)
            return None
        except Exception:
            return None
    
    def hash_password(self, password: str) -> str:
        """ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… passlib"""
        if BCRYPT_AVAILABLE and pwd_context:
            try:
                return pwd_context.hash(password)
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¨Ù€ passlib: {e}")
        
        # fallback Ø¥Ù„Ù‰ hashlib Ù…Ø¹ salt
        import hashlib
        import secrets
        salt = secrets.token_hex(16)
        password_hash = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt.encode('utf-8'), 100000)
        return f"pbkdf2_sha256${salt}${password_hash.hex()}"
    
    def verify_password(self, password: str, hashed: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… passlib"""
        if BCRYPT_AVAILABLE and pwd_context:
            try:
                return pwd_context.verify(password, hashed)
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¨Ù€ passlib: {e}")
        
        # fallback verification
        try:
            if hashed.startswith('pbkdf2_sha256$'):
                parts = hashed.split('$')
                if len(parts) == 3:
                    salt = parts[1]
                    stored_hash = parts[2]
                    import hashlib
                    password_hash = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt.encode('utf-8'), 100000)
                    return password_hash.hex() == stored_hash
        except Exception:
            pass
        return False
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pycryptodome"""
        if not CRYPTO_AVAILABLE:
            logger.warning("Crypto ØºÙŠØ± Ù…ØªØ§Ø­ - Ø§Ø³ØªØ®Ø¯Ø§Ù… base64 encoding")
            import base64
            return base64.b64encode(data.encode('utf-8')).decode('utf-8')
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ IV Ø¹Ø´ÙˆØ§Ø¦ÙŠ
            iv = get_random_bytes(16)
            
            # Ø¥Ù†Ø´Ø§Ø¡ cipher
            cipher = AES.new(self.encryption_key, AES.MODE_CBC, iv)
            
            # ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ padding
            padded_data = pad(data.encode('utf-8'), AES.block_size)
            encrypted_data = cipher.encrypt(padded_data)
            
            # Ø¯Ù…Ø¬ IV Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø©
            result = iv + encrypted_data
            
            import base64
            return base64.b64encode(result).decode('utf-8')
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            # fallback
            import base64
            return base64.b64encode(data.encode('utf-8')).decode('utf-8')
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pycryptodome"""
        if not CRYPTO_AVAILABLE:
            logger.warning("Crypto ØºÙŠØ± Ù…ØªØ§Ø­ - Ø§Ø³ØªØ®Ø¯Ø§Ù… base64 decoding")
            try:
                import base64
                return base64.b64decode(encrypted_data.encode('utf-8')).decode('utf-8')
            except Exception:
                return encrypted_data
        
        try:
            import base64
            encrypted_bytes = base64.b64decode(encrypted_data.encode('utf-8'))
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ IV
            iv = encrypted_bytes[:16]
            encrypted = encrypted_bytes[16:]
            
            # Ø¥Ù†Ø´Ø§Ø¡ cipher
            cipher = AES.new(self.encryption_key, AES.MODE_CBC, iv)
            
            # ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± ÙˆØ¥Ø²Ø§Ù„Ø© padding
            decrypted_padded = cipher.decrypt(encrypted)
            decrypted_data = unpad(decrypted_padded, AES.block_size)
            
            return decrypted_data.decode('utf-8')
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            # fallback
            try:
                import base64
                return base64.b64decode(encrypted_data.encode('utf-8')).decode('utf-8')
            except Exception:
                return encrypted_data
    
    def create_secure_hash(self, data: str) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ hash Ø¢Ù…Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pycryptodome"""
        if CRYPTO_AVAILABLE:
            try:
                hash_obj = SHA256.new(data.encode('utf-8'))
                return hash_obj.hexdigest()
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ hash Ø¨Ù€ pycryptodome: {e}")
        
        # fallback Ø¥Ù„Ù‰ hashlib
        import hashlib
        return hashlib.sha256(data.encode('utf-8')).hexdigest()
    
    def create_hmac_signature(self, data: str, key: str) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ HMAC signature Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pycryptodome"""
        if CRYPTO_AVAILABLE:
            try:
                h = HMAC.new(key.encode('utf-8'), digestmod=SHA256)
                h.update(data.encode('utf-8'))
                return h.hexdigest()
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ HMAC Ø¨Ù€ pycryptodome: {e}")
        
        # fallback Ø¥Ù„Ù‰ hmac
        import hmac
        import hashlib
        return hmac.new(key.encode('utf-8'), data.encode('utf-8'), hashlib.sha256).hexdigest()

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù†
security_manager = SecurityManager()

# ==================== JWT Decorator ====================

def jwt_required_campaigns(f):
    """Decorator Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT token ÙÙŠ campaigns"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({
                'success': False,
                'error': 'Authorization header Ù…Ø·Ù„ÙˆØ¨',
                'error_code': 'MISSING_AUTH_HEADER'
            }), 401
        
        token = auth_header.split(' ')[1]
        token_data = security_manager.verify_jwt_token(token)
        
        if not token_data:
            return jsonify({
                'success': False,
                'error': 'Token ØºÙŠØ± ØµØ­ÙŠØ­ Ø£Ùˆ Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',
                'error_code': 'INVALID_TOKEN'
            }), 401
        
        # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ request
        request.current_user = token_data
        return f(*args, **kwargs)
    
    return decorated_function

class CampaignType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø­Ù…Ù„Ø§Øª"""
    SEARCH = "SEARCH"
    DISPLAY = "DISPLAY"
    SHOPPING = "SHOPPING"
    VIDEO = "VIDEO"
    APP = "APP"
    SMART = "SMART"
    PERFORMANCE_MAX = "PERFORMANCE_MAX"
    LOCAL = "LOCAL"

class CampaignStatus(Enum):
    """Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©"""
    ENABLED = "ENABLED"
    PAUSED = "PAUSED"
    REMOVED = "REMOVED"
    DRAFT = "DRAFT"

class BiddingStrategy(Enum):
    """Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø¹Ø±ÙˆØ¶"""
    MANUAL_CPC = "MANUAL_CPC"
    ENHANCED_CPC = "ENHANCED_CPC"
    TARGET_CPA = "TARGET_CPA"
    TARGET_ROAS = "TARGET_ROAS"
    MAXIMIZE_CLICKS = "MAXIMIZE_CLICKS"
    MAXIMIZE_CONVERSIONS = "MAXIMIZE_CONVERSIONS"
    MAXIMIZE_CONVERSION_VALUE = "MAXIMIZE_CONVERSION_VALUE"
    TARGET_IMPRESSION_SHARE = "TARGET_IMPRESSION_SHARE"

class BudgetType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©"""
    DAILY = "DAILY"
    CAMPAIGN_TOTAL = "CAMPAIGN_TOTAL"
    SHARED = "SHARED"

class OptimizationGoal(Enum):
    """Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ­Ø³ÙŠÙ†"""
    MAXIMIZE_CLICKS = "maximize_clicks"
    MAXIMIZE_CONVERSIONS = "maximize_conversions"
    MAXIMIZE_REVENUE = "maximize_revenue"
    MINIMIZE_COST = "minimize_cost"
    IMPROVE_QUALITY_SCORE = "improve_quality_score"
    INCREASE_IMPRESSION_SHARE = "increase_impression_share"

@dataclass
class CampaignConfig:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©"""
    name: str
    campaign_type: CampaignType
    status: CampaignStatus = CampaignStatus.ENABLED
    budget_amount: float = 100.0
    budget_type: BudgetType = BudgetType.DAILY
    bidding_strategy: BiddingStrategy = BiddingStrategy.ENHANCED_CPC
    target_locations: List[str] = field(default_factory=lambda: ["Saudi Arabia"])
    target_languages: List[str] = field(default_factory=lambda: ["ar", "en"])
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    ad_schedule: Optional[Dict[str, Any]] = None
    device_targeting: Optional[Dict[str, Any]] = None
    audience_targeting: Optional[Dict[str, Any]] = None
    negative_keywords: List[str] = field(default_factory=list)
    conversion_goals: List[str] = field(default_factory=list)
    enable_ai_optimization: bool = True
    optimization_goal: OptimizationGoal = OptimizationGoal.MAXIMIZE_CONVERSIONS

@dataclass
class CampaignPerformance:
    """Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©"""
    campaign_id: str
    impressions: int = 0
    clicks: int = 0
    cost: float = 0.0
    conversions: int = 0
    conversion_value: float = 0.0
    ctr: float = 0.0
    avg_cpc: float = 0.0
    cost_per_conversion: float = 0.0
    conversion_rate: float = 0.0
    roas: float = 0.0
    quality_score: float = 0.0
    impression_share: float = 0.0
    search_impression_share: float = 0.0
    date_range: str = "last_30_days"
    last_updated: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

@dataclass
class OptimizationRecommendation:
    """ØªÙˆØµÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ†"""
    recommendation_id: str
    campaign_id: str
    type: str
    title: str
    description: str
    impact_score: float
    effort_score: float
    priority: str
    estimated_impact: Dict[str, Any]
    implementation_steps: List[str]
    supporting_data: Dict[str, Any]
    auto_apply: bool = False
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

@dataclass
class BudgetRecommendation:
    """ØªÙˆØµÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©"""
    campaign_id: str
    current_budget: float
    recommended_budget: float
    reason: str
    expected_impact: Dict[str, Any]
    confidence_score: float
    implementation_date: Optional[datetime] = None

class TrendAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ù…ØªØ·ÙˆØ±"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª"""
        self.trend_cache = {}
        self.analysis_window = timedelta(days=30)
        
    async def analyze_trends(self, campaign_id: str, performance_data: CampaignPerformance) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            trends = {
                'overall_trend': 'stable',
                'performance_trends': {},
                'seasonal_patterns': {},
                'anomalies': [],
                'predictions': {}
            }
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…
            overall_trend = await self._analyze_overall_trend(campaign_id, performance_data)
            trends['overall_trend'] = overall_trend
            
            # ØªØ­Ù„ÙŠÙ„ Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙØ±Ø¯ÙŠØ©
            performance_trends = await self._analyze_performance_trends(campaign_id, performance_data)
            trends['performance_trends'] = performance_trends
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©
            seasonal_patterns = await self._analyze_seasonal_patterns(campaign_id)
            trends['seasonal_patterns'] = seasonal_patterns
            
            # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø´Ø°ÙˆØ°
            anomalies = await self._detect_anomalies(campaign_id, performance_data)
            trends['anomalies'] = anomalies
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
            predictions = await self._generate_predictions(campaign_id, performance_data)
            trends['predictions'] = predictions
            
            return trends
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª: {e}")
            return {'error': str(e)}
    
    async def _analyze_overall_trend(self, campaign_id: str, performance: CampaignPerformance) -> str:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…"""
        try:
            # Ù…Ø­Ø§ÙƒØ§Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ (ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ©)
            if performance.roas > 2.0 and performance.conversion_rate > 3.0:
                return 'improving'
            elif performance.roas < 1.0 or performance.conversion_rate < 1.0:
                return 'declining'
            else:
                return 'stable'
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…: {e}")
            return 'unknown'
    
    async def _analyze_performance_trends(self, campaign_id: str, performance: CampaignPerformance) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙØ±Ø¯ÙŠØ©"""
        try:
            trends = {}
            
            # Ø§ØªØ¬Ø§Ù‡ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø±
            trends['ctr_trend'] = {
                'direction': 'up' if performance.ctr > 2.0 else 'down' if performance.ctr < 1.0 else 'stable',
                'strength': 'strong' if abs(performance.ctr - 2.0) > 1.0 else 'moderate',
                'confidence': 0.85
            }
            
            # Ø§ØªØ¬Ø§Ù‡ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
            trends['conversion_rate_trend'] = {
                'direction': 'up' if performance.conversion_rate > 3.0 else 'down' if performance.conversion_rate < 1.0 else 'stable',
                'strength': 'strong' if abs(performance.conversion_rate - 3.0) > 2.0 else 'moderate',
                'confidence': 0.80
            }
            
            # Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªÙƒÙ„ÙØ©
            trends['cost_trend'] = {
                'direction': 'up' if performance.avg_cpc > 3.0 else 'down' if performance.avg_cpc < 1.0 else 'stable',
                'strength': 'strong' if abs(performance.avg_cpc - 2.0) > 1.0 else 'moderate',
                'confidence': 0.75
            }
            
            return trends
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³: {e}")
            return {}
    
    async def _analyze_seasonal_patterns(self, campaign_id: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©"""
        try:
            # Ù…Ø­Ø§ÙƒØ§Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©
            current_month = datetime.now().month
            
            patterns = {
                'monthly_patterns': {},
                'weekly_patterns': {},
                'daily_patterns': {},
                'holiday_effects': {}
            }
            
            # Ø£Ù†Ù…Ø§Ø· Ø´Ù‡Ø±ÙŠØ© (Ù…Ø­Ø§ÙƒØ§Ø©)
            if current_month in [11, 12, 1]:  # Ù…ÙˆØ³Ù… Ø§Ù„ØªØ³ÙˆÙ‚
                patterns['monthly_patterns'] = {
                    'season': 'high_shopping_season',
                    'expected_performance': 'above_average',
                    'recommendations': ['increase_budget', 'expand_targeting']
                }
            elif current_month in [6, 7, 8]:  # Ù…ÙˆØ³Ù… Ø§Ù„ØµÙŠÙ
                patterns['monthly_patterns'] = {
                    'season': 'summer_season',
                    'expected_performance': 'below_average',
                    'recommendations': ['adjust_targeting', 'focus_on_mobile']
                }
            else:
                patterns['monthly_patterns'] = {
                    'season': 'regular_season',
                    'expected_performance': 'average',
                    'recommendations': ['maintain_current_strategy']
                }
            
            return patterns
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©: {e}")
            return {}
    
    async def _detect_anomalies(self, campaign_id: str, performance: CampaignPerformance) -> List[Dict[str, Any]]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø´Ø°ÙˆØ° ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            anomalies = []
            
            # Ø´Ø°ÙˆØ° ÙÙŠ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø±
            if performance.ctr > 10.0:
                anomalies.append({
                    'type': 'high_ctr_anomaly',
                    'metric': 'ctr',
                    'value': performance.ctr,
                    'severity': 'high',
                    'description': 'Ù…Ø¹Ø¯Ù„ Ù†Ù‚Ø± Ù…Ø±ØªÙØ¹ Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ',
                    'possible_causes': ['click_fraud', 'viral_content', 'competitor_activity'],
                    'recommended_actions': ['investigate_traffic_quality', 'check_ad_content', 'monitor_competitors']
                })
            elif performance.ctr < 0.1:
                anomalies.append({
                    'type': 'low_ctr_anomaly',
                    'metric': 'ctr',
                    'value': performance.ctr,
                    'severity': 'medium',
                    'description': 'Ù…Ø¹Ø¯Ù„ Ù†Ù‚Ø± Ù…Ù†Ø®ÙØ¶ Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ',
                    'possible_causes': ['poor_ad_relevance', 'targeting_issues', 'ad_fatigue'],
                    'recommended_actions': ['improve_ad_copy', 'refine_targeting', 'refresh_creatives']
                })
            
            # Ø´Ø°ÙˆØ° ÙÙŠ Ø§Ù„ØªÙƒÙ„ÙØ©
            if performance.avg_cpc > 20.0:
                anomalies.append({
                    'type': 'high_cpc_anomaly',
                    'metric': 'avg_cpc',
                    'value': performance.avg_cpc,
                    'severity': 'high',
                    'description': 'ØªÙƒÙ„ÙØ© Ø§Ù„Ù†Ù‚Ø±Ø© Ù…Ø±ØªÙØ¹Ø© Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ',
                    'possible_causes': ['increased_competition', 'poor_quality_score', 'broad_targeting'],
                    'recommended_actions': ['optimize_quality_score', 'refine_targeting', 'adjust_bids']
                })
            
            # Ø´Ø°ÙˆØ° ÙÙŠ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª
            if performance.conversion_rate > 20.0:
                anomalies.append({
                    'type': 'high_conversion_anomaly',
                    'metric': 'conversion_rate',
                    'value': performance.conversion_rate,
                    'severity': 'medium',
                    'description': 'Ù…Ø¹Ø¯Ù„ ØªØ­ÙˆÙŠÙ„ Ù…Ø±ØªÙØ¹ Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ',
                    'possible_causes': ['tracking_issues', 'exceptional_offer', 'data_error'],
                    'recommended_actions': ['verify_tracking', 'check_data_accuracy', 'investigate_traffic_source']
                })
            
            return anomalies
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø´Ø°ÙˆØ°: {e}")
            return []
    
    async def _generate_predictions(self, campaign_id: str, performance: CampaignPerformance) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª"""
        try:
            predictions = {
                'next_7_days': {},
                'next_30_days': {},
                'confidence_intervals': {},
                'factors_affecting_predictions': []
            }
            
            # ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù‚Ø§Ø¯Ù…
            predictions['next_7_days'] = {
                'expected_clicks': int(performance.clicks * 1.05),  # Ù†Ù…Ùˆ Ù…ØªÙˆÙ‚Ø¹ 5%
                'expected_conversions': int(performance.conversions * 1.03),  # Ù†Ù…Ùˆ Ù…ØªÙˆÙ‚Ø¹ 3%
                'expected_cost': round(performance.cost * 1.04, 2),  # Ø²ÙŠØ§Ø¯Ø© Ù…ØªÙˆÙ‚Ø¹Ø© 4%
                'expected_roas': round(performance.roas * 1.02, 2)  # ØªØ­Ø³Ù† Ù…ØªÙˆÙ‚Ø¹ 2%
            }
            
            # ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…
            predictions['next_30_days'] = {
                'expected_clicks': int(performance.clicks * 4.2 * 1.1),  # 4 Ø£Ø³Ø§Ø¨ÙŠØ¹ + Ù†Ù…Ùˆ 10%
                'expected_conversions': int(performance.conversions * 4.2 * 1.08),  # Ù†Ù…Ùˆ 8%
                'expected_cost': round(performance.cost * 4.2 * 1.06, 2),  # Ø²ÙŠØ§Ø¯Ø© 6%
                'expected_roas': round(performance.roas * 1.05, 2)  # ØªØ­Ø³Ù† 5%
            }
            
            # ÙØªØ±Ø§Øª Ø§Ù„Ø«Ù‚Ø©
            predictions['confidence_intervals'] = {
                'clicks': {'lower': 0.85, 'upper': 1.15},
                'conversions': {'lower': 0.80, 'upper': 1.20},
                'cost': {'lower': 0.90, 'upper': 1.10},
                'roas': {'lower': 0.95, 'upper': 1.05}
            }
            
            # Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø¤Ø«Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
            predictions['factors_affecting_predictions'] = [
                'seasonal_trends',
                'competitor_activity',
                'market_conditions',
                'budget_changes',
                'targeting_adjustments'
            ]
            
            return predictions
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª: {e}")
            return {}

class PerformanceAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªØ·ÙˆØ±"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        self.performance_cache = {}
        self.benchmark_data = {}
        self.trend_analyzer = TrendAnalyzer()
    
    async def analyze_campaign_performance(self, campaign_id: str, 
                                         performance_data: CampaignPerformance) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©"""
        try:
            analysis = {
                'campaign_id': campaign_id,
                'overall_score': 0.0,
                'performance_metrics': {},
                'trends': {},
                'benchmarks': {},
                'insights': [],
                'recommendations': []
            }
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            overall_score = await self._calculate_overall_score(performance_data)
            analysis['overall_score'] = overall_score
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙØ±Ø¯ÙŠØ©
            metrics_analysis = await self._analyze_individual_metrics(performance_data)
            analysis['performance_metrics'] = metrics_analysis
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
            trends = await self.trend_analyzer.analyze_trends(campaign_id, performance_data)
            analysis['trends'] = trends
            
            # Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±
            benchmarks = await self._compare_with_benchmarks(performance_data)
            analysis['benchmarks'] = benchmarks
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰
            insights = await self._generate_insights(performance_data, trends, benchmarks)
            analysis['insights'] = insights
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª
            recommendations = await self._generate_performance_recommendations(
                campaign_id, performance_data, analysis
            )
            analysis['recommendations'] = recommendations
            
            return analysis
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
            return {'error': str(e)}
    
    async def _calculate_overall_score(self, performance: CampaignPerformance) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©"""
        try:
            # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
            weights = {
                'ctr': 0.20,
                'conversion_rate': 0.25,
                'cost_efficiency': 0.20,
                'quality_score': 0.15,
                'impression_share': 0.10,
                'roas': 0.10
            }
            
            scores = {}
            
            # Ù†Ù‚Ø§Ø· Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø±
            scores['ctr'] = min(performance.ctr / 5.0 * 100, 100)  # 5% = 100 Ù†Ù‚Ø·Ø©
            
            # Ù†Ù‚Ø§Ø· Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
            scores['conversion_rate'] = min(performance.conversion_rate / 10.0 * 100, 100)  # 10% = 100 Ù†Ù‚Ø·Ø©
            
            # Ù†Ù‚Ø§Ø· ÙƒÙØ§Ø¡Ø© Ø§Ù„ØªÙƒÙ„ÙØ© (Ø¹ÙƒØ³ÙŠ)
            if performance.cost_per_conversion > 0:
                scores['cost_efficiency'] = max(100 - (performance.cost_per_conversion / 100 * 100), 0)
            else:
                scores['cost_efficiency'] = 0
            
            # Ù†Ù‚Ø§Ø· Ø§Ù„Ø¬ÙˆØ¯Ø©
            scores['quality_score'] = performance.quality_score * 10  # Ù…Ù† 10
            
            # Ù†Ù‚Ø§Ø· Ø­ØµØ© Ø§Ù„Ø¸Ù‡ÙˆØ±
            scores['impression_share'] = performance.impression_share
            
            # Ù†Ù‚Ø§Ø· Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ
            if performance.roas > 0:
                scores['roas'] = min(performance.roas / 4.0 * 100, 100)  # 4x ROAS = 100 Ù†Ù‚Ø·Ø©
            else:
                scores['roas'] = 0
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø±Ø¬Ø­Ø©
            weighted_score = sum(scores[metric] * weights[metric] for metric in weights.keys())
            
            return round(weighted_score, 2)
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {e}")
            return 0.0
    
    async def _analyze_individual_metrics(self, performance: CampaignPerformance) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙØ±Ø¯ÙŠØ©"""
        try:
            metrics = {}
            
            # ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø±
            metrics['ctr_analysis'] = {
                'value': performance.ctr,
                'status': 'excellent' if performance.ctr >= 5.0 else 
                         'good' if performance.ctr >= 3.0 else 
                         'average' if performance.ctr >= 1.0 else 'poor',
                'benchmark': 2.5,
                'improvement_potential': max(2.5 - performance.ctr, 0)
            }
            
            # ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
            metrics['conversion_rate_analysis'] = {
                'value': performance.conversion_rate,
                'status': 'excellent' if performance.conversion_rate >= 10.0 else 
                         'good' if performance.conversion_rate >= 5.0 else 
                         'average' if performance.conversion_rate >= 2.0 else 'poor',
                'benchmark': 3.5,
                'improvement_potential': max(3.5 - performance.conversion_rate, 0)
            }
            
            # ØªØ­Ù„ÙŠÙ„ ØªÙƒÙ„ÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„
            metrics['cost_per_conversion_analysis'] = {
                'value': performance.cost_per_conversion,
                'status': 'excellent' if performance.cost_per_conversion <= 50 else 
                         'good' if performance.cost_per_conversion <= 100 else 
                         'average' if performance.cost_per_conversion <= 200 else 'poor',
                'benchmark': 100,
                'savings_potential': max(performance.cost_per_conversion - 100, 0)
            }
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ
            metrics['roas_analysis'] = {
                'value': performance.roas,
                'status': 'excellent' if performance.roas >= 4.0 else 
                         'good' if performance.roas >= 2.0 else 
                         'average' if performance.roas >= 1.0 else 'poor',
                'benchmark': 2.5,
                'improvement_potential': max(2.5 - performance.roas, 0)
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙØ±Ø¯ÙŠØ©: {e}")
            return {}
    
    async def _compare_with_benchmarks(self, performance: CampaignPerformance) -> Dict[str, Any]:
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±"""
        try:
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØµÙ†Ø§Ø¹Ø© (ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ«Ù‡Ø§ Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø®Ø§Ø±Ø¬ÙŠØ©)
            industry_benchmarks = {
                'search_campaigns': {
                    'avg_ctr': 3.17,
                    'avg_conversion_rate': 3.75,
                    'avg_cost_per_click': 2.69,
                    'avg_cost_per_conversion': 48.96
                },
                'display_campaigns': {
                    'avg_ctr': 0.46,
                    'avg_conversion_rate': 0.89,
                    'avg_cost_per_click': 0.63,
                    'avg_cost_per_conversion': 75.51
                }
            }
            
            # Ø§ÙØªØ±Ø§Ø¶ Ø­Ù…Ù„Ø© Ø¨Ø­Ø« (ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ¯Ù‡Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©)
            benchmark = industry_benchmarks['search_campaigns']
            
            comparison = {
                'ctr_vs_benchmark': {
                    'performance': performance.ctr,
                    'benchmark': benchmark['avg_ctr'],
                    'difference_percentage': ((performance.ctr - benchmark['avg_ctr']) / benchmark['avg_ctr']) * 100,
                    'status': 'above' if performance.ctr > benchmark['avg_ctr'] else 'below'
                },
                'conversion_rate_vs_benchmark': {
                    'performance': performance.conversion_rate,
                    'benchmark': benchmark['avg_conversion_rate'],
                    'difference_percentage': ((performance.conversion_rate - benchmark['avg_conversion_rate']) / benchmark['avg_conversion_rate']) * 100,
                    'status': 'above' if performance.conversion_rate > benchmark['avg_conversion_rate'] else 'below'
                },
                'cpc_vs_benchmark': {
                    'performance': performance.avg_cpc,
                    'benchmark': benchmark['avg_cost_per_click'],
                    'difference_percentage': ((performance.avg_cpc - benchmark['avg_cost_per_click']) / benchmark['avg_cost_per_click']) * 100,
                    'status': 'below' if performance.avg_cpc < benchmark['avg_cost_per_click'] else 'above'
                }
            }
            
            return comparison
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±: {e}")
            return {}
    
    async def _generate_insights(self, performance: CampaignPerformance, 
                               trends: Dict[str, Any], benchmarks: Dict[str, Any]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰"""
        insights = []
        
        try:
            # Ø±Ø¤Ù‰ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø±
            if performance.ctr > 5.0:
                insights.append("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø± Ù…Ù…ØªØ§Ø² - Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª ØªØ¬Ø°Ø¨ Ø§Ù†ØªØ¨Ø§Ù‡ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø¨ÙØ¹Ø§Ù„ÙŠØ©")
            elif performance.ctr < 1.0:
                insights.append("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø± Ù…Ù†Ø®ÙØ¶ - ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† ÙˆØ§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù")
            
            # Ø±Ø¤Ù‰ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
            if performance.conversion_rate > 10.0:
                insights.append("Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ù…ØªØ§Ø² - Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ù‚ØµÙˆØ¯Ø© ÙˆØ§Ù„Ø¹Ø±Ø¶ ÙØ¹Ø§Ù„Ø§Ù† Ø¬Ø¯Ø§Ù‹")
            elif performance.conversion_rate < 2.0:
                insights.append("Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ù†Ø®ÙØ¶ - ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ù‚ØµÙˆØ¯Ø© ÙˆØ§Ù„Ø¹Ø±Ø¶")
            
            # Ø±Ø¤Ù‰ Ø§Ù„ØªÙƒÙ„ÙØ©
            if performance.cost_per_conversion > 200:
                insights.append("ØªÙƒÙ„ÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ø±ØªÙØ¹Ø© - ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù ÙˆØ§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¹Ø±ÙˆØ¶")
            elif performance.cost_per_conversion < 50:
                insights.append("ØªÙƒÙ„ÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ù…ØªØ§Ø²Ø© - ÙØ±ØµØ© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„ØªÙˆØ³Ø¹")
            
            # Ø±Ø¤Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ
            if performance.roas > 4.0:
                insights.append("Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ù…Ù…ØªØ§Ø² - Ø§Ù„Ø­Ù…Ù„Ø© Ù…Ø±Ø¨Ø­Ø© Ø¬Ø¯Ø§Ù‹")
            elif performance.roas < 1.0:
                insights.append("Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ù…Ù†Ø®ÙØ¶ - Ø§Ù„Ø­Ù…Ù„Ø© ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø©")
            
            # Ø±Ø¤Ù‰ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
            if trends.get('overall_trend') == 'improving':
                insights.append("Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ ØªØ­Ø³Ù† Ù…Ø³ØªÙ…Ø± - Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©")
            elif trends.get('overall_trend') == 'declining':
                insights.append("Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ ØªØ±Ø§Ø¬Ø¹ - ÙŠØ­ØªØ§Ø¬ ØªØ¯Ø®Ù„ ÙÙˆØ±ÙŠ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            
            # Ø±Ø¤Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±
            ctr_benchmark = benchmarks.get('ctr_vs_benchmark', {})
            if ctr_benchmark.get('status') == 'above':
                insights.append(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø± Ø£Ø¹Ù„Ù‰ Ù…Ù† Ù…Ø¹ÙŠØ§Ø± Ø§Ù„ØµÙ†Ø§Ø¹Ø© Ø¨Ù†Ø³Ø¨Ø© {ctr_benchmark.get('difference_percentage', 0):.1f}%")
            
            return insights
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰: {e}")
            return []
    
    async def _generate_performance_recommendations(self, campaign_id: str, 
                                                  performance: CampaignPerformance,
                                                  analysis: Dict[str, Any]) -> List[OptimizationRecommendation]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        recommendations = []
        
        try:
            # ØªÙˆØµÙŠØ§Øª Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø±
            if performance.ctr < 2.0:
                recommendations.append(OptimizationRecommendation(
                    recommendation_id=str(uuid.uuid4()),
                    campaign_id=campaign_id,
                    type="improve_ctr",
                    title="ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø±",
                    description="Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø± Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ØŒ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† ÙˆØ§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù",
                    impact_score=8.5,
                    effort_score=6.0,
                    priority="high",
                    estimated_impact={
                        "ctr_improvement": "30-50%",
                        "clicks_increase": "25-40%",
                        "cost_impact": "neutral"
                    },
                    implementation_steps=[
                        "Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØªØ­Ø³ÙŠÙ† Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª",
                        "Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø£ÙƒØ«Ø± ØµÙ„Ø©",
                        "ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ ÙˆØ§Ù„Ø¯Ø¹ÙˆØ© Ù„Ù„Ø¹Ù…Ù„",
                        "Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© A/B"
                    ],
                    supporting_data={
                        "current_ctr": performance.ctr,
                        "industry_benchmark": 3.17,
                        "improvement_potential": 3.17 - performance.ctr
                    }
                ))
            
            # ØªÙˆØµÙŠØ§Øª Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
            if performance.conversion_rate < 3.0:
                recommendations.append(OptimizationRecommendation(
                    recommendation_id=str(uuid.uuid4()),
                    campaign_id=campaign_id,
                    type="improve_conversion_rate",
                    title="ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„",
                    description="Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ù†Ø®ÙØ¶ØŒ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ù‚ØµÙˆØ¯Ø© ÙˆØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…",
                    impact_score=9.0,
                    effort_score=7.5,
                    priority="high",
                    estimated_impact={
                        "conversion_rate_improvement": "40-60%",
                        "conversions_increase": "35-55%",
                        "roas_improvement": "30-50%"
                    },
                    implementation_steps=[
                        "ØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ù‚ØµÙˆØ¯Ø©",
                        "ØªØ¨Ø³ÙŠØ· Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„",
                        "ØªØ­Ø³ÙŠÙ† ØªØµÙ…ÙŠÙ… Ø§Ù„ØµÙØ­Ø© ÙˆØ³Ù‡ÙˆÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…",
                        "Ø¥Ø¶Ø§ÙØ© Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„Ø£Ù…Ø§Ù†",
                        "Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ø±ÙˆØ¶ ÙˆØ­ÙˆØ§ÙØ² Ù…Ø®ØªÙ„ÙØ©"
                    ],
                    supporting_data={
                        "current_conversion_rate": performance.conversion_rate,
                        "industry_benchmark": 3.75,
                        "improvement_potential": 3.75 - performance.conversion_rate
                    }
                ))
            
            # ØªÙˆØµÙŠØ§Øª ØªÙƒÙ„ÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„
            if performance.cost_per_conversion > 100:
                recommendations.append(OptimizationRecommendation(
                    recommendation_id=str(uuid.uuid4()),
                    campaign_id=campaign_id,
                    type="reduce_cost_per_conversion",
                    title="ØªÙ‚Ù„ÙŠÙ„ ØªÙƒÙ„ÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„",
                    description="ØªÙƒÙ„ÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù…Ø±ØªÙØ¹Ø©ØŒ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù ÙˆØ§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¹Ø±ÙˆØ¶",
                    impact_score=8.0,
                    effort_score=5.5,
                    priority="medium",
                    estimated_impact={
                        "cost_reduction": "20-35%",
                        "efficiency_improvement": "25-40%",
                        "budget_optimization": "15-30%"
                    },
                    implementation_steps=[
                        "Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©",
                        "Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø³Ù„Ø¨ÙŠØ©",
                        "ØªØ­Ø³ÙŠÙ† Ù†Ù‚Ø§Ø· Ø§Ù„Ø¬ÙˆØ¯Ø©",
                        "ØªØ¹Ø¯ÙŠÙ„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¹Ø±ÙˆØ¶",
                        "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠ ÙˆØ§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠ"
                    ],
                    supporting_data={
                        "current_cost_per_conversion": performance.cost_per_conversion,
                        "industry_benchmark": 48.96,
                        "savings_potential": performance.cost_per_conversion - 48.96
                    }
                ))
            
            # ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ
            if performance.roas < 2.0:
                recommendations.append(OptimizationRecommendation(
                    recommendation_id=str(uuid.uuid4()),
                    campaign_id=campaign_id,
                    type="improve_roas",
                    title="ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ",
                    description="Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ù…Ù†Ø®ÙØ¶ØŒ ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©",
                    impact_score=9.5,
                    effort_score=8.0,
                    priority="critical",
                    estimated_impact={
                        "roas_improvement": "50-100%",
                        "revenue_increase": "40-80%",
                        "profitability_improvement": "significant"
                    },
                    implementation_steps=[
                        "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø­Ù…Ù„Ø©",
                        "ØªØ­Ø³ÙŠÙ† Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª/Ø§Ù„Ø®Ø¯Ù…Ø§Øª",
                        "ØªØ­Ø³ÙŠÙ† Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¨ÙŠØ¹ ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„",
                        "Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù",
                        "ØªØ­Ø³ÙŠÙ† ØªØªØ¨Ø¹ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª ÙˆÙ‚ÙŠØ§Ø³ Ø§Ù„Ù‚ÙŠÙ…Ø©"
                    ],
                    supporting_data={
                        "current_roas": performance.roas,
                        "target_roas": 2.5,
                        "improvement_needed": 2.5 - performance.roas
                    }
                ))
            
            # ØªÙˆØµÙŠØ§Øª Ø­ØµØ© Ø§Ù„Ø¸Ù‡ÙˆØ±
            if performance.impression_share < 50.0:
                recommendations.append(OptimizationRecommendation(
                    recommendation_id=str(uuid.uuid4()),
                    campaign_id=campaign_id,
                    type="increase_impression_share",
                    title="Ø²ÙŠØ§Ø¯Ø© Ø­ØµØ© Ø§Ù„Ø¸Ù‡ÙˆØ±",
                    description="Ø­ØµØ© Ø§Ù„Ø¸Ù‡ÙˆØ± Ù…Ù†Ø®ÙØ¶Ø©ØŒ ÙØ±ØµØ© Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆØµÙˆÙ„ ÙˆØ§Ù„Ø¸Ù‡ÙˆØ±",
                    impact_score=7.0,
                    effort_score=4.0,
                    priority="medium",
                    estimated_impact={
                        "impression_share_increase": "20-40%",
                        "impressions_increase": "30-60%",
                        "reach_expansion": "25-50%"
                    },
                    implementation_steps=[
                        "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©",
                        "ØªØ­Ø³ÙŠÙ† Ù†Ù‚Ø§Ø· Ø§Ù„Ø¬ÙˆØ¯Ø©",
                        "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¹Ø±ÙˆØ¶ Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø©",
                        "ØªÙˆØ³ÙŠØ¹ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©",
                        "ØªØ­Ø³ÙŠÙ† ØµÙ„Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª"
                    ],
                    supporting_data={
                        "current_impression_share": performance.impression_share,
                        "target_impression_share": 70.0,
                        "lost_impression_share": 100.0 - performance.impression_share
                    }
                ))
            
            return recommendations
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡: {e}")
            return []

class CampaignManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø­Ù…Ù„Ø§Øª Ø§Ù„Ù…ØªØ·ÙˆØ±"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ø­Ù…Ù„Ø§Øª"""
        self.campaigns_cache = {}
        self.performance_analyzer = PerformanceAnalyzer()
        self.optimization_queue = asyncio.Queue()
        self.active_optimizations = {}
        
    async def create_campaign(self, config: CampaignConfig, user_id: str) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø­Ù…Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
        try:
            campaign_id = str(uuid.uuid4())
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            validation_result = await self._validate_campaign_config(config)
            if not validation_result['valid']:
                return {
                    'success': False,
                    'error': 'Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø© ØºÙŠØ± ØµØ­ÙŠØ­Ø©',
                    'validation_errors': validation_result['errors']
                }
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©
            campaign_data = {
                'campaign_id': campaign_id,
                'user_id': user_id,
                'config': asdict(config),
                'status': 'draft',
                'created_at': datetime.now(timezone.utc).isoformat(),
                'updated_at': datetime.now(timezone.utc).isoformat(),
                'performance': None,
                'optimization_history': [],
                'budget_history': [],
                'metadata': {
                    'created_by': user_id,
                    'version': '1.0',
                    'platform': 'google_ads_ai_platform'
                }
            }
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
            self.campaigns_cache[campaign_id] = campaign_data
            
            # ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©
            encrypted_data = security_manager.encrypt_sensitive_data(json.dumps(campaign_data))
            
            logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø­Ù…Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©: {campaign_id}")
            
            return {
                'success': True,
                'campaign_id': campaign_id,
                'message': 'ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­',
                'campaign_data': campaign_data,
                'next_steps': [
                    'Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©',
                    'Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©',
                    'Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª',
                    'ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø­Ù…Ù„Ø©'
                ]
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
            return {
                'success': False,
                'error': f'Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©: {str(e)}'
            }
    
    async def _validate_campaign_config(self, config: CampaignConfig) -> Dict[str, Any]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©"""
        try:
            validation = {'valid': True, 'errors': []}
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø³Ù…
            if not config.name or len(config.name.strip()) < 3:
                validation['errors'].append('Ø§Ø³Ù… Ø§Ù„Ø­Ù…Ù„Ø© ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† 3 Ø£Ø­Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„')
                validation['valid'] = False
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©
            if config.budget_amount <= 0:
                validation['errors'].append('Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø£ÙƒØ¨Ø± Ù…Ù† ØµÙØ±')
                validation['valid'] = False
            elif config.budget_amount < 10:
                validation['errors'].append('Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† 10 Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„')
                validation['valid'] = False
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
            if not config.target_locations:
                validation['errors'].append('ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆÙ‚Ø¹ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù')
                validation['valid'] = False
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
            if not config.target_languages:
                validation['errors'].append('ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ù„ØºØ© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù')
                validation['valid'] = False
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
            if config.start_date and config.end_date:
                try:
                    start = datetime.fromisoformat(config.start_date.replace('Z', '+00:00'))
                    end = datetime.fromisoformat(config.end_date.replace('Z', '+00:00'))
                    if end <= start:
                        validation['errors'].append('ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¨Ø¹Ø¯ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©')
                        validation['valid'] = False
                except ValueError:
                    validation['errors'].append('ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ø±ÙŠØ® ØºÙŠØ± ØµØ­ÙŠØ­')
                    validation['valid'] = False
            
            return validation
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
            return {'valid': False, 'errors': [f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚: {str(e)}']}
    
    async def get_campaign_performance(self, campaign_id: str, date_range: str = "last_30_days") -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©"""
        try:
            # Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ (ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ÙŠØªÙ… Ø¬Ù„Ø¨Ù‡Ø§ Ù…Ù† Google Ads API)
            performance_data = CampaignPerformance(
                campaign_id=campaign_id,
                impressions=12500,
                clicks=375,
                cost=750.50,
                conversions=28,
                conversion_value=2240.00,
                ctr=3.0,
                avg_cpc=2.00,
                cost_per_conversion=26.80,
                conversion_rate=7.47,
                roas=2.98,
                quality_score=7.2,
                impression_share=65.5,
                search_impression_share=62.3,
                date_range=date_range
            )
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡
            analysis = await self.performance_analyzer.analyze_campaign_performance(
                campaign_id, performance_data
            )
            
            return {
                'success': True,
                'campaign_id': campaign_id,
                'performance_data': asdict(performance_data),
                'analysis': analysis,
                'last_updated': datetime.now(timezone.utc).isoformat()
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
            return {
                'success': False,
                'error': f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©: {str(e)}'
            }
    
    async def optimize_campaign(self, campaign_id: str, optimization_goals: List[OptimizationGoal]) -> Dict[str, Any]:
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ù…Ù„Ø©"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø­Ù…Ù„Ø©
            if campaign_id not in self.campaigns_cache:
                return {
                    'success': False,
                    'error': 'Ø§Ù„Ø­Ù…Ù„Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©'
                }
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ ØªØ­Ø³ÙŠÙ† Ù†Ø´Ø·
            if campaign_id in self.active_optimizations:
                return {
                    'success': False,
                    'error': 'ÙŠÙˆØ¬Ø¯ ØªØ­Ø³ÙŠÙ† Ù†Ø´Ø· Ù„Ù„Ø­Ù…Ù„Ø© Ø¨Ø§Ù„ÙØ¹Ù„'
                }
            
            # Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ†
            optimization_id = str(uuid.uuid4())
            self.active_optimizations[campaign_id] = optimization_id
            
            # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ØªØ­Ø³ÙŠÙ†
            await self.optimization_queue.put({
                'optimization_id': optimization_id,
                'campaign_id': campaign_id,
                'goals': optimization_goals,
                'started_at': datetime.now(timezone.utc).isoformat()
            })
            
            # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ø³ÙŠÙ† ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
            campaigns_executor.submit(self._run_optimization, optimization_id, campaign_id, optimization_goals)
            
            return {
                'success': True,
                'optimization_id': optimization_id,
                'message': 'ØªÙ… Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ†',
                'estimated_duration': '5-15 Ø¯Ù‚ÙŠÙ‚Ø©',
                'status': 'in_progress'
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
            return {
                'success': False,
                'error': f'Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ù…Ù„Ø©: {str(e)}'
            }
    
    def _run_optimization(self, optimization_id: str, campaign_id: str, goals: List[OptimizationGoal]):
        """ØªØ´ØºÙŠÙ„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ†"""
        try:
            logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ù…Ù„Ø©: {campaign_id}")
            
            # Ù…Ø­Ø§ÙƒØ§Ø© Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ†
            time.sleep(5)  # Ù…Ø­Ø§ÙƒØ§Ø© ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            
            # Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ø³ÙŠÙ†
            optimization_results = {
                'optimization_id': optimization_id,
                'campaign_id': campaign_id,
                'goals': [goal.value for goal in goals],
                'changes_made': [
                    'ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©',
                    'ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¹Ø±ÙˆØ¶',
                    'ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù',
                    'ØªØ­Ø¯ÙŠØ« Ù†ØµÙˆØµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª'
                ],
                'expected_improvements': {
                    'ctr_improvement': '15-25%',
                    'conversion_rate_improvement': '10-20%',
                    'cost_reduction': '5-15%',
                    'roas_improvement': '20-30%'
                },
                'completed_at': datetime.now(timezone.utc).isoformat(),
                'status': 'completed'
            }
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            if campaign_id in self.campaigns_cache:
                if 'optimization_history' not in self.campaigns_cache[campaign_id]:
                    self.campaigns_cache[campaign_id]['optimization_history'] = []
                self.campaigns_cache[campaign_id]['optimization_history'].append(optimization_results)
            
            # Ø¥Ø²Ø§Ù„Ø© Ù…Ù† Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©
            if campaign_id in self.active_optimizations:
                del self.active_optimizations[campaign_id]
            
            logger.info(f"âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ù…Ù„Ø©: {campaign_id}")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ø³ÙŠÙ†: {e}")
            # Ø¥Ø²Ø§Ù„Ø© Ù…Ù† Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
            if campaign_id in self.active_optimizations:
                del self.active_optimizations[campaign_id]

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„Ø­Ù…Ù„Ø§Øª
campaign_manager = CampaignManager()

# ==================== Ù…Ø³Ø§Ø±Ø§Øª API ====================

@google_ads_campaigns_bp.route('/health', methods=['GET'])
def campaigns_health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø®Ø¯Ù…Ø© Ø§Ù„Ø­Ù…Ù„Ø§Øª"""
    try:
        return jsonify({
            'success': True,
            'service': 'google_ads_campaigns',
            'status': 'healthy',
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'libraries': {
                'jwt': JWT_LIBRARY,
                'bcrypt': BCRYPT_LIBRARY,
                'crypto': CRYPTO_LIBRARY
            },
            'services_status': CAMPAIGNS_SERVICES_STATUS,
            'active_campaigns': len(campaign_manager.campaigns_cache),
            'active_optimizations': len(campaign_manager.active_optimizations)
        })
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø­Ù…Ù„Ø§Øª: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@google_ads_campaigns_bp.route('/create', methods=['POST'])
@jwt_required_campaigns
def create_campaign():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø­Ù…Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'Ø¨ÙŠØ§Ù†Ø§Øª JSON Ù…Ø·Ù„ÙˆØ¨Ø©'
            }), 400
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† JWT
        user_id = request.current_user.get('user_id', 'unknown')
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©
        try:
            config = CampaignConfig(
                name=data.get('name', ''),
                campaign_type=CampaignType(data.get('campaign_type', 'SEARCH')),
                status=CampaignStatus(data.get('status', 'ENABLED')),
                budget_amount=float(data.get('budget_amount', 100.0)),
                budget_type=BudgetType(data.get('budget_type', 'DAILY')),
                bidding_strategy=BiddingStrategy(data.get('bidding_strategy', 'ENHANCED_CPC')),
                target_locations=data.get('target_locations', ['Saudi Arabia']),
                target_languages=data.get('target_languages', ['ar', 'en']),
                start_date=data.get('start_date'),
                end_date=data.get('end_date'),
                ad_schedule=data.get('ad_schedule'),
                device_targeting=data.get('device_targeting'),
                audience_targeting=data.get('audience_targeting'),
                negative_keywords=data.get('negative_keywords', []),
                conversion_goals=data.get('conversion_goals', []),
                enable_ai_optimization=data.get('enable_ai_optimization', True),
                optimization_goal=OptimizationGoal(data.get('optimization_goal', 'MAXIMIZE_CONVERSIONS'))
            )
        except (ValueError, TypeError) as e:
            return jsonify({
                'success': False,
                'error': f'Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø©: {str(e)}'
            }), 400
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©
        result = asyncio.run(campaign_manager.create_campaign(config, user_id))
        
        if result['success']:
            return jsonify(result), 201
        else:
            return jsonify(result), 400
            
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
        return jsonify({
            'success': False,
            'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'
        }), 500

@google_ads_campaigns_bp.route('/<campaign_id>/performance', methods=['GET'])
@jwt_required_campaigns
def get_campaign_performance(campaign_id):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©"""
    try:
        date_range = request.args.get('date_range', 'last_30_days')
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© date_range
        valid_ranges = ['last_7_days', 'last_30_days', 'last_90_days', 'this_month', 'last_month']
        if date_range not in valid_ranges:
            return jsonify({
                'success': False,
                'error': f'Ù†Ø·Ø§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ® ØºÙŠØ± ØµØ­ÙŠØ­. Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©: {valid_ranges}'
            }), 400
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©
        result = asyncio.run(campaign_manager.get_campaign_performance(campaign_id, date_range))
        
        if result['success']:
            return jsonify(result)
        else:
            return jsonify(result), 404
            
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
        return jsonify({
            'success': False,
            'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'
        }), 500

@google_ads_campaigns_bp.route('/<campaign_id>/optimize', methods=['POST'])
@jwt_required_campaigns
def optimize_campaign(campaign_id):
    """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ù…Ù„Ø©"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'Ø¨ÙŠØ§Ù†Ø§Øª JSON Ù…Ø·Ù„ÙˆØ¨Ø©'
            }), 400
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ­Ø³ÙŠÙ†
        goals_data = data.get('optimization_goals', ['MAXIMIZE_CONVERSIONS'])
        try:
            goals = [OptimizationGoal(goal) for goal in goals_data]
        except ValueError as e:
            return jsonify({
                'success': False,
                'error': f'Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ­Ø³ÙŠÙ† ØºÙŠØ± ØµØ­ÙŠØ­Ø©: {str(e)}'
            }), 400
        
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ù…Ù„Ø©
        result = asyncio.run(campaign_manager.optimize_campaign(campaign_id, goals))
        
        if result['success']:
            return jsonify(result), 202
        else:
            return jsonify(result), 400
            
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
        return jsonify({
            'success': False,
            'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'
        }), 500

@google_ads_campaigns_bp.route('/<campaign_id>', methods=['GET'])
@jwt_required_campaigns
def get_campaign_details(campaign_id):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø­Ù…Ù„Ø©"""
    try:
        if campaign_id not in campaign_manager.campaigns_cache:
            return jsonify({
                'success': False,
                'error': 'Ø§Ù„Ø­Ù…Ù„Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©'
            }), 404
        
        campaign_data = campaign_manager.campaigns_cache[campaign_id]
        
        return jsonify({
            'success': True,
            'campaign': campaign_data
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
        return jsonify({
            'success': False,
            'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'
        }), 500

@google_ads_campaigns_bp.route('/', methods=['GET'])
@jwt_required_campaigns
def list_campaigns():
    """Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø­Ù…Ù„Ø§Øª"""
    try:
        user_id = request.current_user.get('user_id', 'unknown')
        
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø­Ù…Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        user_campaigns = {
            campaign_id: campaign_data 
            for campaign_id, campaign_data in campaign_manager.campaigns_cache.items()
            if campaign_data.get('user_id') == user_id
        }
        
        return jsonify({
            'success': True,
            'campaigns': user_campaigns,
            'total_count': len(user_campaigns)
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø­Ù…Ù„Ø§Øª: {e}")
        return jsonify({
            'success': False,
            'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'
        }), 500

@google_ads_campaigns_bp.route('/test', methods=['GET'])
def test_campaigns_service():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø¯Ù…Ø© Ø§Ù„Ø­Ù…Ù„Ø§Øª"""
    try:
        # Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ù†Ø´Ø§Ø¡ token
        test_payload = {'user_id': 'test_user', 'role': 'admin'}
        test_token = security_manager.create_jwt_token(test_payload)
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† token
        verified_payload = security_manager.verify_jwt_token(test_token)
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ´ÙÙŠØ±
        test_data = "sensitive campaign data"
        encrypted_data = security_manager.encrypt_sensitive_data(test_data)
        decrypted_data = security_manager.decrypt_sensitive_data(encrypted_data)
        
        return jsonify({
            'success': True,
            'tests': {
                'jwt_creation': test_token is not None,
                'jwt_verification': verified_payload is not None,
                'jwt_payload_match': verified_payload.get('user_id') == 'test_user' if verified_payload else False,
                'encryption': encrypted_data != test_data,
                'decryption': decrypted_data == test_data,
                'libraries': {
                    'jwt_available': JWT_AVAILABLE,
                    'bcrypt_available': BCRYPT_AVAILABLE,
                    'crypto_available': CRYPTO_AVAILABLE
                }
            },
            'message': 'Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª'
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø¯Ù…Ø© Ø§Ù„Ø­Ù…Ù„Ø§Øª: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ØªØ³Ø¬ÙŠÙ„ Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ­Ù…ÙŠÙ„
logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Google Ads Campaigns Blueprint Ø¨Ù†Ø¬Ø§Ø­")
logger.info(f"ğŸ” Ø§Ù„Ø£Ù…Ø§Ù†: JWT={JWT_AVAILABLE}, bcrypt={BCRYPT_AVAILABLE}, crypto={CRYPTO_AVAILABLE}")
logger.info(f"ğŸ“Š Ø§Ù„Ø®Ø¯Ù…Ø§Øª: {sum(CAMPAIGNS_SERVICES_STATUS.values())}/8 Ù…ØªØ§Ø­Ø©")

# ØªØµØ¯ÙŠØ± Blueprint
__all__ = ['google_ads_campaigns_bp', 'campaign_manager', 'security_manager']

