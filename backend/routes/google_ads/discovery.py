"""
Google Ads Discovery Service
Ø®Ø¯Ù…Ø© Ø§ÙƒØªØ´Ø§Ù Google Ads Ø§Ù„Ø°ÙƒÙŠØ© ÙˆØ§Ù„Ù…ØªØ·ÙˆØ±Ø©

ÙŠÙˆÙØ± ÙˆØ¸Ø§Ø¦Ù Ø§ÙƒØªØ´Ø§Ù ÙˆØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„Ø© Ù„Ø­Ø³Ø§Ø¨Ø§Øª Google Ads Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ:
- Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª ÙˆØ§Ù„Ø­Ù…Ù„Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
- Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙØ±Øµ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† ÙˆØ§Ù„Ø³ÙˆÙ‚
- ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª ÙˆØ§Ù„ØªÙ†Ø¨Ø¤Ø§Øª

Author: Google Ads AI Platform Team
Version: 2.1.0
Security Level: Enterprise
Performance: Optimized with AI
"""

import os
import asyncio
import aiohttp
import json
import time
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any, Tuple, Union, Set
from dataclasses import dataclass, field, asdict
from enum import Enum, auto
from functools import wraps, lru_cache
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from collections import defaultdict, Counter
import hashlib
import uuid

# Flask imports
from flask import Blueprint, request, jsonify, current_app

# ==================== Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ø¢Ù…Ù†Ø© ====================

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ python-jose Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† PyJWT
try:
    from jose import jwt
    from jose.exceptions import JWTError, ExpiredSignatureError, JWTClaimsError
    JWT_AVAILABLE = True
    JWT_LIBRARY = 'python-jose'
except ImportError:
    JWT_AVAILABLE = False
    JWT_LIBRARY = 'ØºÙŠØ± Ù…ØªØ§Ø­'
    jwt = None
    JWTError = Exception
    ExpiredSignatureError = Exception
    JWTClaimsError = Exception

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ passlib Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† bcrypt
try:
    from passlib.hash import bcrypt as passlib_bcrypt
    from passlib.context import CryptContext
    BCRYPT_AVAILABLE = True
    BCRYPT_LIBRARY = 'passlib'
    # Ø¥Ù†Ø´Ø§Ø¡ context Ù„Ù„ØªØ´ÙÙŠØ±
    pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
except ImportError:
    BCRYPT_AVAILABLE = False
    BCRYPT_LIBRARY = 'ØºÙŠØ± Ù…ØªØ§Ø­'
    passlib_bcrypt = None
    pwd_context = None

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ pycryptodome Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† cryptography
try:
    from Crypto.Hash import SHA256, SHA512, HMAC
    from Crypto.Cipher import AES
    from Crypto.Random import get_random_bytes
    from Crypto.Protocol.KDF import PBKDF2
    from Crypto.Util.Padding import pad, unpad
    CRYPTO_AVAILABLE = True
    CRYPTO_LIBRARY = 'pycryptodome'
except ImportError:
    CRYPTO_AVAILABLE = False
    CRYPTO_LIBRARY = 'ØºÙŠØ± Ù…ØªØ§Ø­'
    SHA256 = None
    SHA512 = None
    HMAC = None
    AES = None
    get_random_bytes = None
    PBKDF2 = None
    pad = None
    unpad = None

# Third-party imports
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Local imports
import logging

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
logger = logging.getLogger(__name__)

# ØªØ³Ø¬ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
logger.info(f"ğŸ” JWT Library: {JWT_LIBRARY} ({'âœ…' if JWT_AVAILABLE else 'âŒ'})")
logger.info(f"ğŸ”’ Bcrypt Library: {BCRYPT_LIBRARY} ({'âœ…' if BCRYPT_AVAILABLE else 'âŒ'})")
logger.info(f"ğŸ”‘ Crypto Library: {CRYPTO_LIBRARY} ({'âœ…' if CRYPTO_AVAILABLE else 'âŒ'})")

# Ø¥Ù†Ø´Ø§Ø¡ Blueprint Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
google_ads_discovery_bp = Blueprint(
    'google_ads_discovery',
    __name__,
    url_prefix='/api/google-ads/discovery',
    static_folder=None,
    template_folder=None
)

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
SERVICES_STATUS = {
    'google_ads_client': False,
    'oauth_manager': False,
    'validators': False,
    'helpers': False,
    'database': False,
    'redis': False,
    'ai_services': False
}

try:
    from services.google_ads_client import GoogleAdsClientManager
    SERVICES_STATUS['google_ads_client'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ GoogleAdsClientManager ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from backend.routes.google_ads.auth_jwt import oauth_manager
    SERVICES_STATUS['oauth_manager'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ OAuth Manager ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from utils.validators import validate_customer_id, validate_discovery_params
    SERVICES_STATUS['validators'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ Validators ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from utils.helpers import (
        generate_unique_id, sanitize_text, format_currency,
        calculate_performance_score, extract_keywords_from_text
    )
    SERVICES_STATUS['helpers'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ Helpers ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from utils.database import DatabaseManager
    SERVICES_STATUS['database'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ DatabaseManager ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from utils.redis_config import cache_set, cache_get, cache_delete
    SERVICES_STATUS['redis'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ Redis ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

try:
    from services.ai_services import KeywordAnalyzer, CompetitorAnalyzer, OpportunityFinder
    SERVICES_STATUS['ai_services'] = True
except ImportError as e:
    logger.warning(f"âš ï¸ AI Services ØºÙŠØ± Ù…ØªØ§Ø­: {e}")

# ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª
SERVICES_AVAILABLE = any(SERVICES_STATUS.values())
logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø®Ø¯Ù…Ø§Øª Discovery - Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©: {sum(SERVICES_STATUS.values())}/7")

# Ø¥Ø¹Ø¯Ø§Ø¯ Thread Pool Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©
discovery_executor = ThreadPoolExecutor(max_workers=20, thread_name_prefix="discovery_worker")

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„ØªØ´ÙÙŠØ± ====================

class DiscoverySecurityManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„ØªØ´ÙÙŠØ± Ù„Ø®Ø¯Ù…Ø© Discovery"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù†"""
        self.jwt_secret = os.getenv('JWT_SECRET_KEY', 'discovery_secret_key_change_in_production')
        self.encryption_key = self._derive_encryption_key()
        self.session_timeout = timedelta(hours=12)
        
    def _derive_encryption_key(self) -> bytes:
        """Ø§Ø´ØªÙ‚Ø§Ù‚ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ´ÙÙŠØ±"""
        if CRYPTO_AVAILABLE:
            try:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… PBKDF2 Ù…Ù† pycryptodome
                password = self.jwt_secret.encode('utf-8')
                salt = b'google_ads_discovery_salt_2024'
                key = PBKDF2(password, salt, 32, count=100000, hmac_hash_module=SHA256)
                return key
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø´ØªÙ‚Ø§Ù‚ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ´ÙÙŠØ±: {e}")
        
        # fallback Ø¥Ù„Ù‰ hashlib
        import hashlib
        return hashlib.sha256(self.jwt_secret.encode('utf-8')).digest()
    
    def create_jwt_token(self, payload: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ JWT token Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… python-jose"""
        if not JWT_AVAILABLE:
            logger.warning("JWT ØºÙŠØ± Ù…ØªØ§Ø­ - Ø§Ø³ØªØ®Ø¯Ø§Ù… fallback")
            return self._create_fallback_token(payload)
        
        try:
            if expires_delta:
                expire = datetime.utcnow() + expires_delta
            else:
                expire = datetime.utcnow() + self.session_timeout
            
            payload.update({
                'exp': expire,
                'iat': datetime.utcnow(),
                'jti': str(uuid.uuid4()),
                'service': 'discovery'
            })
            
            token = jwt.encode(payload, self.jwt_secret, algorithm='HS256')
            return token if isinstance(token, str) else token.decode('utf-8')
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ JWT token: {e}")
            return self._create_fallback_token(payload)
    
    def verify_jwt_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT token Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… python-jose"""
        if not JWT_AVAILABLE:
            return self._verify_fallback_token(token)
        
        try:
            payload = jwt.decode(token, self.jwt_secret, algorithms=['HS256'])
            return payload
        except ExpiredSignatureError:
            logger.warning("JWT token Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©")
            return None
        except JWTError as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT token: {e}")
            return None
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT token: {e}")
            return None
    
    def _create_fallback_token(self, payload: Dict[str, Any]) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ token Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
        import base64
        import json
        
        try:
            payload_str = json.dumps(payload, default=str)
            encoded_payload = base64.b64encode(payload_str.encode('utf-8')).decode('utf-8')
            return f"discovery_fallback_{encoded_payload}_{uuid.uuid4().hex}"
        except Exception:
            return f"discovery_emergency_token_{uuid.uuid4().hex}"
    
    def _verify_fallback_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† token Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
        try:
            if token.startswith('discovery_fallback_'):
                parts = token.split('_', 3)
                if len(parts) >= 3:
                    import base64
                    import json
                    payload_str = base64.b64decode(parts[2]).decode('utf-8')
                    return json.loads(payload_str)
            return None
        except Exception:
            return None
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pycryptodome"""
        if not CRYPTO_AVAILABLE:
            logger.warning("Crypto ØºÙŠØ± Ù…ØªØ§Ø­ - Ø§Ø³ØªØ®Ø¯Ø§Ù… base64 encoding")
            import base64
            return base64.b64encode(data.encode('utf-8')).decode('utf-8')
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ IV Ø¹Ø´ÙˆØ§Ø¦ÙŠ
            iv = get_random_bytes(16)
            
            # Ø¥Ù†Ø´Ø§Ø¡ cipher
            cipher = AES.new(self.encryption_key, AES.MODE_CBC, iv)
            
            # ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ padding
            padded_data = pad(data.encode('utf-8'), AES.block_size)
            encrypted_data = cipher.encrypt(padded_data)
            
            # Ø¯Ù…Ø¬ IV Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø©
            result = iv + encrypted_data
            
            import base64
            return base64.b64encode(result).decode('utf-8')
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            # fallback
            import base64
            return base64.b64encode(data.encode('utf-8')).decode('utf-8')
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pycryptodome"""
        if not CRYPTO_AVAILABLE:
            logger.warning("Crypto ØºÙŠØ± Ù…ØªØ§Ø­ - Ø§Ø³ØªØ®Ø¯Ø§Ù… base64 decoding")
            try:
                import base64
                return base64.b64decode(encrypted_data.encode('utf-8')).decode('utf-8')
            except Exception:
                return encrypted_data
        
        try:
            import base64
            encrypted_bytes = base64.b64decode(encrypted_data.encode('utf-8'))
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ IV
            iv = encrypted_bytes[:16]
            encrypted = encrypted_bytes[16:]
            
            # Ø¥Ù†Ø´Ø§Ø¡ cipher
            cipher = AES.new(self.encryption_key, AES.MODE_CBC, iv)
            
            # ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± ÙˆØ¥Ø²Ø§Ù„Ø© padding
            decrypted_padded = cipher.decrypt(encrypted)
            decrypted_data = unpad(decrypted_padded, AES.block_size)
            
            return decrypted_data.decode('utf-8')
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            # fallback
            try:
                import base64
                return base64.b64decode(encrypted_data.encode('utf-8')).decode('utf-8')
            except Exception:
                return encrypted_data
    
    def create_secure_hash(self, data: str) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ hash Ø¢Ù…Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pycryptodome"""
        if CRYPTO_AVAILABLE:
            try:
                hash_obj = SHA256.new(data.encode('utf-8'))
                return hash_obj.hexdigest()
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ hash Ø¨Ù€ pycryptodome: {e}")
        
        # fallback Ø¥Ù„Ù‰ hashlib
        import hashlib
        return hashlib.sha256(data.encode('utf-8')).hexdigest()

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù†
discovery_security_manager = DiscoverySecurityManager()

# ==================== JWT Decorator ====================

def jwt_required_discovery(f):
    """Decorator Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT token ÙÙŠ discovery"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({
                'success': False,
                'error': 'Authorization header Ù…Ø·Ù„ÙˆØ¨',
                'error_code': 'MISSING_AUTH_HEADER'
            }), 401
        
        token = auth_header.split(' ')[1]
        token_data = discovery_security_manager.verify_jwt_token(token)
        
        if not token_data:
            return jsonify({
                'success': False,
                'error': 'Token ØºÙŠØ± ØµØ­ÙŠØ­ Ø£Ùˆ Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©',
                'error_code': 'INVALID_TOKEN'
            }), 401
        
        # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ request
        request.current_user = token_data
        return f(*args, **kwargs)
    
    return decorated_function

# ==================== Data Classes ====================

class DiscoveryType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§ÙƒØªØ´Ø§Ù"""
    ACCOUNTS = "accounts"
    CAMPAIGNS = "campaigns"
    KEYWORDS = "keywords"
    OPPORTUNITIES = "opportunities"
    COMPETITORS = "competitors"
    MARKET_TRENDS = "market_trends"
    AUDIENCE_INSIGHTS = "audience_insights"

class OpportunityType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙØ±Øµ"""
    KEYWORD_EXPANSION = "keyword_expansion"
    BUDGET_OPTIMIZATION = "budget_optimization"
    BID_OPTIMIZATION = "bid_optimization"
    AD_COPY_IMPROVEMENT = "ad_copy_improvement"
    LANDING_PAGE_OPTIMIZATION = "landing_page_optimization"
    AUDIENCE_EXPANSION = "audience_expansion"
    GEOGRAPHIC_EXPANSION = "geographic_expansion"
    DEVICE_OPTIMIZATION = "device_optimization"

@dataclass
class DiscoveryRequest:
    """Ø·Ù„Ø¨ Ø§Ù„Ø§ÙƒØªØ´Ø§Ù"""
    discovery_type: DiscoveryType
    customer_id: Optional[str] = None
    campaign_ids: List[str] = field(default_factory=list)
    keywords: List[str] = field(default_factory=list)
    competitors: List[str] = field(default_factory=list)
    date_range: str = "last_30_days"
    filters: Dict[str, Any] = field(default_factory=dict)
    options: Dict[str, Any] = field(default_factory=dict)

@dataclass
class KeywordOpportunity:
    """ÙØ±ØµØ© Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
    keyword: str
    search_volume: int
    competition: str
    suggested_bid: float
    relevance_score: float
    opportunity_score: float
    current_rank: Optional[int] = None
    potential_clicks: int = 0
    potential_conversions: int = 0
    potential_revenue: float = 0.0
    difficulty_level: str = "medium"
    related_keywords: List[str] = field(default_factory=list)

@dataclass
class CompetitorInsight:
    """Ø±Ø¤Ù‰ Ø§Ù„Ù…Ù†Ø§ÙØ³"""
    competitor_domain: str
    competitor_name: str
    estimated_budget: float
    ad_count: int
    top_keywords: List[str]
    ad_copy_themes: List[str]
    landing_page_insights: Dict[str, Any]
    performance_indicators: Dict[str, Any]
    competitive_advantage: List[str]
    weakness_areas: List[str]
    market_share: float = 0.0

# ==================== Discovery Services ====================

class KeywordDiscoveryService:
    """Ø®Ø¯Ù…Ø© Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        self.keyword_cache = {}
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        
    def discover_keywords(self, seed_keywords: List[str], options: Dict[str, Any] = None) -> List[KeywordOpportunity]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© - Ø¯Ø§Ù„Ø© Ù…ØªØ²Ø§Ù…Ù†Ø©"""
        try:
            if not options:
                options = {}
            
            discovered_keywords = []
            
            for seed_keyword in seed_keywords:
                # Ù…Ø­Ø§ÙƒØ§Ø© Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
                related_keywords = self._generate_related_keywords(seed_keyword)
                
                for keyword in related_keywords:
                    opportunity = KeywordOpportunity(
                        keyword=keyword,
                        search_volume=np.random.randint(1000, 50000),
                        competition=np.random.choice(['low', 'medium', 'high']),
                        suggested_bid=round(np.random.uniform(0.5, 5.0), 2),
                        relevance_score=round(np.random.uniform(0.6, 1.0), 2),
                        opportunity_score=round(np.random.uniform(0.5, 1.0), 2),
                        potential_clicks=np.random.randint(50, 1000),
                        potential_conversions=np.random.randint(5, 100),
                        potential_revenue=round(np.random.uniform(100, 5000), 2),
                        difficulty_level=np.random.choice(['easy', 'medium', 'hard']),
                        related_keywords=self._get_related_keywords(keyword)
                    )
                    discovered_keywords.append(opportunity)
            
            # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ÙØ±ØµØ©
            discovered_keywords.sort(key=lambda x: x.opportunity_score, reverse=True)
            
            return discovered_keywords[:options.get('limit', 50)]
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {e}")
            return []
    
    def _generate_related_keywords(self, seed_keyword: str) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø±ØªØ¨Ø·Ø© - Ø¯Ø§Ù„Ø© Ù…ØªØ²Ø§Ù…Ù†Ø©"""
        try:
            # Ù…Ø­Ø§ÙƒØ§Ø© ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø±ØªØ¨Ø·Ø©
            base_variations = [
                f"{seed_keyword} online",
                f"{seed_keyword} best",
                f"{seed_keyword} cheap",
                f"{seed_keyword} reviews",
                f"{seed_keyword} price",
                f"buy {seed_keyword}",
                f"{seed_keyword} near me",
                f"{seed_keyword} service",
                f"{seed_keyword} company",
                f"{seed_keyword} store"
            ]
            
            # Ø¥Ø¶Ø§ÙØ© ØªÙ†ÙˆÙŠØ¹Ø§Øª Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ø§Ù‹
            advanced_variations = [
                f"best {seed_keyword} 2024",
                f"affordable {seed_keyword}",
                f"{seed_keyword} comparison",
                f"{seed_keyword} guide",
                f"{seed_keyword} tips",
                f"professional {seed_keyword}",
                f"{seed_keyword} solutions",
                f"top {seed_keyword}",
                f"{seed_keyword} expert",
                f"{seed_keyword} consultation"
            ]
            
            all_variations = base_variations + advanced_variations
            return np.random.choice(all_variations, size=min(15, len(all_variations)), replace=False).tolist()
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø±ØªØ¨Ø·Ø©: {e}")
            return []
    
    def _get_related_keywords(self, keyword: str) -> List[str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø±ØªØ¨Ø·Ø© - Ø¯Ø§Ù„Ø© Ù…ØªØ²Ø§Ù…Ù†Ø©"""
        try:
            # Ù…Ø­Ø§ÙƒØ§Ø© ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø±ØªØ¨Ø·Ø©
            related = [
                f"{keyword} alternative",
                f"{keyword} similar",
                f"{keyword} like",
                f"{keyword} vs",
                f"{keyword} comparison"
            ]
            return related[:3]
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø±ØªØ¨Ø·Ø©: {e}")
            return []
    
    def analyze_keyword_clusters(self, keywords: List[str]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© - Ø¯Ø§Ù„Ø© Ù…ØªØ²Ø§Ù…Ù†Ø©"""
        try:
            if len(keywords) < 3:
                return {'clusters': [], 'analysis': 'Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù‚Ù„ÙŠÙ„ Ù„Ù„ØªØ­Ù„ÙŠÙ„'}
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø¥Ù„Ù‰ vectors
            try:
                tfidf_matrix = self.vectorizer.fit_transform(keywords)
                
                # ØªØ·Ø¨ÙŠÙ‚ K-means clustering
                n_clusters = min(5, len(keywords) // 2)
                if n_clusters < 2:
                    n_clusters = 2
                
                kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                cluster_labels = kmeans.fit_predict(tfidf_matrix)
                
                # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
                clusters = {}
                for i, keyword in enumerate(keywords):
                    cluster_id = int(cluster_labels[i])
                    if cluster_id not in clusters:
                        clusters[cluster_id] = []
                    clusters[cluster_id].append(keyword)
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
                cluster_analysis = []
                for cluster_id, cluster_keywords in clusters.items():
                    analysis = {
                        'cluster_id': cluster_id,
                        'keywords': cluster_keywords,
                        'size': len(cluster_keywords),
                        'theme': self._identify_cluster_theme(cluster_keywords),
                        'avg_search_volume': np.random.randint(5000, 25000),
                        'competition_level': np.random.choice(['low', 'medium', 'high']),
                        'opportunity_score': round(np.random.uniform(0.6, 1.0), 2)
                    }
                    cluster_analysis.append(analysis)
                
                return {
                    'clusters': cluster_analysis,
                    'total_clusters': len(clusters),
                    'analysis': f'ØªÙ… ØªØ­Ø¯ÙŠØ¯ {len(clusters)} Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©'
                }
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {e}")
                return {'clusters': [], 'analysis': 'ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª'}
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {e}")
            return {'clusters': [], 'analysis': 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„'}
    
    def _identify_cluster_theme(self, keywords: List[str]) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©"""
        try:
            # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
            common_words = []
            for keyword in keywords:
                words = keyword.lower().split()
                common_words.extend(words)
            
            # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹
            word_counts = Counter(common_words)
            most_common = word_counts.most_common(3)
            
            if most_common:
                return f"Ù…ÙˆØ¶ÙˆØ¹: {', '.join([word for word, count in most_common])}"
            else:
                return "Ù…ÙˆØ¶ÙˆØ¹ Ø¹Ø§Ù…"
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©: {e}")
            return "Ù…ÙˆØ¶ÙˆØ¹ ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

class CompetitorDiscoveryService:
    """Ø®Ø¯Ù…Ø© Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"""
        self.competitor_cache = {}
        
    def discover_competitors(self, domain: str, keywords: List[str] = None) -> List[CompetitorInsight]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ† - Ø¯Ø§Ù„Ø© Ù…ØªØ²Ø§Ù…Ù†Ø©"""
        try:
            competitors = []
            
            # Ù…Ø­Ø§ÙƒØ§Ø© Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†
            competitor_domains = [
                "competitor1.com",
                "competitor2.com", 
                "competitor3.com",
                "competitor4.com",
                "competitor5.com"
            ]
            
            for i, comp_domain in enumerate(competitor_domains):
                competitor = CompetitorInsight(
                    competitor_domain=comp_domain,
                    competitor_name=f"Competitor {i+1}",
                    estimated_budget=round(np.random.uniform(10000, 100000), 2),
                    ad_count=np.random.randint(50, 500),
                    top_keywords=self._get_competitor_keywords(comp_domain),
                    ad_copy_themes=self._analyze_ad_copy_themes(comp_domain),
                    landing_page_insights=self._analyze_landing_pages(comp_domain),
                    performance_indicators=self._get_performance_indicators(comp_domain),
                    competitive_advantage=self._identify_competitive_advantages(comp_domain),
                    weakness_areas=self._identify_weakness_areas(comp_domain),
                    market_share=round(np.random.uniform(5, 25), 2)
                )
                competitors.append(competitor)
            
            return competitors
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†: {e}")
            return []
    
    def _get_competitor_keywords(self, domain: str) -> List[str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        try:
            # Ù…Ø­Ø§ÙƒØ§Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            keywords = [
                "digital marketing",
                "online advertising",
                "SEO services",
                "PPC management",
                "social media marketing",
                "content marketing",
                "email marketing",
                "web design",
                "brand strategy",
                "marketing automation"
            ]
            return np.random.choice(keywords, size=5, replace=False).tolist()
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³: {e}")
            return []
    
    def _analyze_ad_copy_themes(self, domain: str) -> List[str]:
        """ØªØ­Ù„ÙŠÙ„ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ù†Ø³Ø® Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª"""
        try:
            themes = [
                "Quality Focus",
                "Price Competitive", 
                "Expert Service",
                "Fast Delivery",
                "Customer Satisfaction",
                "Innovation Leader",
                "Trusted Brand",
                "24/7 Support"
            ]
            return np.random.choice(themes, size=3, replace=False).tolist()
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª: {e}")
            return []
    
    def _analyze_landing_pages(self, domain: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ù‚ØµÙˆØ¯Ø©"""
        try:
            return {
                'page_count': np.random.randint(10, 50),
                'avg_load_time': round(np.random.uniform(1.5, 4.0), 2),
                'mobile_optimized': np.random.choice([True, False]),
                'conversion_elements': np.random.randint(3, 8),
                'design_quality': np.random.choice(['excellent', 'good', 'average', 'poor']),
                'content_quality': np.random.choice(['high', 'medium', 'low']),
                'user_experience_score': round(np.random.uniform(6.0, 9.5), 1)
            }
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ù‚ØµÙˆØ¯Ø©: {e}")
            return {}
    
    def _get_performance_indicators(self, domain: str) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            return {
                'estimated_traffic': np.random.randint(10000, 100000),
                'estimated_clicks': np.random.randint(5000, 50000),
                'estimated_conversions': np.random.randint(500, 5000),
                'estimated_ctr': round(np.random.uniform(2.0, 8.0), 2),
                'estimated_conversion_rate': round(np.random.uniform(1.0, 10.0), 2),
                'brand_awareness_score': round(np.random.uniform(0.3, 0.9), 2),
                'social_media_presence': np.random.choice(['strong', 'moderate', 'weak'])
            }
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡: {e}")
            return {}
    
    def _identify_competitive_advantages(self, domain: str) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø²Ø§ÙŠØ§ Ø§Ù„ØªÙ†Ø§ÙØ³ÙŠØ©"""
        try:
            advantages = [
                "Strong brand recognition",
                "Competitive pricing",
                "Superior customer service",
                "Advanced technology",
                "Wide product range",
                "Fast delivery",
                "Expert team",
                "Market leadership"
            ]
            return np.random.choice(advantages, size=3, replace=False).tolist()
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø²Ø§ÙŠØ§ Ø§Ù„ØªÙ†Ø§ÙØ³ÙŠØ©: {e}")
            return []
    
    def _identify_weakness_areas(self, domain: str) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù"""
        try:
            weaknesses = [
                "Limited mobile optimization",
                "Slow website speed",
                "Poor customer reviews",
                "Limited social media presence",
                "High pricing",
                "Limited product variety",
                "Weak brand awareness",
                "Poor user experience"
            ]
            return np.random.choice(weaknesses, size=2, replace=False).tolist()
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù: {e}")
            return []

# ==================== Discovery Manager ====================

class DiscoveryManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ø§ÙƒØªØ´Ø§Ù"""
        self.keyword_service = KeywordDiscoveryService()
        self.competitor_service = CompetitorDiscoveryService()
        self.discovery_cache = {}
        
    def execute_discovery(self, request: DiscoveryRequest, user_id: str) -> Dict[str, Any]:
        """ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù - Ø¯Ø§Ù„Ø© Ù…ØªØ²Ø§Ù…Ù†Ø©"""
        try:
            discovery_id = str(uuid.uuid4())
            
            result = {
                'discovery_id': discovery_id,
                'user_id': user_id,
                'request': asdict(request),
                'results': {},
                'metadata': {
                    'started_at': datetime.now(timezone.utc).isoformat(),
                    'status': 'in_progress'
                }
            }
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ø§ÙƒØªØ´Ø§Ù Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
            if request.discovery_type == DiscoveryType.KEYWORDS:
                result['results'] = self._discover_keywords(request)
            elif request.discovery_type == DiscoveryType.COMPETITORS:
                result['results'] = self._discover_competitors(request)
            else:
                result['results'] = self._comprehensive_discovery(request)
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø©
            result['metadata']['completed_at'] = datetime.now(timezone.utc).isoformat()
            result['metadata']['status'] = 'completed'
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
            self.discovery_cache[discovery_id] = result
            
            return {
                'success': True,
                'discovery_id': discovery_id,
                'results': result['results'],
                'metadata': result['metadata']
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø§ÙƒØªØ´Ø§Ù: {e}")
            return {
                'success': False,
                'error': f'Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø§ÙƒØªØ´Ø§Ù: {str(e)}'
            }
    
    def _discover_keywords(self, request: DiscoveryRequest) -> Dict[str, Any]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        try:
            keywords = self.keyword_service.discover_keywords(
                request.keywords, 
                request.options
            )
            
            # ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            cluster_analysis = self.keyword_service.analyze_keyword_clusters(
                [kw.keyword for kw in keywords]
            )
            
            return {
                'keywords': [asdict(kw) for kw in keywords],
                'cluster_analysis': cluster_analysis,
                'summary': {
                    'total_keywords': len(keywords),
                    'high_opportunity': len([kw for kw in keywords if kw.opportunity_score > 0.8]),
                    'avg_search_volume': np.mean([kw.search_volume for kw in keywords]) if keywords else 0
                }
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {e}")
            return {'error': str(e)}
    
    def _discover_competitors(self, request: DiscoveryRequest) -> Dict[str, Any]:
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"""
        try:
            domain = request.options.get('domain', 'example.com')
            competitors = self.competitor_service.discover_competitors(
                domain, 
                request.keywords
            )
            
            return {
                'competitors': [asdict(comp) for comp in competitors],
                'summary': {
                    'total_competitors': len(competitors),
                    'avg_market_share': np.mean([comp.market_share for comp in competitors]) if competitors else 0,
                    'total_estimated_budget': sum(comp.estimated_budget for comp in competitors)
                }
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†: {e}")
            return {'error': str(e)}
    
    def _comprehensive_discovery(self, request: DiscoveryRequest) -> Dict[str, Any]:
        """Ø§ÙƒØªØ´Ø§Ù Ø´Ø§Ù…Ù„"""
        try:
            # ØªÙ†ÙÙŠØ° Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§ÙƒØªØ´Ø§Ù
            results = {}
            
            if request.keywords:
                results['keywords'] = self._discover_keywords(request)
            
            if request.competitors:
                comp_request = DiscoveryRequest(
                    discovery_type=DiscoveryType.COMPETITORS,
                    keywords=request.keywords,
                    options={'domain': request.competitors[0] if request.competitors else 'example.com'}
                )
                results['competitors'] = self._discover_competitors(comp_request)
            
            return results
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø´Ø§Ù…Ù„: {e}")
            return {'error': str(e)}

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„Ø§ÙƒØªØ´Ø§Ù
discovery_manager = DiscoveryManager()

# ==================== Ù…Ø³Ø§Ø±Ø§Øª API ====================

@google_ads_discovery_bp.route('/health', methods=['GET'])
def discovery_health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø®Ø¯Ù…Ø© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù"""
    try:
        return jsonify({
            'success': True,
            'service': 'google_ads_discovery',
            'status': 'healthy',
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'libraries': {
                'jwt': JWT_LIBRARY,
                'bcrypt': BCRYPT_LIBRARY,
                'crypto': CRYPTO_LIBRARY
            },
            'services_status': SERVICES_STATUS,
            'cached_discoveries': len(discovery_manager.discovery_cache)
        })
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@google_ads_discovery_bp.route('/discover', methods=['POST'])
@jwt_required_discovery
def execute_discovery():
    """ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§ÙƒØªØ´Ø§Ù"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'Ø¨ÙŠØ§Ù†Ø§Øª JSON Ù…Ø·Ù„ÙˆØ¨Ø©'
            }), 400
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† JWT
        user_id = request.current_user.get('user_id', 'unknown')
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ Ø§Ù„Ø§ÙƒØªØ´Ø§Ù
        try:
            discovery_request = DiscoveryRequest(
                discovery_type=DiscoveryType(data.get('discovery_type', 'keywords')),
                customer_id=data.get('customer_id'),
                campaign_ids=data.get('campaign_ids', []),
                keywords=data.get('keywords', []),
                competitors=data.get('competitors', []),
                date_range=data.get('date_range', 'last_30_days'),
                filters=data.get('filters', {}),
                options=data.get('options', {})
            )
        except ValueError as e:
            return jsonify({
                'success': False,
                'error': f'Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø©: {str(e)}'
            }), 400
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ø§ÙƒØªØ´Ø§Ù
        result = discovery_manager.execute_discovery(discovery_request, user_id)
        
        if result['success']:
            return jsonify(result), 200
        else:
            return jsonify(result), 400
            
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø§ÙƒØªØ´Ø§Ù: {e}")
        return jsonify({
            'success': False,
            'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'
        }), 500

@google_ads_discovery_bp.route('/keywords/discover', methods=['POST'])
@jwt_required_discovery
def discover_keywords():
    """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'Ø¨ÙŠØ§Ù†Ø§Øª JSON Ù…Ø·Ù„ÙˆØ¨Ø©'
            }), 400
        
        seed_keywords = data.get('keywords', [])
        if not seed_keywords:
            return jsonify({
                'success': False,
                'error': 'ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø·Ù„ÙˆØ¨Ø©'
            }), 400
        
        options = data.get('options', {})
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        keywords = discovery_manager.keyword_service.discover_keywords(seed_keywords, options)
        
        return jsonify({
            'success': True,
            'keywords': [asdict(kw) for kw in keywords],
            'total_count': len(keywords)
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {e}")
        return jsonify({
            'success': False,
            'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'
        }), 500

@google_ads_discovery_bp.route('/competitors/discover', methods=['POST'])
@jwt_required_discovery
def discover_competitors():
    """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'Ø¨ÙŠØ§Ù†Ø§Øª JSON Ù…Ø·Ù„ÙˆØ¨Ø©'
            }), 400
        
        domain = data.get('domain')
        if not domain:
            return jsonify({
                'success': False,
                'error': 'Ø§Ù„Ù†Ø·Ø§Ù‚ Ù…Ø·Ù„ÙˆØ¨'
            }), 400
        
        keywords = data.get('keywords', [])
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†
        competitors = discovery_manager.competitor_service.discover_competitors(domain, keywords)
        
        return jsonify({
            'success': True,
            'competitors': [asdict(comp) for comp in competitors],
            'total_count': len(competitors)
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†: {e}")
        return jsonify({
            'success': False,
            'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'
        }), 500

@google_ads_discovery_bp.route('/test', methods=['GET'])
def test_discovery_service():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø¯Ù…Ø© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù"""
    try:
        # Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ù†Ø´Ø§Ø¡ token
        test_payload = {'user_id': 'test_user', 'role': 'admin', 'service': 'discovery'}
        test_token = discovery_security_manager.create_jwt_token(test_payload)
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† token
        verified_payload = discovery_security_manager.verify_jwt_token(test_token)
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ´ÙÙŠØ±
        test_data = "sensitive discovery data"
        encrypted_data = discovery_security_manager.encrypt_sensitive_data(test_data)
        decrypted_data = discovery_security_manager.decrypt_sensitive_data(encrypted_data)
        
        return jsonify({
            'success': True,
            'tests': {
                'jwt_creation': test_token is not None,
                'jwt_verification': verified_payload is not None,
                'jwt_payload_match': verified_payload.get('user_id') == 'test_user' if verified_payload else False,
                'jwt_service_match': verified_payload.get('service') == 'discovery' if verified_payload else False,
                'encryption': encrypted_data != test_data,
                'decryption': decrypted_data == test_data,
                'libraries': {
                    'jwt_available': JWT_AVAILABLE,
                    'bcrypt_available': BCRYPT_AVAILABLE,
                    'crypto_available': CRYPTO_AVAILABLE
                }
            },
            'message': 'Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª'
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø¯Ù…Ø© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ØªØ³Ø¬ÙŠÙ„ Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ­Ù…ÙŠÙ„
logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Google Ads Discovery Blueprint Ø¨Ù†Ø¬Ø§Ø­")
logger.info(f"ğŸ” Ø§Ù„Ø£Ù…Ø§Ù†: JWT={JWT_AVAILABLE}, bcrypt={BCRYPT_AVAILABLE}, crypto={CRYPTO_AVAILABLE}")
logger.info(f"ğŸ“Š Ø§Ù„Ø®Ø¯Ù…Ø§Øª: {sum(SERVICES_STATUS.values())}/7 Ù…ØªØ§Ø­Ø©")

# ØªØµØ¯ÙŠØ± Blueprint
__all__ = ['google_ads_discovery_bp', 'discovery_manager', 'discovery_security_manager']

