#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
AI Content Generation Service for Ad Copy
"""

import os
import requests
import logging
import json
import re
from typing import Dict, List, Any, Optional
from datetime import datetime
import sys
from dotenv import load_dotenv

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Ù…Ù„Ù .env.development
load_dotenv(dotenv_path=os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env.development'))

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± backend Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
backend_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(backend_path)

from cometapi_config import CometAPIConfig

logger = logging.getLogger(__name__)

# Ø¯Ø§Ù„Ø© Ø¹Ø§Ù…Ø© Ù„Ø¥Ø²Ø§Ù„Ø© Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ (Google Ads Policy)
def remove_phone_numbers(text: str) -> str:
    """Ø¥Ø²Ø§Ù„Ø© Ø¬Ù…ÙŠØ¹ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ù…Ù† Ø§Ù„Ù†Øµ Ù„ØªØ¬Ù†Ø¨ Ø§Ù†ØªÙ‡Ø§Ùƒ Ø³ÙŠØ§Ø³Ø§Øª Google Ads"""
    if not text:
        return text
    
    # Ø£Ù†Ù…Ø§Ø· Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    patterns = [
        r'\b0\d{9,10}\b',  # Ø£Ø±Ù‚Ø§Ù… Ù…Ø­Ù„ÙŠØ© Ù…Ø«Ù„ 0558038312
        r'\b\+?\d{10,15}\b',  # Ø£Ø±Ù‚Ø§Ù… Ø¯ÙˆÙ„ÙŠØ©
        r'\b\d{3}[-.\s]?\d{3}[-.\s]?\d{4}\b',  # 555-123-4567
        r'\b\d{4}[-.\s]?\d{3}[-.\s]?\d{3}\b',  # 0555-123-456
        r'\(\d{3}\)[-.\s]?\d{3}[-.\s]?\d{4}\b',  # (555) 123-4567
    ]
    
    cleaned_text = text
    for pattern in patterns:
        cleaned_text = re.sub(pattern, '', cleaned_text)
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
    
    return cleaned_text

class AIContentGenerator:
    """Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        self.api_key = os.getenv("COMETAPI_API_KEY")
        self.base_url = os.getenv("COMETAPI_BASE_URL", "https://api.cometapi.com")
        self.text_model = os.getenv("TEXT_MODEL", "gpt-4o-mini")
        self.image_model = os.getenv("IMAGE_MODEL", "black-forest-labs/flux-1.1-pro-ultra")  # Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù„ÙˆØ§Ù‚Ø¹ÙŠØ© Ø§Ù„Ù…Ø·Ù„Ù‚Ø©
        
        # Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© Ù†Ù…ÙˆØ°Ø¬ llama-2-7b-chat ØºÙŠØ± Ø§Ù„Ù…ØªÙˆÙØ±
        if self.text_model == "llama-2-7b-chat":
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø±Ø®Øµ Ù†Ù…ÙˆØ°Ø¬ GPT (Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªÙƒÙ„ÙØ©)
            self.text_model = "gpt-4o-mini"  # $0.00015/1K tokens - Ø£Ø±Ø®Øµ GPT ÙˆØ£ÙØ¶Ù„ Ù„Ù„Ø£Ø¯Ø§Ø¡
            logger.warning(f"âš ï¸ Ù†Ù…ÙˆØ°Ø¬ llama-2-7b-chat ØºÙŠØ± Ù…ØªÙˆÙØ±ØŒ ØªÙ… Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ {self.text_model} (Ø£Ø±Ø®Øµ GPT ÙˆØ£ÙØ¶Ù„ Ù„Ù„Ø£Ø¯Ø§Ø¡)")
        
        if not self.api_key:
            raise ValueError("COMETAPI_API_KEY environment variable not set")
        
        # ØªÙ‡ÙŠØ¦Ø© Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª CometAPI
        self.logger = logging.getLogger(__name__)
        try:
            self.cometapi_config = CometAPIConfig()
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            self.cometapi_base_url = self.base_url
            self.cometapi_headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            self.logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ù…Ø¹ CometAPI")
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© CometAPI: {e}")
            self.cometapi_config = None
            self.cometapi_base_url = self.base_url
            self.cometapi_headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
    
    def get_campaign_image_requirements(self) -> Dict[str, Dict[str, Any]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØµÙˆØ± Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø©"""
        return {
                   "SEARCH": {
                       "required": True,
                       "min_images": 4,
                       "max_images": 4,
                       "images": {
                           "square_image": {
                               "size": "1200Ã—1200",
                               "aspect_ratio": "1:1",
                               "min_size": "300Ã—300",
                               "max_file_size": "5120 KB",
                               "formats": ["JPEG", "PNG"],
                               "field_type": "AD_IMAGE",
                               "description": "ØµÙˆØ±Ø© Ù…Ø±Ø¨Ø¹Ø© Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†"
                           },
                           "landscape_image": {
                               "size": "1200Ã—628",
                               "aspect_ratio": "1.91:1",
                               "min_size": "600Ã—314",
                               "max_file_size": "5120 KB",
                               "formats": ["JPEG", "PNG"],
                               "field_type": "AD_IMAGE",
                               "description": "ØµÙˆØ±Ø© Ø£ÙÙ‚ÙŠØ© Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†"
                           }
                       }
                   },
            "PERFORMANCE_MAX": {
                "required": True,
                "min_images": 4,
                "max_images": 4,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    },
                    "logo": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "LOGO",
                        "description": "Ø´Ø¹Ø§Ø± Ø§Ù„Ø¹Ù…Ù„"
                    },
                    "landscape_logo": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "LANDSCAPE_LOGO",
                        "description": "Ø´Ø¹Ø§Ø± Ø£ÙÙ‚ÙŠ"
                    }
                }
            },
            "DISPLAY": {
                "required": True,
                "min_images": 5,
                "max_images": 5,
                "images": {
                    "medium_rectangle": {
                        "size": "300Ã—250",
                        "aspect_ratio": "1.2:1",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù…Ø³ØªØ·ÙŠÙ„ Ù…ØªÙˆØ³Ø·"
                    },
                    "leaderboard": {
                        "size": "728Ã—90",
                        "aspect_ratio": "8.09:1",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù„ÙˆØ­Ø© Ø§Ù„Ù…ØªØµØ¯Ø±ÙŠÙ†"
                    },
                    "wide_skyscraper": {
                        "size": "160Ã—600",
                        "aspect_ratio": "1:3.75",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù†Ø§Ø·Ø­Ø© Ø³Ø­Ø§Ø¨ Ø¹Ø±ÙŠØ¶Ø©"
                    },
                    "large_rectangle": {
                        "size": "336Ã—280",
                        "aspect_ratio": "1.2:1",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù…Ø³ØªØ·ÙŠÙ„ ÙƒØ¨ÙŠØ±"
                    },
                    "half_page": {
                        "size": "300Ã—600",
                        "aspect_ratio": "1:2",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù†ØµÙ ØµÙØ­Ø©"
                    }
                }
            },
            "VIDEO": {
                "required": True,
                "min_images": 2,
                "max_images": 2,
                "images": {
                    "hd_thumbnail": {
                        "size": "1280Ã—720",
                        "aspect_ratio": "16:9",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "ØµÙˆØ±Ø© Ù…ØµØºØ±Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¯Ù‚Ø©"
                    },
                    "sd_thumbnail": {
                        "size": "640Ã—360",
                        "aspect_ratio": "16:9",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "ØµÙˆØ±Ø© Ù…ØµØºØ±Ø© Ø¹Ø§Ø¯ÙŠØ© Ø§Ù„Ø¯Ù‚Ø©"
                    }
                }
            },
            "SHOPPING": {
                "required": True,
                "min_images": 1,
                "max_images": 1000,
                "images": {
                    "product_images": {
                        "recommended_size": "800Ã—800",
                        "min_size": "250Ã—250",
                        "max_file_size": "16 MB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "ØµÙˆØ± Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª - Ø¹Ø¯Ø¯ ÙØ±ÙŠØ¯ Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª"
                    }
                }
            },
            "SMART": {
                "required": True,
                "min_images": 2,
                "max_images": 2,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    }
                }
            },
            "LOCAL": {
                "required": True,
                "min_images": 2,
                "max_images": 2,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    }
                }
            },
            "DEMAND_GEN": {
                "required": True,
                "min_images": 3,
                "max_images": 3,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    },
                    "logo": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "LOGO",
                        "description": "Ø´Ø¹Ø§Ø± Ø§Ù„Ø¹Ù…Ù„"
                    }
                }
            },
                   "HOTEL": {
                       "required": False,
                       "description": "Ù„Ø§ ØªØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§ - ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙ†Ø§Ø¯Ù‚ ÙˆØ§Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ù† Hotel Center"
                   },
            "TRAVEL": {
                "required": True,
                "min_images": 2,
                "max_images": 2,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    }
                }
            },
            "DEMAND_GEN": {
                "required": True,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"]
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"]
                    }
                }
            },
            "LOCAL_SERVICES": {
                "required": False,
                "min_images": 0,
                "max_images": 0,
                "description": "Ù„Ø§ ØªØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§ - ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø© ÙˆØ§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ù† Local Services"
            },
            "MULTI_CHANNEL": {
                "required": True,
                "min_images": 3,
                "max_images": 3,
                "images": {
                    "app_icon": {
                        "size": "320Ã—50",
                        "aspect_ratio": "6.4:1",
                        "max_file_size": "150 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "Ø£ÙŠÙ‚ÙˆÙ†Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"
                    },
                    "app_screenshot": {
                        "size": "480Ã—320",
                        "aspect_ratio": "1.5:1",
                        "max_file_size": "150 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù„Ù‚Ø·Ø© Ø´Ø§Ø´Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"
                    },
                    "app_banner": {
                        "size": "320Ã—480",
                        "aspect_ratio": "2:3",
                        "max_file_size": "150 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "Ø¨Ø§Ù†Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"
                    }
                }
            }
        }
    
    def _get_ad_copy_prompts(self, language: str = 'Arabic') -> Dict[str, str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨Ø±ÙˆÙ…Ø¨ØªØ§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© (Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©)"""
        
        # Language-specific instructions
        language_instructions = {
            'Arabic': 'Write in Arabic language. Use Arabic action words.',
            'English': 'Write in English language. Use compelling English action words.',
            'French': 'Write in French language. Use compelling French action words.',
            'German': 'Write in German language. Use compelling German action words.',
            'Spanish': 'Write in Spanish language. Use compelling Spanish action words.',
            'Italian': 'Write in Italian language. Use compelling Italian action words.',
            'Portuguese': 'Write in Portuguese language. Use compelling Portuguese action words.',
            'Russian': 'Write in Russian language. Use compelling Russian action words.',
            'Chinese (simplified)': 'Write in Simplified Chinese language.',
            'Chinese (traditional)': 'Write in Traditional Chinese language.',
            'Japanese': 'Write in Japanese language.',
            'Korean': 'Write in Korean language.',
            'Hindi': 'Write in Hindi language.',
            'Turkish': 'Write in Turkish language.',
            'Dutch': 'Write in Dutch language.',
            'Polish': 'Write in Polish language.',
            'Swedish': 'Write in Swedish language.',
            'Thai': 'Write in Thai language.',
            'Vietnamese': 'Write in Vietnamese language.',
        }
        
        lang_instruction = language_instructions.get(language, f'Write in {language} language.')
        
        return {
            "headlines": f"""
You are an expert in writing Google Ads headlines. Write 5 professional headlines for the following product/service:

Product/Service: {{product_service}}
Website: {{website_url}}
Website Content: {{website_content}}

IMPORTANT LANGUAGE REQUIREMENT:
{lang_instruction}
ALL headlines MUST be written in {language} language.

Requirements:
- Each headline maximum 30 characters
- Include key benefit
- Clear and honest (Google Ads compliant)
- Compelling and persuasive
- Suitable for {language} speaking audience

Return results in JSON format:
{{{{
    "headlines": [
        "First headline in {language}",
        "Second headline in {language}",
        "Third headline in {language}",
        "Fourth headline in {language}",
        "Fifth headline in {language}"
    ]
}}}}
""",
            "descriptions": f"""
You are an expert in writing Google Ads descriptions. Write 5 professional descriptions for the following product/service:

Product/Service: {{product_service}}
Website: {{website_url}}
Website Content: {{website_content}}

IMPORTANT LANGUAGE REQUIREMENT:
{lang_instruction}
ALL descriptions MUST be written in {language} language.

Requirements:
- Each description maximum 90 characters
- Clearly explain key benefit
- Include clear call-to-action
- Avoid misleading claims
- Google Ads compliant
- Compelling and attractive
- Suitable for {language} speaking audience

Return results in JSON format:
{{{{
    "descriptions": [
        "First description in {language}",
        "Second description in {language}",
        "Third description in {language}",
        "Fourth description in {language}",
        "Fifth description in {language}"
    ]
}}}}
""",
            "keywords": f"""
You are an expert in Google Ads keyword research. Suggest 20 keywords for the following product/service:

Product/Service: {{product_service}}
Website: {{website_url}}
Website Content: {{website_content}}

IMPORTANT LANGUAGE REQUIREMENT:
{lang_instruction}
ALL keywords MUST be in {language} language.

Requirements:
- Keywords relevant to product/service
- Suitable for {language} speaking audience
- Include long-tail keywords
- Include short direct keywords
- Suitable for Google Ads campaigns
- Varied phrasing

Return results in JSON format:
{{{{
    "keywords": [
        "First keyword in {language}",
        "Second keyword in {language}",
        "Third keyword in {language}",
        ...
    ]
}}}}
""",
            "campaign_type": """
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨. Ø­Ù„Ù„ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ§Ù‚ØªØ±Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©:

Ø§Ù„Ù…Ù†ØªØ¬/Ø§Ù„Ø®Ø¯Ù…Ø©: {product_service}
Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ: {website_url}
Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {website_content}

Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø­Ù…Ù„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
- search_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¨Ø­Ø«
- display_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©
- video_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
- shopping_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„ØªØ³ÙˆÙ‚
- performance_max: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ù‚ØµÙ‰
- app_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª
- call_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª

Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ JSON:
{{
    "recommended_campaign_type": "Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­",
    "confidence_score": 85,
    "reasoning": "Ø§Ù„Ø³Ø¨Ø¨ ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹",
    "alternative_types": ["Ù†ÙˆØ¹ Ø¨Ø¯ÙŠÙ„ 1", "Ù†ÙˆØ¹ Ø¨Ø¯ÙŠÙ„ 2"]
}}
""",
            "color_analysis": """
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©. Ø­Ù„Ù„ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:

Ø§Ù„Ù…Ù†ØªØ¬/Ø§Ù„Ø®Ø¯Ù…Ø©: {product_service}
Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ: {website_url}
Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {website_content}

Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ JSON:
{{
    "primary_color": "#1A1A1A",
    "secondary_color": "#00BFA5",
    "accent_color": "#FF6B6B",
    "text_color": "#FFFFFF",
    "background_color": "#1A1A1A",
    "color_palette": ["#1A1A1A", "#00BFA5", "#FF6B6B", "#FFFFFF"],
    "brand_style": "modern, clean, professional"
}}
"""
        }
    
    def _fetch_website_content(self, website_url: str) -> str:
        """Fetch website content with www fallback"""
        try:
            from urllib.parse import urlparse
            
            # Add https:// if no scheme provided
            if not website_url.startswith(('http://', 'https://')):
                website_url = f'https://{website_url}'
            
            self.logger.info(f"Fetching website content: {website_url}")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'ar-SA,ar;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            }
            
            # Try to fetch with www fallback
            urls_to_try = [website_url]
            parsed = urlparse(website_url)
            if not parsed.netloc.startswith('www.'):
                www_url = f"{parsed.scheme}://www.{parsed.netloc}{parsed.path}"
                if parsed.query:
                    www_url += f"?{parsed.query}"
                urls_to_try.append(www_url)
            
            response = None
            for url_attempt in urls_to_try:
                try:
                    self.logger.info(f"ğŸ”— Trying: {url_attempt}")
                    response = requests.get(url_attempt, headers=headers, timeout=30)
                    if response.status_code == 200:
                        self.logger.info(f"âœ… Successfully fetched: {url_attempt}")
                        break
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Failed {url_attempt}: {e}")
                    continue
            
            if not response or response.status_code != 200:
                raise Exception("Could not fetch website from any URL variant")
            
            # Extract text from HTML
            html_content = response.text
            text_content = self._extract_text_from_html(html_content)
            
            # Limit content to reduce cost (first 3000 chars)
            text_content = text_content[:3000]
            
            self.logger.info(f"Successfully fetched website content: {len(text_content)} chars")
            return text_content
                
        except Exception as e:
            self.logger.error(f"Error fetching website content: {e}")
            return ""
    
    def _extract_text_from_html(self, html_content: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ HTML"""
        import re
        
        # Ø¥Ø²Ø§Ù„Ø© script Ùˆ style tags
        clean = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL)
        clean = re.sub(r'<style[^>]*>.*?</style>', '', clean, flags=re.DOTALL)
        
        # Ø¥Ø²Ø§Ù„Ø© HTML tags
        clean = re.sub(r'<[^>]+>', ' ', clean)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        clean = re.sub(r'\s+', ' ', clean)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ©
        clean = re.sub(r'[^\w\s\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF]', ' ', clean)
        
        return clean.strip()
    
    def _get_best_model_for_task(self, task_type: str) -> str:
        """Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©"""
        model_mapping = {
            "website_analysis": "claude-3-5-haiku-20241022",  # Ø³Ø±ÙŠØ¹ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹
            "ad_copy_generation": "qwen-2.5-7b-instruct",     # Ù…Ù…ØªØ§Ø² Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
            "keyword_extraction": "gpt-4o-mini",              # Ø£Ø±Ø®Øµ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
            "content_optimization": "gpt-4o-mini",            # Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            "arabic_content": "qwen-2.5-7b-instruct",         # Ø¬ÙŠØ¯ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
            "multilingual": "gemini-2.0-flash-exp",           # Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª
            "creative": "claude-3-5-sonnet-20241022",         # Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ
            "budget": "qwen-2.5-7b-instruct",                 # Ø£Ø±Ø®Øµ
            "premium": "gpt-4o"                               # Ø£ÙØ¶Ù„ Ø¬ÙˆØ¯Ø©
        }
        return model_mapping.get(task_type, self.text_model)
    
    def _call_cometapi(self, prompt: str, task_type: str = "general") -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.text_model,
                "messages": [
                    {
                        "role": "system",
                        "content": """You are a Google Ads expert specializing in high-converting ad copy. 

KEY REQUIREMENTS:
1. Generate exactly 30 headlines (max 30 characters each)
2. Generate exactly 4 descriptions (60-90 characters each - MINIMUM 60 chars)
3. EVERY description MUST end with a strong Call-to-Action (CTA) appropriate for the industry

DESCRIPTION BEST PRACTICES:
- Length: 60-90 characters (use full space available)
- Structure: [Value Proposition] + [Key Benefit] + [Industry-Specific CTA]
- CTA must match the business type and keywords (e.g., booking services use "Ø§Ø­Ø¬Ø² Ø§Ù„Ø¢Ù†", e-commerce uses "ØªØ³ÙˆÙ‚ Ø§Ù„Ø¢Ù†", professional services use "Ø§ØªØµÙ„ Ø¨Ù†Ø§")
- Include numbers, guarantees, or urgency when relevant to the industry
- Focus on benefits, not just features

HEADLINE BEST PRACTICES:
- Use numbers and percentages when relevant to the business
- Include location when provided in keywords
- Add urgency elements appropriate to the industry
- Use power words that match the business tone
- Focus on unique selling propositions and benefits

Base ALL content on the keywords from Google Keyword Planner and adapt to the specific industry."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 2000,
                "temperature": 0.5,
                "top_p": 0.9
            }
            
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    content = result["choices"][0]["message"]["content"]
                    return {
                        "success": True,
                        "content": content
                    }
                else:
                    return {
                        "success": False,
                        "error": "No content generated"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© JSON"""
        try:
            import json
            import re
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø£ÙˆÙ„Ø§Ù‹
            content = content.strip()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† JSON ÙÙŠ Ø§Ù„Ù†Øµ - ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø­Ø«
            json_patterns = [
                r'\{.*\}',  # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† JSON Ø¹Ø§Ø¯ÙŠ
                r'```json\s*(\{.*?\})\s*```',  # JSON ÙÙŠ code blocks
                r'```\s*(\{.*?\})\s*```',  # JSON ÙÙŠ code blocks Ø¨Ø¯ÙˆÙ† json
            ]
            
            for pattern in json_patterns:
                matches = re.findall(pattern, content, re.DOTALL)
                if matches:
                    json_str = matches[0] if isinstance(matches[0], str) else matches[0]
                    try:
                        return json.loads(json_str)
                    except json.JSONDecodeError:
                        continue
            
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ JSONØŒ Ø­Ø§ÙˆÙ„ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ù‚ÙˆØ§Ø³
            start = content.find('{')
            end = content.rfind('}') + 1
            
            if start != -1 and end != -1 and end > start:
                json_str = content[start:end]
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ JSON Ø¨Ø³ÙŠØ·
                    json_str = self._fix_json_format(json_str)
                    return json.loads(json_str)
            
            # Ø¥Ø°Ø§ ÙØ´Ù„ ÙƒÙ„ Ø´ÙŠØ¡ØŒ Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
            return self._create_fallback_response(content)
                
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON: {e}")
            return {"error": f"JSON parsing error: {str(e)}"}
    
    def _fix_json_format(self, json_str: str) -> str:
        """Ø¥ØµÙ„Ø§Ø­ ØªÙ†Ø³ÙŠÙ‚ JSON Ø§Ù„Ø¨Ø³ÙŠØ·"""
        try:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
            json_str = json_str.strip()
            
            # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
            json_str = json_str.replace("'", '"')  # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙØ±Ø¯Ø©
            json_str = re.sub(r',\s*}', '}', json_str)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ø£Ø®ÙŠØ±Ø©
            json_str = re.sub(r',\s*]', ']', json_str)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù…Ù† Ø§Ù„Ù…ØµÙÙˆÙØ§Øª
            
            return json_str
        except Exception:
            return json_str
    
    def _create_fallback_response(self, content: str) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¹Ù†Ø¯ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ JSON"""
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© Ù…Ù† Ø§Ù„Ù†Øµ
            headlines = []
            descriptions = []
            keywords = []
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù†Ø§ÙˆÙŠÙ†
            headline_patterns = [
                r'Ø¹Ù†ÙˆØ§Ù†[:\s]*([^\n]+)',
                r'headline[:\s]*([^\n]+)',
                r'Ø§Ù„Ø¹Ù†ÙˆØ§Ù†[:\s]*([^\n]+)'
            ]
            
            for pattern in headline_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                headlines.extend(matches[:5])  # Ø£ÙˆÙ„ 5 Ø¹Ù†Ø§ÙˆÙŠÙ†
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆØµØ§Ù
            desc_patterns = [
                r'ÙˆØµÙ[:\s]*([^\n]+)',
                r'description[:\s]*([^\n]+)',
                r'Ø§Ù„ÙˆØµÙ[:\s]*([^\n]+)'
            ]
            
            for pattern in desc_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                descriptions.extend(matches[:3])  # Ø£ÙˆÙ„ 3 Ø£ÙˆØµØ§Ù
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
            keyword_patterns = [
                r'ÙƒÙ„Ù…Ø©[:\s]*([^\n]+)',
                r'keyword[:\s]*([^\n]+)',
                r'Ø§Ù„ÙƒÙ„Ù…Ø©[:\s]*([^\n]+)'
            ]
            
            for pattern in keyword_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                keywords.extend(matches[:10])  # Ø£ÙˆÙ„ 10 ÙƒÙ„Ù…Ø§Øª
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
            response = {}
            if headlines:
                response['headlines'] = headlines
            if descriptions:
                response['descriptions'] = descriptions
            if keywords:
                response['keywords'] = keywords
            
            # Ø¥Ø¶Ø§ÙØ© Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
            if 'search' in content.lower() or 'Ø¨Ø­Ø«' in content:
                response['recommended_campaign_type'] = 'search_ads'
            elif 'display' in content.lower() or 'Ø¹Ø±Ø¶' in content:
                response['recommended_campaign_type'] = 'display_ads'
            else:
                response['recommended_campaign_type'] = 'search_ads'
            
            response['confidence_score'] = 60
            response['reasoning'] = 'ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ'
            
            return response
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
            return {
                'error': 'ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©',
                'headlines': ['Ø¹Ù†ÙˆØ§Ù† Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ø­ØªÙŠØ§Ø·ÙŠ'],
                'descriptions': ['ÙˆØµÙ Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ø­ØªÙŠØ§Ø·ÙŠ'],
                'keywords': ['ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©'],
                'recommended_campaign_type': 'search_ads',
                'confidence_score': 50
            }
    
    def generate_headlines(self, product_service: str, website_url: str, language: str = 'Arabic') -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©"""
        try:
            self.logger.info(f"ğŸ“ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ù„Ù„Ù…Ù†ØªØ¬: {product_service} Ø¨Ø§Ù„Ù„ØºØ©: {language}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª (Ù…Ø¹ Ø§Ù„Ù„ØºØ©)
            prompts = self._get_ad_copy_prompts(language=language)
            prompt = prompts["headlines"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "headlines" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(parsed_response['headlines'])} Ø¹Ù†ÙˆØ§Ù†")
                    return {
                        "success": True,
                        "headlines": parsed_response["headlines"],
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No headlines found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†"
            }
    
    def generate_descriptions(self, product_service: str, website_url: str, language: str = 'Arabic') -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©"""
        try:
            self.logger.info(f"ğŸ“ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù Ù„Ù„Ù…Ù†ØªØ¬: {product_service} Ø¨Ø§Ù„Ù„ØºØ©: {language}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª (Ù…Ø¹ Ø§Ù„Ù„ØºØ©)
            prompts = self._get_ad_copy_prompts(language=language)
            prompt = prompts["descriptions"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "descriptions" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(parsed_response['descriptions'])} ÙˆØµÙ")
                    return {
                        "success": True,
                        "descriptions": parsed_response["descriptions"],
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No descriptions found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù"
            }
    
    def generate_keywords(self, product_service: str, website_url: str, language: str = 'Arabic') -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©"""
        try:
            self.logger.info(f"ğŸ”‘ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ù…Ù†ØªØ¬: {product_service} Ø¨Ø§Ù„Ù„ØºØ©: {language}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª (Ù…Ø¹ Ø§Ù„Ù„ØºØ©)
            prompts = self._get_ad_copy_prompts(language=language)
            prompt = prompts["keywords"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "keywords" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(parsed_response['keywords'])} ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ©")
                    return {
                        "success": True,
                        "keywords": parsed_response["keywords"],
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No keywords found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"
            }
    
    def suggest_campaign_type(self, product_service: str, website_url: str) -> Dict[str, Any]:
        """Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©"""
        try:
            self.logger.info(f"ğŸ¯ Ø¨Ø¯Ø¡ Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ù„Ù„Ù…Ù†ØªØ¬: {product_service}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
            prompts = self._get_ad_copy_prompts()
            prompt = prompts["campaign_type"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "recommended_campaign_type" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©: {parsed_response['recommended_campaign_type']}")
                    return {
                        "success": True,
                        "recommended_campaign_type": parsed_response["recommended_campaign_type"],
                        "confidence_score": parsed_response.get("confidence_score", 0),
                        "reasoning": parsed_response.get("reasoning", ""),
                        "alternative_types": parsed_response.get("alternative_types", []),
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No campaign type found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©"
            }
    
    def analyze_website_colors(self, product_service: str, website_url: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ"""
        try:
            self.logger.info(f"ğŸ¨ Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹: {website_url}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
            prompts = self._get_ad_copy_prompts()
            prompt = prompts["color_analysis"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "primary_color" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹")
                    return {
                        "success": True,
                        "colors": {
                            "primary": parsed_response.get("primary_color", "#1A1A1A"),
                            "secondary": parsed_response.get("secondary_color", "#00BFA5"),
                            "accent": parsed_response.get("accent_color", "#FF6B6B"),
                            "text": parsed_response.get("text_color", "#FFFFFF"),
                            "background": parsed_response.get("background_color", "#1A1A1A")
                        },
                        "color_palette": parsed_response.get("color_palette", []),
                        "brand_style": parsed_response.get("brand_style", "modern, clean, professional"),
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No colors found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹"
            }
    
    def _get_campaign_requirements(self, campaign_type: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Google Ads Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø©"""
        requirements = {
            "SEARCH": "Headlines: 3-15 (max 30 chars each), Descriptions: 2-4 (max 90 chars each)",
            "DISPLAY": "Headlines: 5 short (max 30 chars), Descriptions: 5 long (max 90 chars), Images required",
            "VIDEO": "Headlines: 5 (max 30 chars), Descriptions: 5 (max 90 chars), Video required",
            "SHOPPING": "Product title, description, price, images",
            "PERFORMANCE_MAX": "Headlines: 3-15 (max 30 chars), Descriptions: 2-5 (max 90 chars), Images: 3-20",
            "DEMAND_GEN": "Headlines: 5 (max 40 chars), Descriptions: 5 (max 90 chars), Images required",
            "APP": "Headlines: 4 (max 30 chars), Descriptions: 4 (max 90 chars)",
            "LOCAL": "Business name, address, phone, headlines, descriptions",
            "SMART": "Headlines: 3 (max 30 chars), Descriptions: 2 (max 90 chars)",
            "HOTEL": "Hotel name, price, images, descriptions",
            "TRAVEL": "Headlines, descriptions, destination info, images"
        }
        return requirements.get(campaign_type.upper(), requirements["DISPLAY"])
    
    def generate_complete_ad_content(self, product_service: str, website_url: str, service_type: str = None, target_language: str = "ar", website_content: str = None, campaign_type: str = "DISPLAY", keywords_list: list = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© ÙˆØªØ¹Ù„ÙŠÙ…Ø§Øª Google Ads"""
        try:
            self.logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ - Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©: {campaign_type}")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… website_content Ø¥Ø°Ø§ ØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡ØŒ ÙˆØ¥Ù„Ø§ Ø¬Ù„Ø¨Ù‡
            if not website_content:
                website_content = self._fetch_website_content(website_url)
            else:
                self.logger.info(f"âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ù…Ø±Ø±: {len(website_content)} Ø­Ø±Ù")

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ù…Ø±Ø±Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
            keywords_line = ""
            if keywords_list and len(keywords_list) > 0:
                keywords_line = ', '.join(keywords_list)
                print(f"âœ… ØªÙ… Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ {len(keywords_list)} ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Google!")
                print(f"âœ… Ø£ÙˆÙ„ 5 ÙƒÙ„Ù…Ø§Øª: {keywords_list[:5]}")
            else:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡Ø§ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙƒÙ†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
                if "Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Google:" in website_content:
                    keywords_line = website_content.split("Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Google:")[1].split("\n")[0].strip()
                    print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ: {keywords_line[:200]}")
                elif "Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©:" in website_content:
                    keywords_line = website_content.split("Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©:")[1].split("\n")[0].strip()
                    print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {keywords_line[:200]}")
                else:
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù†ÙØ³Ù‡ ÙƒÙ€ fallback
                    print("âš ï¸ No keywords provided - extracting from website content...")
                    import re
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø·ÙˆÙŠÙ„Ø© (Ø£ÙƒØ«Ø± Ù…Ù† 3 Ø£Ø­Ø±Ù)
                    arabic_words = re.findall(r'[\u0600-\u06FF]{4,}', website_content)
                    # Ø£Ø®Ø° Ø£ÙƒØ«Ø± 10 ÙƒÙ„Ù…Ø§Øª ØªÙƒØ±Ø§Ø±Ø§Ù‹
                    from collections import Counter
                    word_counts = Counter(arabic_words)
                    top_keywords = [word for word, count in word_counts.most_common(10)]
                    if top_keywords:
                        keywords_line = ', '.join(top_keywords)
                        print(f"âœ… Extracted {len(top_keywords)} keywords from website content: {top_keywords[:5]}")
                    else:
                        # Ø¢Ø®Ø± fallback - ÙƒÙ„Ù…Ø§Øª Ø¹Ø§Ù…Ø©
                        keywords_line = "Ù…Ù†ØªØ¬Ø§Øª, Ø®Ø¯Ù…Ø§Øª, Ø¹Ø±ÙˆØ¶, Ø¬ÙˆØ¯Ø©, Ø£Ø³Ø¹Ø§Ø±"
                        print(f"âš ï¸ Using default fallback keywords")
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Google Ads Ù„Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©
            campaign_requirements = self._get_campaign_requirements(campaign_type)
            
            # Convert language code to language name
            language_map = {
                'ar': 'Arabic', 'en': 'English', 'fr': 'French', 'de': 'German', 
                'es': 'Spanish', 'it': 'Italian', 'pt': 'Portuguese', 'ru': 'Russian',
                'zh-CN': 'Chinese (simplified)', 'zh-TW': 'Chinese (traditional)',
                'ja': 'Japanese', 'ko': 'Korean', 'hi': 'Hindi', 'tr': 'Turkish',
                'nl': 'Dutch', 'pl': 'Polish', 'sv': 'Swedish', 'th': 'Thai',
                'vi': 'Vietnamese', 'bn': 'Bengali', 'bg': 'Bulgarian', 'ca': 'Catalan',
                'cs': 'Czech', 'da': 'Danish', 'et': 'Estonian', 'fil': 'Filipino',
                'fi': 'Finnish', 'el': 'Greek', 'gu': 'Gujarati', 'he': 'Hebrew',
                'hu': 'Hungarian', 'is': 'Icelandic', 'id': 'Indonesian', 'kn': 'Kannada',
                'lv': 'Latvian', 'lt': 'Lithuanian', 'ms': 'Malay', 'ml': 'Malayalam',
                'mr': 'Marathi', 'no': 'Norwegian', 'fa': 'Persian', 'ro': 'Romanian',
                'sr': 'Serbian', 'sk': 'Slovak', 'sl': 'Slovenian', 'ta': 'Tamil',
                'te': 'Telugu', 'uk': 'Ukrainian', 'ur': 'Urdu'
            }
            
            language_name = language_map.get(target_language, 'English')
            self.logger.info(f"ğŸŒ Generating content in {language_name} (code: {target_language})")
            
            # Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù† Google
            comprehensive_prompt = f"""
Create professional Google Ads content based on these keywords from Google Keyword Planner.

Campaign Type: {campaign_type}
Website URL: {website_url}

KEYWORDS FROM GOOGLE KEYWORD PLANNER:
{keywords_line}

Website Content:
{website_content}

Google Ads Requirements for {campaign_type}:
{campaign_requirements}

REQUIREMENTS:

**HEADLINES (30 characters max):**
- Generate EXACTLY 30 unique headlines
- Analyze the keywords to understand the industry and target audience
- Use relevant numbers, percentages, and industry-specific power words
- Include location if present in keywords
- Create headlines that match the business type and tone
- Mix of: service/product names, benefits, urgency, credibility elements

**DESCRIPTIONS (60-90 characters - CRITICAL):**
- Generate EXACTLY 4 descriptions
- Length: MINIMUM 60 characters, MAXIMUM 90 characters
- MANDATORY: Each description MUST end with a Call-to-Action (CTA)
- Structure: [Value/Benefit] + [Key Feature] + [Industry-Appropriate CTA]
- The CTA must be relevant to the business type identified from keywords
- Analyze keywords to determine appropriate CTAs (booking, purchasing, contacting, registering, etc.)
- Use full character space (60-90 chars)

CRITICAL LANGUAGE REQUIREMENT:
ALL content (headlines, descriptions, keywords) MUST be written in {language_name} language.
Use {language_name} professional, persuasive, industry-appropriate tone.

Return VALID JSON:
{{
    "headlines": ["headline 1", "headline 2", "headline 3", "headline 4", "headline 5", "headline 6", "headline 7", "headline 8", "headline 9", "headline 10", "headline 11", "headline 12", "headline 13", "headline 14", "headline 15", "headline 16", "headline 17", "headline 18", "headline 19", "headline 20", "headline 21", "headline 22", "headline 23", "headline 24", "headline 25", "headline 26", "headline 27", "headline 28", "headline 29", "headline 30"],
    "descriptions": ["description 1 (60-90 chars with CTA)", "description 2 (60-90 chars with CTA)", "description 3 (60-90 chars with CTA)", "description 4 (60-90 chars with CTA)"],
    "keywords": {keywords_line.split(',') if keywords_line else []},
    "recommended_campaign_type": "{campaign_type.lower()}",
    "confidence_score": 95,
    "reasoning": "Created content based on Google keywords with industry-appropriate CTAs",
    "colors": {{"primary": "#hex", "secondary": "#hex", "accent": "#hex"}},
    "color_palette": ["#hex1", "#hex2", "#hex3"],
    "brand_style": "modern professional"
            }}
            """
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            print("=" * 80)
            print("ğŸ¤– Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù…Ø±Ø³Ù„ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:")
            print("=" * 80)
            print(comprehensive_prompt[:500] + "..." if len(comprehensive_prompt) > 500 else comprehensive_prompt)
            print("=" * 80)
            
            # Ø·Ù„Ø¨ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ù…
            ai_response = self._call_cometapi(comprehensive_prompt)
            
            if ai_response.get("success"):
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© ØªØ­Ù„ÙŠÙ„ JSON Ø§Ù„Ù…Ø­Ø³Ù†Ø©
                content = ai_response.get("content", "{}")
                
                print("=" * 80)
                print("âœ… Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:")
                print("=" * 80)
                print(content[:800] + "..." if len(content) > 800 else content)
                print("=" * 80)
                
                parsed_result = self._parse_json_response(content)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„
                if "error" in parsed_result:
                    self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON: {parsed_result['error']}")
                    return {
                        "success": False,
                        "error": "ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
                        "message": "Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØµØ­ÙŠØ­Ø© Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
                    }
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø­Ù„Ù„Ø©
                ad_copies = []
                headlines = parsed_result.get("headlines", [])
                descriptions = parsed_result.get("descriptions", [])
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø® Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ø£ÙˆØµØ§Ù
                for i, headline in enumerate(headlines[:5]):
                    description = descriptions[i] if i < len(descriptions) else descriptions[0] if descriptions else "ÙˆØµÙ Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ø­ØªÙŠØ§Ø·ÙŠ"
                    ad_copies.append({
                        "headline": headline,
                        "description": description,
                        "final_url": website_url,
                        "match_type": "BROAD",
                        "bid_amount": 2500000  # 2.5 Ø¯ÙˆÙ„Ø§Ø±
                    })
                
                # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
                brand_colors = parsed_result.get("colors", {})
                image_result = self.generate_ad_images(product_service, website_url, brand_colors)
                
                # ØªÙ†Ø¸ÙŠÙ Headlines Ùˆ Descriptions Ùˆ Keywords Ù…Ù† Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ (Google Ads Policy)
                self.logger.info("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ (Google Ads Policy)...")
                cleaned_headlines = [remove_phone_numbers(h) for h in headlines if h]
                cleaned_descriptions = [remove_phone_numbers(d) for d in descriptions if d]
                cleaned_keywords = [remove_phone_numbers(k) for k in parsed_result.get("keywords", []) if k]
                
                # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ù†ØµÙˆØµ ÙØ§Ø±ØºØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
                cleaned_headlines = [h for h in cleaned_headlines if h.strip()]
                cleaned_descriptions = [d for d in cleaned_descriptions if d.strip()]
                cleaned_keywords = [k for k in cleaned_keywords if k.strip()]
                
                self.logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(headlines)} headlines â†’ {len(cleaned_headlines)} Ù†Ø¸ÙŠÙØ©")
                self.logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(descriptions)} descriptions â†’ {len(cleaned_descriptions)} Ù†Ø¸ÙŠÙØ©")
                self.logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(parsed_result.get('keywords', []))} keywords â†’ {len(cleaned_keywords)} Ù†Ø¸ÙŠÙØ©")
                
                # ØªØ­Ø¯ÙŠØ« ad_copies Ø¨Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ù†Ø¸ÙØ©
                cleaned_ad_copies = []
                for i, headline in enumerate(cleaned_headlines[:5]):
                    description = cleaned_descriptions[i] if i < len(cleaned_descriptions) else cleaned_descriptions[0] if cleaned_descriptions else "ÙˆØµÙ Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ø­ØªØ±Ø§Ù"
                    cleaned_ad_copies.append({
                        "headline": headline,
                        "description": description,
                        "final_url": website_url,
                        "match_type": "BROAD",
                        "bid_amount": 2500000
                    })
                
                result = {
                    "success": True,
                    "product_service": product_service,
                    "website_url": website_url,
                    "headlines": cleaned_headlines,
                    "descriptions": cleaned_descriptions,
                    "keywords": cleaned_keywords,
                    "ad_copies": cleaned_ad_copies,
                    "recommended_campaign_type": parsed_result.get("recommended_campaign_type", "search_ads"),
                    "confidence_score": parsed_result.get("confidence_score", 0),
                    "reasoning": parsed_result.get("reasoning", ""),
                    "alternative_types": parsed_result.get("alternative_types", []),
                    "colors": brand_colors,
                    "color_palette": parsed_result.get("color_palette", []),
                    "brand_style": parsed_result.get("brand_style", "modern, clean, professional"),
                    "website_content": website_content,
                    "timestamp": datetime.now().isoformat(),
                    "errors": [],
                    "images": {
                        "success": image_result.get("success", False),
                        "image_url": image_result.get("image_url", ""),
                        "error": image_result.get("error", "") if not image_result.get("success") else ""
                    }
                }
            else:
                # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ø·Ù„Ø¨ØŒ Ø¥Ø±Ø¬Ø§Ø¹ Ø®Ø·Ø£
                return {
                    "success": False,
                    "error": ai_response.get("error", "Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"),
                    "message": "Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
                }
            
            self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„"
            }
    
    def generate_single_ad_element(self, element_type: str, website_url: str, existing_content: Dict = None, keywords_list: list = None, language: str = 'ar') -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø¹Ù†ØµØ± Ø¥Ø¹Ù„Ø§Ù†ÙŠ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· (headline Ø£Ùˆ description) Ø¨Ø³Ø±Ø¹Ø©"""
        try:
            # Language mapping
            language_map = {
                'ar': 'Arabic', 'en': 'English', 'fr': 'French', 'de': 'German', 
                'es': 'Spanish', 'it': 'Italian', 'pt': 'Portuguese', 'ru': 'Russian',
                'zh-CN': 'Chinese (simplified)', 'zh-TW': 'Chinese (traditional)',
                'ja': 'Japanese', 'ko': 'Korean', 'hi': 'Hindi', 'tr': 'Turkish',
                'nl': 'Dutch', 'pl': 'Polish', 'sv': 'Swedish', 'th': 'Thai',
                'vi': 'Vietnamese'
            }
            
            language_name = language_map.get(language, 'English')
            self.logger.info(f"ğŸš€ ØªÙˆÙ„ÙŠØ¯ {element_type} ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ø¨Ù„ØºØ© {language_name}")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
            keywords_line = ""
            if keywords_list and len(keywords_list) > 0:
                keywords_line = ', '.join(keywords_list[:5])  # Ø£ÙˆÙ„ 5 ÙƒÙ„Ù…Ø§Øª ÙÙ‚Ø· Ù„Ù„Ø³Ø±Ø¹Ø©
            elif existing_content and existing_content.get('keywords'):
                keywords_line = ', '.join(existing_content['keywords'][:5])
            
            # Ø¨Ø±ÙˆÙ…Ø¨Øª Ù…Ø®ØªØµØ± ÙˆØ³Ø±ÙŠØ¹ (Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©)
            if element_type == 'headline':
                prompt = f"""Generate ONE new Google Ads headline in {language_name}.

Keywords: {keywords_line}
Website: {website_url}

CRITICAL LANGUAGE REQUIREMENT:
Write ONLY in {language_name} language. Do NOT use any other language.

Requirements:
- Maximum 30 characters
- Use keywords naturally
- Different from existing headlines
- Focus on benefits
- Professional {language_name} tone

Return ONLY JSON:
{{"headline": "your headline here in {language_name}"}}"""
            else:  # description
                prompt = f"""Generate ONE new Google Ads description in {language_name}.

Keywords: {keywords_line}
Website: {website_url}

CRITICAL LANGUAGE REQUIREMENT:
Write ONLY in {language_name} language. Do NOT use any other language.

Requirements:
- 60-90 characters (MINIMUM 60)
- MUST end with a Call-to-Action (CTA)
- Use keywords naturally
- Different from existing descriptions
- Structure: [Value] + [Benefit] + [CTA]
- Professional {language_name} tone

Return ONLY JSON:
{{"description": "your description here with CTA in {language_name}"}}"""
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø³Ø±ÙŠØ¹ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
            ai_response = self._call_cometapi(prompt)
            
            if ai_response.get("success"):
                content = ai_response.get("content", "{}")
                parsed_result = self._parse_json_response(content)
                
                if element_type == 'headline' and 'headline' in parsed_result:
                    return {
                        "success": True,
                        "text": parsed_result['headline']
                    }
                elif element_type == 'description' and 'description' in parsed_result:
                    return {
                        "success": True,
                        "text": parsed_result['description']
                    }
                else:
                    return {
                        "success": False,
                        "error": "No valid content in response"
                    }
            else:
                return {
                    "success": False,
                    "error": ai_response.get("error", "AI call failed")
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ {element_type}: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def generate_ad_images(self, product_service: str, website_url: str, brand_colors: Dict[str, str] = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DALL-E 3"""
        try:
            self.logger.info(f"ğŸ¨ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù„Ù„Ù…Ù†ØªØ¬: {product_service}")
            
            # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù„Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¬/Ø§Ù„Ø®Ø¯Ù…Ø©
            image_prompt = f"""
            Create a professional advertisement image for: {product_service}
            Website: {website_url}
            
            Requirements:
            - Professional, clean, modern design
            - Suitable for Google Ads display campaigns
            - High quality, commercial use
            - Brand colors: {brand_colors.get('primary', '#1A1A1A') if brand_colors else '#1A1A1A'}
            - Arabic-friendly design
            - No text overlay (text will be added separately)
            - 1024x1024 pixels, square format
            - Bright, engaging, trustworthy appearance
            """
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.image_model,
                "prompt": image_prompt,
                "n": 1,
                "size": "1024x1024",
                "quality": "standard",
                "style": "natural"
            }
            
            response = requests.post(
                f"{self.base_url}/v1/images/generations",
                headers=headers,
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                if "data" in result and len(result["data"]) > 0:
                    image_url = result["data"][0]["url"]
                    self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
                    return {
                        "success": True,
                        "image_url": image_url,
                        "product_service": product_service,
                        "website_url": website_url,
                        "brand_colors": brand_colors,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No image generated",
                        "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}",
                    "message": "ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©"
            }

    def generate_campaign_images(self, campaign_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø© ÙˆÙ…Ø­ØªÙˆØ§Ù‡Ø§ ÙˆÙƒÙ„Ù…Ø§ØªÙ‡Ø§ Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        try:
            self.logger.info(f"ğŸ¨ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù„Ù„Ø­Ù…Ù„Ø©: {campaign_type}")
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØµÙˆØ± Ù„Ù„Ø­Ù…Ù„Ø©
            image_requirements = self.get_campaign_image_requirements()
            campaign_requirements = image_requirements.get(campaign_type, {})
            
            if not campaign_requirements.get("required", False):
                self.logger.info(f"âœ… Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© {campaign_type} Ù„Ø§ ÙŠØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§")
                return {
                    "success": True,
                    "message": f"Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© {campaign_type} Ù„Ø§ ÙŠØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§",
                    "campaign_type": campaign_type,
                    "images": []
                }
            
            # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù„Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰
            image_prompt = self._create_campaign_image_prompt(campaign_type, product_service, website_url, keywords, brand_colors)
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø­Ø³Ø¨ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©
            generated_images = []
            images_config = campaign_requirements.get("images", {})
            
            for image_type, image_config in images_config.items():
                try:
                    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù…Ø­Ø¯Ø¯ Ù„ÙƒÙ„ Ù†ÙˆØ¹ ØµÙˆØ±Ø©
                    specific_prompt = f"{image_prompt}\n\nImage type: {image_type}\nSize: {image_config.get('size', '1024x1024')}\nAspect ratio: {image_config.get('aspect_ratio', '1:1')}"
                    
                    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©
                    image_result = self._generate_single_image(specific_prompt, image_config)
                    
                    if image_result.get("success"):
                        generated_images.append({
                            "type": image_type,
                            "url": image_result["image_url"],
                            "size": image_config.get("size", "1024x1024"),
                            "aspect_ratio": image_config.get("aspect_ratio", "1:1"),
                            "format": image_config.get("formats", ["JPEG", "PNG"])[0]
                        })
                        self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type} Ø¨Ù†Ø¬Ø§Ø­")
                    else:
                        self.logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {image_result.get('error')}")
                        
                except Exception as e:
                    self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {e}")
                    continue
            
            if generated_images:
                self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(generated_images)} ØµÙˆØ±Ø© Ù„Ù„Ø­Ù…Ù„Ø© {campaign_type}")
                return {
                    "success": True,
                    "campaign_type": campaign_type,
                    "product_service": product_service,
                    "website_url": website_url,
                    "keywords": keywords,
                    "brand_colors": brand_colors,
                    "images": generated_images,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "success": False,
                    "error": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø£ÙŠ ØµÙˆØ±Ø©",
                    "message": "Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø£ÙŠ ØµÙˆØ±Ø© Ù„Ù„Ø­Ù…Ù„Ø©"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø§Ù„Ø­Ù…Ù„Ø©"
            }
    
    def generate_campaign_images_detailed(self, campaign_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None) -> List[Dict[str, Any]]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù„Ù„Ø­Ù…Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©"""
        try:
            logger.info(f"ğŸ¨ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© Ù„Ù„Ù…Ù†ØªØ¬: {product_service}")
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØµÙˆØ± Ù„Ù„Ø­Ù…Ù„Ø©
            image_requirements = self.get_campaign_image_requirements().get(campaign_type, {})
            
            if not image_requirements.get("required", False):
                logger.info(f"Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© {campaign_type} Ù„Ø§ ÙŠØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§")
                return []
            
            generated_images = []
            images_config = image_requirements.get("images", {})
            min_images = image_requirements.get("min_images", 1)
            max_images = image_requirements.get("max_images", 10)
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù† Ø§Ù„ØµÙˆØ± Ù„ÙƒÙ„ Ù†ÙˆØ¹
            for image_type, config in images_config.items():
                try:
                    # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹
                    images_needed = min(max_images, max(min_images, 1))
                    
                    for i in range(images_needed):
                        image_data = self._generate_single_image_detailed(
                            campaign_type=campaign_type,
                            image_type=image_type,
                            product_service=product_service,
                            website_url=website_url,
                            keywords=keywords,
                            brand_colors=brand_colors,
                            config=config,
                            image_index=i + 1
                        )
                        
                        if image_data:
                            generated_images.append(image_data)
                            logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type} #{i + 1} Ø¨Ù†Ø¬Ø§Ø­")
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {str(e)}")
                    continue
            
            logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(generated_images)} ØµÙˆØ±Ø© Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
            return generated_images
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©: {str(e)}")
            return []

    def _create_campaign_image_prompt(self, campaign_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø©"""
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ø£Ø³Ø§Ø³ÙŠ
        base_prompt = f"""
        Create a professional advertisement image for: {product_service}
        Website: {website_url}
        Keywords: {', '.join(keywords[:5])}
        Brand colors: {brand_colors.get('primary', '#1A1A1A') if brand_colors else '#1A1A1A'}
        
        Requirements:
        - Professional, clean, modern design
        - High quality, commercial use
        - Arabic-friendly design
        - NO TEXT, NO WORDS, NO LETTERS on the image (absolutely no text overlay - text will be added separately by the ad system)
        - Pure visual design without any written content
        - Bright, engaging, trustworthy appearance
        - Image only, no typography
        """
        
        # Ø¥Ø¶Ø§ÙØ© Ù…ØªØ·Ù„Ø¨Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø©
        campaign_specific_prompts = {
            "SEARCH": """
            - Suitable for Search campaigns
            - Text-based ads with image assets for enhancement
            - Professional and trustworthy appearance
            - Clear and compelling messaging
            - Square and landscape image formats
            """,
            "PERFORMANCE_MAX": """
            - Suitable for Performance Max campaigns
            - Works across all Google networks (Search, Display, YouTube, Gmail, Discover)
            - Versatile design that works in different contexts
            - Eye-catching and conversion-focused
            """,
            "DISPLAY": """
            - Suitable for Display campaigns
            - Visual appeal for website banners and ads
            - Attention-grabbing design
            - Professional and trustworthy appearance
            """,
            "VIDEO": """
            - Suitable for Video campaign thumbnails
            - High visual impact for video content
            - Engaging and click-worthy design
            - Professional video thumbnail style
            """,
            "SHOPPING": """
            - Suitable for Shopping campaigns
            - Product-focused design
            - Clean and professional product presentation
            - E-commerce friendly appearance
            - High-quality product images
            """,
            "SMART": """
            - Suitable for Smart campaigns
            - Automated campaign friendly design
            - Simple and clear visual message
            - Professional business appearance
            """,
            "LOCAL": """
            - Suitable for Local campaigns
            - Local business focused design
            - Community and location-based appeal
            - Professional local service appearance
            """,
            "DISCOVERY": """
            - Suitable for Discovery campaigns
            - Engaging and discovery-focused design
            - Eye-catching for feed content
            - Modern and appealing appearance
            """,
            "TRAVEL": """
            - Suitable for Travel campaigns
            - Travel and tourism focused design
            - Destination and experience appeal
            - Professional travel service appearance
            """,
            "DEMAND_GEN": """
            - Suitable for Demand Gen campaigns
            - Demand generation focused design
            - Engaging and conversion-oriented
            - Professional marketing appearance
            """,
            "MULTI_CHANNEL": """
            - Suitable for Multi-Channel campaigns
            - App and mobile focused design
            - Modern app store appearance
            - Professional mobile app design
            - App icon, screenshot, and banner formats
            """
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„Ù„Ø­Ù…Ù„Ø©
        campaign_prompt = campaign_specific_prompts.get(campaign_type, "")
        
        return f"{base_prompt}\n{campaign_prompt}"
    
    def _generate_single_image(self, prompt: str, image_config: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Flux-1.1-Pro-Ultra (Ø£Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© ÙˆØ§Ù‚Ø¹ÙŠØ©)"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            # ØªØ­Ø¯ÙŠØ¯ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø© - Flux Ultra ÙŠØ¯Ø¹Ù… Ø£Ø­Ø¬Ø§Ù… Ù…Ø®ØµØµØ©
            width = 1024
            height = 1024
            
            size = image_config.get("size", "1024x1024")
            if "x" in size or "Ã—" in size:
                try:
                    dims = size.replace("Ã—", "x").split("x")
                    width = int(dims[0])
                    height = int(dims[1])
                except:
                    width, height = 1024, 1024
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4o-mini Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØµÙˆØ± ÙˆØ§Ù‚Ø¹ÙŠØ© 100%
            enhanced_prompt = self._enhance_prompt_with_gpt4o(prompt)
            
            data = {
                "model": self.image_model,
                "prompt": enhanced_prompt,
                "width": width,
                "height": height,
                "aspect_ratio": "16:9" if width > height else "1:1",  # Flux Ultra ÙŠØ¯Ø¹Ù… aspect ratios
                "output_format": "jpeg",  # JPEG Ù„Ù„ØµÙˆØ± Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©
                "safety_tolerance": 2  # Ø£Ù‚Ù„ ØªÙ‚ÙŠÙŠØ¯ Ù„Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©
            }
            
            response = requests.post(
                f"{self.base_url}/v1/images/generations",
                headers=headers,
                json=data,
                timeout=180
            )
            
            if response.status_code == 200:
                result = response.json()
                if "data" in result and len(result["data"]) > 0:
                    image_url = result["data"][0]["url"]
                    return {
                        "success": True,
                        "image_url": image_url
                    }
                else:
                    return {
                        "success": False,
                        "error": "No image generated"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _enhance_prompt_with_gpt4o(self, prompt: str) -> str:
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4o-mini"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.text_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "You are a professional photography director specializing in PHOTOREALISTIC commercial photography. Your job is to enhance image prompts to achieve 100% realistic, documentary-style photographs - NOT AI-generated looking images. Focus on: camera settings, natural lighting, authentic environments, real materials, professional workers, and genuine work scenes."
                    },
                    {
                        "role": "user",
                        "content": f"Enhance this prompt for PHOTOREALISTIC documentary photography. The result must look like a real photograph taken with a professional DSLR camera, NOT an AI-generated image:\n\n{prompt}\n\nAdd specific details about: camera angle, lighting conditions, authentic worker appearance, real tool usage, genuine environment details, natural colors, and realistic textures. Make it look 100% like real documentary photography."
                    }
                ],
                "max_tokens": 400,
                "temperature": 0.6
            }
            
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                enhanced = result["choices"][0]["message"]["content"].strip()
                self.logger.info(f"âœ¨ ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨ÙˆØ§Ø³Ø·Ø© GPT-4o-mini")
                return enhanced
            else:
                self.logger.warning(f"ÙØ´Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨ØªØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£ØµÙ„ÙŠ")
                return prompt
                
        except Exception as e:
            self.logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª: {e}")
            return prompt

    def _generate_single_image_detailed(self, campaign_type: str, image_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None, config: Dict[str, Any] = None, image_index: int = 1, website_content: str = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø®ØµØµ
            prompt = self._create_detailed_image_prompt(
                campaign_type=campaign_type,
                image_type=image_type,
                product_service=product_service,
                website_url=website_url,
                keywords=keywords,
                brand_colors=brand_colors,
                config=config,
                image_index=image_index,
                website_content=website_content
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©
            response = self._call_cometapi_image(prompt, config)
            
            if response.get("success"):
                return {
                    "success": True,
                    "image_type": image_type,
                    "campaign_type": campaign_type,
                    "image_index": image_index,
                    "config": config,
                    "image_url": response.get("image_url"),
                    "prompt": prompt,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {response.get('error')}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {str(e)}")
            return None

    def _analyze_service_type(self, service_context: str, product_service: str, keywords_text: str = "", website_description: str = "") -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ù…Ø®ØµØµØ©"""
        
        text = f"{service_context} {product_service}".lower()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ - Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£ÙŠ Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø«Ø§Ø¨ØªØ©
        return self._extract_fully_dynamic_service_details(text, keywords_text, website_description)

    def _extract_fully_dynamic_service_details(self, text: str, keywords_text: str, website_description: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ 100% Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙÙ‚Ø· - Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù‚ÙˆØ§Ù„Ø¨ Ø«Ø§Ø¨ØªØ©"""

        # Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
        all_text = f"{text} {keywords_text} {website_description}".lower()

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ ÙƒØ§Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø«Ø§Ø¨ØªØ©
        return {
            "worker_action": self._extract_action_dynamically(all_text),
            "tools": self._extract_tools_dynamically(all_text),
            "material_color": self._extract_materials_dynamically(all_text),
            "environment": self._extract_environment_dynamically(all_text),
            "uniform_color": self._extract_uniform_dynamically(all_text)
        }

    def _extract_action_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¹Ø§Ù„ ÙˆØ¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ
        action_patterns = [
            r"ÙŠ(\w+)",  # Ø£ÙØ¹Ø§Ù„ Ø¨Ø§Ù„ÙŠØ§Ø¡
            r"Ù†(\w+)",  # Ø£ÙØ¹Ø§Ù„ Ø¨Ø§Ù„Ù†ÙˆÙ†
            r"Øª(\w+)",  # Ø£ÙØ¹Ø§Ù„ Ø¨Ø§Ù„ØªØ§Ø¡
            r"(\w+)ing",  # Ø£ÙØ¹Ø§Ù„ Ø¨Ø§Ù„Ù€ ing
        ]

        import re
        actions = []
        for pattern in action_patterns:
            matches = re.findall(pattern, text)
            actions.extend(matches[:2])  # Ø£ÙˆÙ„ ÙƒÙ„Ù…ØªÙŠÙ† ÙÙ‚Ø·

        return actions[0] if actions else "professional work"

    def _extract_tools_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆØ§Øª
        tool_indicators = [
            "Ø´Ø§Ø­Ù†Ø©", "Ø³ÙŠØ§Ø±Ø©", "ØµÙ†Ø§Ø¯ÙŠÙ‚", "Ø£Ø¯ÙˆØ§Øª", "Ù…Ø¹Ø¯Ø§Øª", "Ø­Ø¨Ø§Ù„", "Ø´Ø±Ø§Ø¦Ø·",
            "ØºÙ„Ø§Ù", "Ø­Ù…Ø§ÙŠØ©", "ÙØ±Ø´", "Ø£Ø¬Ù‡Ø²Ø©", "Ù…Ø§ÙƒÙŠÙ†Ø§Øª", "truck", "tools",
            "equipment", "boxes", "ropes", "tape", "wrapping", "padding"
        ]

        found_tools = []
        for indicator in tool_indicators:
            if indicator in text:
                found_tools.append(indicator)

        return found_tools[0] if found_tools else "professional equipment"

    def _extract_materials_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ø£Ù„ÙˆØ§Ù†
        material_indicators = [
            "Ø®Ø´Ø¨", "Ù…Ø¹Ø¯Ù†", "Ø¨Ù„Ø§Ø³ØªÙŠÙƒ", "Ø²Ø¬Ø§Ø¬", "Ù‚Ù…Ø§Ø´", "Ø¬Ù„Ø¯", "ÙˆØ±Ù‚",
            "Ø£Ø¨ÙŠØ¶", "Ø£Ø³ÙˆØ¯", "Ø£Ø²Ø±Ù‚", "Ø£Ø­Ù…Ø±", "Ø£Ø®Ø¶Ø±", "Ø£ØµÙØ±", "Ø¨Ù†ÙŠ",
            "wood", "metal", "plastic", "glass", "fabric", "leather", "paper"
        ]

        found_materials = []
        for indicator in material_indicators:
            if indicator in text:
                found_materials.append(indicator)

        return found_materials[0] if found_materials else "standard materials"

    def _extract_environment_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ¦Ø©
        env_indicators = [
            "Ø´Ù‚Ø©", "Ù…Ù†Ø²Ù„", "Ù…ÙƒØªØ¨", "Ù…Ø³ØªÙˆØ¯Ø¹", "Ù…Ø­Ù„", "Ù…Ø¨Ù†Ù‰", "Ø®Ø§Ø±Ø¬ÙŠ", "Ø¯Ø§Ø®Ù„ÙŠ",
            "Ø³ÙƒÙ†ÙŠ", "ØªØ¬Ø§Ø±ÙŠ", "apartment", "house", "office", "warehouse", "outdoor"
        ]

        found_envs = []
        for indicator in env_indicators:
            if indicator in text:
                found_envs.append(indicator)

        return found_envs[0] if found_envs else "business location"

    def _extract_uniform_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø²ÙŠ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
        color_indicators = [
            "Ø£Ø²Ø±Ù‚", "Ø£Ø¨ÙŠØ¶", "Ø£Ø³ÙˆØ¯", "Ø£Ø­Ù…Ø±", "Ø£Ø®Ø¶Ø±", "Ø£ØµÙØ±", "Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠ", "Ø¨Ù†ÙŠ",
            "Ø±Ù…Ø§Ø¯ÙŠ", "ÙˆØ±Ø¯ÙŠ", "blue", "white", "black", "red", "green", "yellow"
        ]

        found_colors = []
        for indicator in color_indicators:
            if indicator in text:
                found_colors.append(indicator)

        return found_colors[0] if found_colors else "professional uniform"
    
    def _create_detailed_image_prompt(self, campaign_type: str, image_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None, config: Dict[str, Any] = None, image_index: int = 1, website_content: str = None) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù…ÙØµÙ„ Ù„Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© ÙˆÙ†ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø©
        size = config.get("size", "1200Ã—628") if config else "1200Ã—628"
        aspect_ratio = config.get("aspect_ratio", "1.91:1") if config else "1.91:1"
        description = config.get("description", "ØµÙˆØ±Ø© Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©") if config else "ØµÙˆØ±Ø© Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©"
        field_type = config.get("field_type", "AD_IMAGE") if config else "AD_IMAGE"
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ùˆ website_content
        top_keywords = keywords[:5] if keywords else []
        service_context = ', '.join(top_keywords) if top_keywords else product_service
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… website_content Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªÙˆÙØ±Ø§Ù‹ Ù„ØªØ­Ø³ÙŠÙ† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø©
        if website_content:
            service_context = f"{service_context}, {website_content[:300]}"  # Ø£ÙˆÙ„ 300 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ù…Ù† ÙØ­Øµ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        keywords_text = ', '.join(top_keywords[:10]) if top_keywords else product_service
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØµÙ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„ÙØ¹Ù„ÙŠ
        website_description = ""
        if website_content:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ 400 Ø­Ø±Ù Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_description = website_content[:400].strip()
        
        # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        service_analysis = self._analyze_service_type(service_context, product_service, keywords_text, website_description)
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙÙ‚Ø· - Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø«Ø§Ø¨ØªØ©
        base_prompt = self._create_fully_dynamic_prompt(
            keywords_text, website_description
        )
        
        # ØªÙˆÙ„ÙŠØ¯ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´ÙŠØ¡ Ø«Ø§Ø¨Øª - Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒØ§Ù…Ù„ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙÙ‚Ø·
        return self._generate_purely_dynamic_prompt(
            keywords_text, website_description
        )

    def _generate_purely_dynamic_prompt(self, keywords_text: str, website_description: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´ÙŠØ¡ Ø«Ø§Ø¨Øª - ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙ‚Ø·"""

        # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
        combined_text = f"{keywords_text} {website_description}"

        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ±
        analysis_result = self._ai_analyze_content(combined_text)

        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙ‚Ø·
        prompt_parts = []

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        for category, items in analysis_result.items():
            if items and len(items) > 0:
                prompt_parts.append(f"{category.upper()}: {', '.join(items[:3])}")

        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø£ÙŠ Ø¹Ù†Ø§ØµØ±ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¹Ø§Ù…
        if not prompt_parts:
            prompt_parts.append("PROFESSIONAL: High quality professional photography")
            prompt_parts.append(f"CONTENT: {keywords_text}")
            prompt_parts.append(f"DESCRIPTION: {website_description[:200]}")

        return "\n".join(prompt_parts)

    def _extract_all_info_dynamically(self, text: str) -> Dict[str, str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù‚ÙˆØ§Ù…ÙŠØ³ Ø«Ø§Ø¨ØªØ© Ø£Ùˆ Ø§ÙØªØ±Ø§Ø¶Ø§Øª"""

        info = {}

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ ÙƒØ§Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù‚ÙˆØ§Ù…ÙŠØ³ Ø«Ø§Ø¨ØªØ© - ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙƒÙŠ
        all_extracted = self._analyze_text_intelligently(text)

        # ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹Ù‡Ø§ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹
        for category, items in all_extracted.items():
            if items and len(items) > 0:
                info[category] = f"{category}: {', '.join(items[:3])}"

        return info

    # ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø«Ø§Ø¨ØªØ© - Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¢Ù† Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙƒÙŠ

    def _analyze_text_intelligently(self, text: str) -> Dict[str, List[str]]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù‚ÙˆØ§Ù…ÙŠØ³ Ø«Ø§Ø¨ØªØ©"""

        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ù‡Ù…Ø©
        return self._ai_analyze_content(text)

    def _ai_analyze_content(self, text: str) -> Dict[str, List[str]]:
        """Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ù‡Ù…Ø©"""

        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… TEXT_MODEL Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒÙŠ
            prompt = f"""
            Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ù‡Ù…Ø© Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø§Ø­ØªØ±Ø§ÙÙŠØ©:

            Ø§Ù„Ù†Øµ: {text}

            Ù‚Ù… Ø¨ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙÙŠ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:
            - location: Ø£Ù…Ø§ÙƒÙ† ÙˆÙ…Ø¯Ù† Ù…Ø°ÙƒÙˆØ±Ø©
            - service: Ø®Ø¯Ù…Ø§Øª ÙˆØ£Ù†Ø´Ø·Ø© Ù…Ø°ÙƒÙˆØ±Ø©
            - workers: Ø£Ø´Ø®Ø§Øµ ÙˆØ¹Ø§Ù…Ù„ÙŠÙ† Ù…Ø°ÙƒÙˆØ±ÙŠÙ†
            - tools: Ø£Ø¯ÙˆØ§Øª ÙˆÙ…Ø¹Ø¯Ø§Øª Ù…Ø°ÙƒÙˆØ±Ø©
            - materials: Ù…ÙˆØ§Ø¯ ÙˆØ®Ø§Ù…Ø§Øª Ù…Ø°ÙƒÙˆØ±Ø©
            - environment: Ø£Ù…Ø§ÙƒÙ† ÙˆØ¨ÙŠØ¦Ø§Øª Ù…Ø°ÙƒÙˆØ±Ø©
            - actions: Ø£ÙØ¹Ø§Ù„ ÙˆØ£Ù†Ø´Ø·Ø© Ù…Ø°ÙƒÙˆØ±Ø©
            - objects: Ø£Ø´ÙŠØ§Ø¡ ÙˆÙ…ÙˆØ§Ø¯ Ù…Ø°ÙƒÙˆØ±Ø©
            - qualities: Ù…ØµØ·Ù„Ø­Ø§Øª Ø¬ÙˆØ¯Ø© Ù…Ø°ÙƒÙˆØ±Ø©

            Ø£Ø¹Ø¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠ.
            """

            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ØªØ­Ù„ÙŠÙ„
            analysis_result = self._call_text_model(prompt)

            if analysis_result and analysis_result.get('success'):
                content = analysis_result.get('content', '')

                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙƒÙ€ JSON
                try:
                    import json
                    parsed_result = json.loads(content)
                    return parsed_result
                except json.JSONDecodeError:
                    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† JSON ØµØ§Ù„Ø­ØŒ Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰
                    return self._parse_ai_response(content)
            else:
                # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ù†Ø¹ÙˆØ¯ Ø¥Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø³ÙŠØ·
                return self._fallback_text_analysis(text)

        except Exception as e:
            # ÙÙŠ Ø­Ø§Ù„Ø© ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø£ØŒ Ù†Ø¹ÙˆØ¯ Ø¥Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø³ÙŠØ·
            return self._fallback_text_analysis(text)

    def _call_text_model(self, prompt: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            data = {
                "model": self.text_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø­ØªÙˆÙ‰ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø§Ø­ØªØ±Ø§ÙÙŠØ©. Ø£Ø¹Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON ÙÙ‚Ø·."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.3
            }

            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"].strip()
                return {
                    "success": True,
                    "content": content
                }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code}"
                }

        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _parse_ai_response(self, content: str) -> Dict[str, List[str]]:
        """ØªØ­Ù„ÙŠÙ„ Ø±Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON"""
        elements = {
            'location': [],
            'service': [],
            'workers': [],
            'tools': [],
            'materials': [],
            'environment': [],
            'actions': [],
            'objects': [],
            'qualities': []
        }

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø©
        words = content.lower().split()
        for word in words:
            if len(word) > 3:
                # ØªØµÙ†ÙŠÙ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø­Ø³Ø¨ Ø£Ù†Ù…Ø§Ø·Ù‡Ø§
                if any(char in word for char in ['Ù…Ø¯ÙŠÙ†Ø©', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'Ù…Ø¯ÙŠÙ†Ø©']):
                    elements['location'].append(word)
                elif any(char in word for char in ['Ù†Ù‚Ù„', 'Ø®Ø¯Ù…Ø©', 'Ø´Ø±ÙƒØ©']):
                    elements['service'].append(word)
                elif any(char in word for char in ['Ø¹Ø§Ù…Ù„', 'Ù…Ù‡Ù†Ø¯Ø³', 'ÙÙ†ÙŠ']):
                    elements['workers'].append(word)
                elif any(char in word for char in ['Ø´Ø§Ø­Ù†Ø©', 'Ø£Ø¯Ø§Ø©', 'Ù…Ø¹Ø¯Ø©']):
                    elements['tools'].append(word)
                elif any(char in word for char in ['Ø®Ø´Ø¨', 'Ù…Ø¹Ø¯Ù†', 'Ø¨Ù„Ø§Ø³ØªÙŠÙƒ']):
                    elements['materials'].append(word)

        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        for category in elements:
            elements[category] = list(set(elements[category]))[:3]

        return elements

    def _fallback_text_analysis(self, text: str) -> Dict[str, List[str]]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¨Ø³ÙŠØ· ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        elements = {
            'location': [],
            'service': [],
            'workers': [],
            'tools': [],
            'materials': [],
            'environment': [],
            'actions': [],
            'objects': [],
            'qualities': []
        }

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø³ÙŠØ· Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
        words = text.split()
        long_words = [word for word in words if len(word) > 4]

        elements['objects'].extend(long_words[:5])
        elements['service'].extend([word for word in long_words if 'ing' in word or 'ment' in word])

        return elements

    def _call_cometapi_image(self, prompt: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©"""
        try:
            if not self.cometapi_config:
                return {
                    "success": False,
                    "error": "CometAPI not configured"
                }
            
            # Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ±ÙŠØ­Ø© Ø¨Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†Øµ
            enhanced_prompt = f"{prompt}\n\nIMPORTANT: DO NOT include any text, words, letters, or typography in the image. Create a pure visual design without any written content. The image should be completely text-free."
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØµÙˆØ±Ø©
            data = {
                "model": "flux-1.1-pro",
                "prompt": enhanced_prompt,
                "width": int(config.get("size", "1200Ã—628").split("Ã—")[0]),
                "height": int(config.get("size", "1200Ã—628").split("Ã—")[1]),
                "num_inference_steps": 20,
                "guidance_scale": 7.5,
                "safety_tolerance": 2
            }
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
            response = requests.post(
                f"{self.cometapi_config['base_url']}/v1/flux",
                headers={
                    "Authorization": f"Bearer {self.cometapi_config['api_key']}",
                    "Content-Type": "application/json"
                },
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                if "images" in result and len(result["images"]) > 0:
                    return {
                        "success": True,
                        "image_url": result["images"][0]["image_url"]
                    }
                else:
                    return {
                        "success": False,
                        "error": "No image generated"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _call_cometapi_image(self, prompt: str, config: Dict[str, Any] = None) -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
            size = config.get("size", "1200Ã—628") if config else "1200Ã—628"
            width, height = map(int, size.split("Ã—"))
            
            # Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ±ÙŠØ­Ø© Ø¨Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†Øµ
            enhanced_prompt = f"{prompt}\n\nIMPORTANT: DO NOT include any text, words, letters, or typography in the image. Create a pure visual design without any written content. The image should be completely text-free."
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            data = {
                "model": "dall-e-3",
                "prompt": enhanced_prompt,
                "width": width,
                "height": height,
                "quality": "hd",
                "n": 1,
                "response_format": "url"
            }
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API
            response = requests.post(
                f"{self.cometapi_base_url}/v1/images/generations",
                headers=self.cometapi_headers,
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                if "data" in result and len(result["data"]) > 0:
                    return {
                        "success": True,
                        "image_url": result["data"][0]["url"],
                        "width": width,
                        "height": height
                    }
                else:
                    return {
                        "success": False,
                        "error": "No image generated"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def generate_complete_campaign_assets(self, campaign_type: str, product_service: str, website_url: str, keywords: List[str], budget: float = 25.0, language_code: str = "1019", location_ids: List[str] = None, brand_colors: Dict[str, str] = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© (Ù†ØµÙˆØµ + ØµÙˆØ±)"""
        try:
            logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø©: {campaign_type}")
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©
            text_assets = self.generate_complete_ad_content(
                product_service=product_service,
                website_url=website_url
            )
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©
            image_assets = self.generate_campaign_images_detailed(
                campaign_type=campaign_type,
                product_service=product_service,
                website_url=website_url,
                keywords=keywords,
                brand_colors=brand_colors
            )
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            result = {
                "success": True,
                "campaign_type": campaign_type,
                "product_service": product_service,
                "website_url": website_url,
                "keywords": keywords,
                "budget": budget,
                "language_code": language_code,
                "location_ids": location_ids,
                "text_assets": text_assets,
                "image_assets": image_assets,
                "total_assets": {
                    "headlines": len(text_assets.get("headlines", [])),
                    "descriptions": len(text_assets.get("descriptions", [])),
                    "images": len(image_assets)
                },
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­: {result['total_assets']}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø©: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø©"
            }
    
    def select_smart_video_ad_type(
        self,
        goal: str,
        budget: float,
        video_duration: int = None,
        industry: str = None,
        has_product: bool = False,
        target_audience: str = None
    ) -> Dict[str, Any]:
        """
        ğŸ¤– Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù„Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø£Ù…Ø«Ù„
        
        Args:
            goal: Ø§Ù„Ù‡Ø¯Ù ("awareness", "sales", "conversions", "discovery", "brand_message", "engagement")
            budget: Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ø¨Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±
            video_duration: Ù…Ø¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            industry: Ø§Ù„Ù…Ø¬Ø§Ù„/Ø§Ù„ØµÙ†Ø§Ø¹Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            has_product: Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ù…Ù†ØªØ¬Ø§ØªØŸ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            target_audience: Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        
        Returns:
            Dict ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù…Ø¹ Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ø¨Ø¯Ø§Ø¦Ù„
        """
        
        logger.info(f"ğŸ¯ Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ Ù„Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...")
        logger.info(f"   Ø§Ù„Ù‡Ø¯Ù: {goal}, Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©: ${budget}, Ø§Ù„Ù…Ø¯Ø©: {video_duration}s")
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©
        if goal == "awareness" and budget < 30:
            recommendation = {
                "video_ad_type": "VIDEO_BUMPER_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† Bumper (6 Ø«ÙˆØ§Ù†ÙŠ)",
                "confidence": 95,
                "reason": "Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø© - Bumper Ad ÙŠÙˆÙØ± Ø£ÙƒØ¨Ø± ÙˆØµÙˆÙ„ Ø¨Ø£Ù‚Ù„ ØªÙƒÙ„ÙØ©",
                "reason_ar": "Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø© ($" + str(budget) + ") - Ø¥Ø¹Ù„Ø§Ù† Bumper ÙŠÙˆÙØ± Ø£ÙƒØ¨Ø± ÙˆØµÙˆÙ„ Ø¨Ø£Ù‚Ù„ ØªÙƒÙ„ÙØ©",
                "requirements": {
                    "video_duration": "6 Ø«ÙˆØ§Ù†ÙŠ Ø¨Ø§Ù„Ø¶Ø¨Ø·",
                    "video_duration_seconds": 6,
                    "cost_model": "CPM",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ±",
                    "estimated_cost_per_1000": "$0.40",
                    "estimated_daily_impressions": int(budget / 0.0004),
                    "estimated_daily_views": int(budget / 0.0004)
                },
                "pros": [
                    "Ø±Ø®ÙŠØµ Ø¬Ø¯Ø§Ù‹ - Ø£Ù‚Ù„ ØªÙƒÙ„ÙØ©",
                    "ÙˆØµÙˆÙ„ ÙˆØ§Ø³Ø¹ - ÙŠØµÙ„ Ù„Ø£ÙƒØ¨Ø± Ø¹Ø¯Ø¯",
                    "Ø³Ø±ÙŠØ¹ ÙˆÙ…Ø¨Ø§Ø´Ø± - 6 Ø«ÙˆØ§Ù†ÙŠ ÙÙ‚Ø·",
                    "ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ - Ù…Ø´Ø§Ù‡Ø¯Ø© Ù…Ø¶Ù…ÙˆÙ†Ø© 100%",
                    "Ù…Ø«Ø§Ù„ÙŠ Ù„Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©"
                ],
                "cons": [
                    "Ù…Ø¯Ø© Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ (6 Ø«ÙˆØ§Ù†ÙŠ ÙÙ‚Ø·)",
                    "Ø±Ø³Ø§Ù„Ø© Ù…Ø­Ø¯ÙˆØ¯Ø© - Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø´Ø±Ø­ ØªÙØ§ØµÙŠÙ„ ÙƒØ«ÙŠØ±Ø©",
                    "ÙŠØ­ØªØ§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ ÙÙŠ 6 Ø«ÙˆØ§Ù†ÙŠ"
                ],
                "best_for": "Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©",
                "best_for_ar": "Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©",
                "use_cases": [
                    "Ø´Ø±ÙƒØ© Ø¬Ø¯ÙŠØ¯Ø© ØªØ±ÙŠØ¯ Ø§Ù†ØªØ´Ø§Ø± Ø³Ø±ÙŠØ¹",
                    "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ø¬Ø¯ÙŠØ¯ - Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ¹Ø±ÙŠÙ",
                    "Ø­Ù…Ù„Ø© ØªØ°ÙƒÙŠØ±ÙŠØ© Ù‚ØµÙŠØ±Ø©"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…Ø¹ ÙÙŠØ¯ÙŠÙˆ Ø·ÙˆÙŠÙ„
        elif goal in ["sales", "conversions"] and (video_duration is None or video_duration >= 30) and budget >= 50:
            recommendation = {
                "video_ad_type": "VIDEO_TRUEVIEW_IN_STREAM_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† TrueView In-Stream (Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ)",
                "confidence": 92,
                "reason": "Ù‡Ø¯Ù ØªØ­ÙˆÙŠÙ„Ø§Øª + Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø¬ÙŠØ¯Ø© - TrueView ÙŠØ¬Ø°Ø¨ Ø§Ù„Ù…Ù‡ØªÙ…ÙŠÙ† ÙÙ‚Ø·",
                "reason_ar": "Ù‡Ø¯Ù Ù…Ø¨ÙŠØ¹Ø§Øª/ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…Ø¹ Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø¬ÙŠØ¯Ø© ($" + str(budget) + ") - TrueView ÙŠØ¬Ø°Ø¨ Ø§Ù„Ù…Ù‡ØªÙ…ÙŠÙ† ÙÙ‚Ø·",
                "requirements": {
                    "video_duration": "30 Ø«Ø§Ù†ÙŠØ© Ø£Ùˆ Ø£ÙƒØ«Ø± (Ù…ÙˆØµÙ‰ Ø¨Ù‡: 15-60 Ø«Ø§Ù†ÙŠØ©)",
                    "video_duration_seconds": "30-60",
                    "cost_model": "CPV",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø©",
                    "estimated_cost_per_view": "$0.01-0.05",
                    "estimated_daily_views": int(budget / 0.03),
                    "estimated_daily_clicks": int(budget / 0.03 * 0.05),
                    "payment_condition": "ØªØ¯ÙØ¹ Ø¹Ù†Ø¯ Ù…Ø´Ø§Ù‡Ø¯Ø© 30 Ø«Ø§Ù†ÙŠØ© Ø£Ùˆ Ø§Ù„ØªÙØ§Ø¹Ù„"
                },
                "pros": [
                    "ØªØ¯ÙØ¹ ÙÙ‚Ø· Ù„Ù„Ù…Ù‡ØªÙ…ÙŠÙ† - Ù„Ø§ ØªØ¯ÙØ¹ Ø¥Ø°Ø§ ØªØ®Ø·Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…",
                    "Ù…Ø¹Ø¯Ù„ ØªØ­ÙˆÙŠÙ„ Ø¹Ø§Ù„ÙŠ - ÙŠØ¬Ø°Ø¨ Ù…Ù† Ù„Ø¯ÙŠÙ‡ Ù†ÙŠØ© Ø´Ø±Ø§Ø¡",
                    "ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© CTA Ù‚ÙˆÙŠ ÙˆÙ…Ø¨Ø§Ø´Ø±",
                    "Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ Ø¨Ø¹Ø¯ 5 Ø«ÙˆØ§Ù†ÙŠ - ÙŠØµÙÙŠ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±",
                    "Ù…Ø«Ø§Ù„ÙŠ Ù„Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª"
                ],
                "cons": [
                    "ÙŠØ­ØªØ§Ø¬ ÙÙŠØ¯ÙŠÙˆ Ø¬ÙŠØ¯ - Ø£ÙˆÙ„ 5 Ø«ÙˆØ§Ù†ÙŠ Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹",
                    "ØªÙƒÙ„ÙØ© Ø£Ø¹Ù„Ù‰ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø±Ù‰",
                    "Ù‚Ø¯ ÙŠØªØ®Ø·Ù‰ Ø§Ù„Ø¨Ø¹Ø¶ - Ù„ÙƒÙ† Ù‡Ø°Ø§ Ø¬ÙŠØ¯ (ØªØµÙÙŠØ©)"
                ],
                "best_for": "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©",
                "best_for_ar": "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©",
                "use_cases": [
                    "Ù…ØªØ¬Ø± Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙŠØ±ÙŠØ¯ Ù…Ø¨ÙŠØ¹Ø§Øª",
                    "Ø®Ø¯Ù…Ø© B2B ØªØ±ÙŠØ¯ Ø¹Ù…Ù„Ø§Ø¡ Ù…Ø­ØªÙ…Ù„ÙŠÙ†",
                    "ØªØ·Ø¨ÙŠÙ‚ ÙŠØ±ÙŠØ¯ ØªØ­Ù…ÙŠÙ„Ø§Øª"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 3: Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…ØªÙˆØ³Ø·Ø©
        elif goal in ["sales", "conversions"] and budget < 50:
            recommendation = {
                "video_ad_type": "VIDEO_RESPONSIVE_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ Ù…ØªØ¬Ø§ÙˆØ¨",
                "confidence": 85,
                "reason": "Ù‡Ø¯Ù Ù…Ø¨ÙŠØ¹Ø§Øª + Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…ØªÙˆØ³Ø·Ø© - Responsive Ad Ù…Ø±Ù† ÙˆÙ…Ù†Ø§Ø³Ø¨",
                "reason_ar": "Ù‡Ø¯Ù Ù…Ø¨ÙŠØ¹Ø§Øª Ù…Ø¹ Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…ØªÙˆØ³Ø·Ø© ($" + str(budget) + ") - Ø¥Ø¹Ù„Ø§Ù† Ù…ØªØ¬Ø§ÙˆØ¨ Ù…Ø±Ù† ÙˆÙ…Ù†Ø§Ø³Ø¨",
                "requirements": {
                    "video_duration": "Ø£ÙŠ Ù…Ø¯Ø© (Ù…ÙˆØµÙ‰ Ø¨Ù‡: 15-30 Ø«Ø§Ù†ÙŠØ©)",
                    "video_duration_seconds": "15-30",
                    "cost_model": "CPV Ø£Ùˆ CPM",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø£Ùˆ ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ±",
                    "estimated_cost": "Ù…Ø±Ù† - Google ÙŠØ­Ø³Ù† Ø§Ù„ØªÙƒÙ„ÙØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹",
                    "estimated_daily_views": int(budget / 0.02)
                },
                "pros": [
                    "Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© - ÙŠØªÙƒÙŠÙ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹",
                    "ÙŠØ¹Ù…Ù„ ÙÙŠ ÙƒÙ„ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø¹Ù„Ù‰ YouTube",
                    "Google ÙŠØ­Ø³Ù†Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ - AI ÙŠØ®ØªØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„",
                    "Ø£Ù‚Ù„ Ù…Ø®Ø§Ø·Ø±Ø© - Ø®ÙŠØ§Ø± Ø¢Ù…Ù†",
                    "ÙŠØ¯Ø¹Ù… ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"
                ],
                "cons": [
                    "Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù‡Ø¯Ù Ù…Ø­Ø¯Ø¯ Ø¬Ø¯Ø§Ù‹"
                ],
                "best_for": "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù - Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹ ÙˆÙ…Ø±ÙˆÙ†Ø©",
                "best_for_ar": "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù - Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹ ÙˆÙ…Ø±ÙˆÙ†Ø©",
                "use_cases": [
                    "Ù…ØªØ¬Ø± Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…ØªÙˆØ³Ø·Ø©",
                    "Ø­Ù…Ù„Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ù‡Ø¯Ø§Ù",
                    "Ø§Ø®ØªØ¨Ø§Ø± Ø£Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 4: Ø§Ù„Ø§ÙƒØªØ´Ø§Ù ÙˆØ§Ù„Ø¨Ø­Ø«
        elif goal == "discovery" or industry in ["education", "tutorial", "how-to"]:
            recommendation = {
                "video_ad_type": "IN_FEED_VIDEO_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ ÙÙŠ Ø§Ù„Ø®Ù„Ø§ØµØ©",
                "confidence": 88,
                "reason": "Ù…Ø­ØªÙˆÙ‰ ØªØ¹Ù„ÙŠÙ…ÙŠ/Ø§ÙƒØªØ´Ø§Ù - In-Feed ÙŠØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
                "reason_ar": "Ù…Ø­ØªÙˆÙ‰ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø£Ùˆ Ø§ÙƒØªØ´Ø§Ù - Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„Ø®Ù„Ø§ØµØ© ÙŠØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
                "requirements": {
                    "video_duration": "Ø£ÙŠ Ù…Ø¯Ø©",
                    "video_duration_seconds": "any",
                    "cost_model": "CPV",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø©",
                    "estimated_cost_per_view": "$0.01-0.03",
                    "estimated_daily_clicks": int(budget / 0.02),
                    "payment_condition": "ØªØ¯ÙØ¹ ÙÙ‚Ø· Ø¹Ù†Ø¯ Ø§Ù„Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†"
                },
                "pros": [
                    "ÙŠØ¸Ù‡Ø± ÙÙŠ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù„Ù‰ YouTube",
                    "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† ÙŠØ¨Ø­Ø«ÙˆÙ† Ø¹Ù†Ùƒ - Ù†ÙŠØ© Ø¹Ø§Ù„ÙŠØ©",
                    "ØªØ¯ÙØ¹ ÙÙ‚Ø· Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… (Ø§Ù„Ù†Ù‚Ø±)",
                    "Ù…Ø«Ø§Ù„ÙŠ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ ÙˆØ§Ù„Ø¯Ø±ÙˆØ³",
                    "ÙŠØ¨Ù†ÙŠ Ø¬Ù…Ù‡ÙˆØ± Ù…Ù‡ØªÙ… Ø­Ù‚ÙŠÙ‚ÙŠ"
                ],
                "cons": [
                    "ÙˆØµÙˆÙ„ Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø±Ù‰",
                    "ÙŠØ­ØªØ§Ø¬ Ø¹Ù†ÙˆØ§Ù† Ø¬Ø°Ø§Ø¨ Ø¬Ø¯Ø§Ù‹",
                    "ÙŠØ­ØªØ§Ø¬ ØµÙˆØ±Ø© Ù…ØµØºØ±Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©"
                ],
                "best_for": "Ø§Ù„Ø§ÙƒØªØ´Ø§Ù ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ",
                "best_for_ar": "Ø§Ù„Ø§ÙƒØªØ´Ø§Ù ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ",
                "use_cases": [
                    "Ù‚Ù†Ø§Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ©",
                    "Ø´Ø±ÙƒØ© ØªÙ‚Ø¯Ù… Ø¯Ø±ÙˆØ³ ÙˆÙ…Ø­ØªÙˆÙ‰",
                    "Ù…Ø­ØªÙˆÙ‰ How-To"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 5: Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© ØºÙŠØ± Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ®Ø·ÙŠ
        elif goal == "brand_message" and budget >= 70 and (video_duration is None or video_duration <= 20):
            recommendation = {
                "video_ad_type": "VIDEO_NON_SKIPPABLE_IN_STREAM_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ",
                "confidence": 90,
                "reason": "Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© + Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø¬ÙŠØ¯Ø© - Non-Skippable ÙŠØ¶Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©",
                "reason_ar": "Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© Ù…Ø¹ Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø¬ÙŠØ¯Ø© ($" + str(budget) + ") - Ø¥Ø¹Ù„Ø§Ù† ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ ÙŠØ¶Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© 100%",
                "requirements": {
                    "video_duration": "15-20 Ø«Ø§Ù†ÙŠØ©",
                    "video_duration_seconds": "15-20",
                    "cost_model": "CPM",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ±",
                    "estimated_cost_per_1000": "$2-5",
                    "estimated_daily_impressions": int(budget / 0.0035),
                    "estimated_daily_views": int(budget / 0.0035)
                },
                "pros": [
                    "Ù…Ø´Ø§Ù‡Ø¯Ø© Ù…Ø¶Ù…ÙˆÙ†Ø© 100% - Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ®Ø·ÙŠ",
                    "Ø±Ø³Ø§Ù„Ø© ÙƒØ§Ù…Ù„Ø© - ÙŠØ´Ø§Ù‡Ø¯ ÙƒÙ„ Ø´ÙŠØ¡",
                    "Ù…Ø«Ø§Ù„ÙŠ Ù„Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ù…Ù‡Ù…",
                    "ØªØ£Ø«ÙŠØ± Ù‚ÙˆÙŠ - Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø¶Ø­Ø©"
                ],
                "cons": [
                    "Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ø²Ø¹Ø¬Ø§Ù‹ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†",
                    "ØªÙƒÙ„ÙØ© Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø±Ù‰",
                    "ÙŠØ­ØªØ§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ - Ù„Ø§ Ù…Ø¬Ø§Ù„ Ù„Ù„Ø®Ø·Ø£",
                    "Ù‚Ø¯ ÙŠØ¤Ø«Ø± Ø³Ù„Ø¨Ø§Ù‹ Ø¹Ù„Ù‰ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"
                ],
                "best_for": "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ø¬Ø¯ÙŠØ¯ Ø£Ùˆ Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹",
                "best_for_ar": "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ø¬Ø¯ÙŠØ¯ Ø£Ùˆ Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹",
                "use_cases": [
                    "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ø«ÙˆØ±ÙŠ",
                    "Ø¥Ø¹Ù„Ø§Ù† Ø­ÙƒÙˆÙ…ÙŠ Ù…Ù‡Ù…",
                    "Ø±Ø³Ø§Ù„Ø© Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ© Ù…Ù‡Ù…Ø©"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 6: Ø§Ù„ØªÙØ§Ø¹Ù„ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
        elif goal == "engagement":
            recommendation = {
                "video_ad_type": "VIDEO_RESPONSIVE_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ Ù…ØªØ¬Ø§ÙˆØ¨",
                "confidence": 87,
                "reason": "Ù‡Ø¯Ù ØªÙØ§Ø¹Ù„ - Responsive Ad ÙŠØ²ÙŠØ¯ ÙØ±Øµ Ø§Ù„ØªÙØ§Ø¹Ù„ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹",
                "reason_ar": "Ù‡Ø¯Ù ØªÙØ§Ø¹Ù„ ÙˆÙ…Ø´Ø§Ø±ÙƒØ© - Ø¥Ø¹Ù„Ø§Ù† Ù…ØªØ¬Ø§ÙˆØ¨ ÙŠØ²ÙŠØ¯ ÙØ±Øµ Ø§Ù„ØªÙØ§Ø¹Ù„ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹",
                "requirements": {
                    "video_duration": "15-30 Ø«Ø§Ù†ÙŠØ© (Ù…ÙˆØµÙ‰ Ø¨Ù‡)",
                    "video_duration_seconds": "15-30",
                    "cost_model": "CPV Ø£Ùˆ CPM",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø£Ùˆ ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ±",
                    "estimated_daily_engagements": int(budget / 0.02 * 0.1)
                },
                "pros": [
                    "Ù…Ø±Ù† - ÙŠØ¸Ù‡Ø± ÙÙŠ Ø£Ù…Ø§ÙƒÙ† Ù…ØªØ¹Ø¯Ø¯Ø©",
                    "ÙŠØ²ÙŠØ¯ ÙØ±Øµ Ø§Ù„ØªÙØ§Ø¹Ù„",
                    "Google ÙŠØ­Ø³Ù†Ù‡ Ù„Ù„ØªÙØ§Ø¹Ù„",
                    "ÙŠØ¯Ø¹Ù… CTAs Ù…ØªØ¹Ø¯Ø¯Ø©"
                ],
                "cons": [
                    "Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ ÙˆÙ‚Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†"
                ],
                "best_for": "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©",
                "best_for_ar": "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©",
                "use_cases": [
                    "Ø­Ù…Ù„Ø© ØªÙØ§Ø¹Ù„ÙŠØ©",
                    "Ù…Ø³Ø§Ø¨Ù‚Ø© Ø£Ùˆ ØªØ­Ø¯ÙŠ",
                    "Ø¨Ù†Ø§Ø¡ Ù…Ø¬ØªÙ…Ø¹"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 7: Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø¢Ù…Ù† (Default)
        else:
            recommendation = {
                "video_ad_type": "VIDEO_RESPONSIVE_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ Ù…ØªØ¬Ø§ÙˆØ¨",
                "confidence": 80,
                "reason": "Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© ÙˆØ£Ù…Ø§Ù†Ø§Ù‹ - ÙŠØªÙƒÙŠÙ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹ ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù",
                "reason_ar": "Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© ÙˆØ£Ù…Ø§Ù†Ø§Ù‹ - ÙŠØªÙƒÙŠÙ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹ ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù",
                "requirements": {
                    "video_duration": "Ø£ÙŠ Ù…Ø¯Ø© (Ù…ÙˆØµÙ‰ Ø¨Ù‡: 15-30 Ø«Ø§Ù†ÙŠØ©)",
                    "video_duration_seconds": "15-30",
                    "cost_model": "CPV Ø£Ùˆ CPM (Ù…Ø±Ù†)",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø£Ùˆ ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ± (Ù…Ø±Ù†)",
                    "estimated_cost": "Ù…Ø±Ù† - Google ÙŠØ­Ø³Ù† Ø§Ù„ØªÙƒÙ„ÙØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"
                },
                "pros": [
                    "Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© - ÙŠØ¹Ù…Ù„ ÙÙŠ ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„Ø§Øª",
                    "ÙŠØ¹Ù…Ù„ ÙÙŠ ÙƒÙ„ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹ Ø¹Ù„Ù‰ YouTube",
                    "Google ÙŠØ­Ø³Ù†Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
                    "Ø£Ù‚Ù„ Ù…Ø®Ø§Ø·Ø±Ø© - Ø®ÙŠØ§Ø± Ø¢Ù…Ù† Ø¬Ø¯Ø§Ù‹",
                    "ÙŠØ¯Ø¹Ù… ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© (1-5 ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª)"
                ],
                "cons": [
                    "Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù‡Ø¯Ù Ù…Ø­Ø¯Ø¯ Ø¬Ø¯Ø§Ù‹"
                ],
                "best_for": "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù - Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹",
                "best_for_ar": "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù - Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹",
                "use_cases": [
                    "Ø¹Ù…ÙŠÙ„ ØºÙŠØ± Ù…ØªØ£ÙƒØ¯ Ù…Ù† Ù‡Ø¯ÙÙ‡",
                    "Ø­Ù…Ù„Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ù‡Ø¯Ø§Ù",
                    "Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø³ÙˆÙ‚"
                ]
            }
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„
        alternatives = self._get_video_ad_alternatives(recommendation["video_ad_type"], goal, budget)
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        recommendation.update({
            "alternatives": alternatives,
            "input_parameters": {
                "goal": goal,
                "budget": budget,
                "video_duration": video_duration,
                "industry": industry,
                "has_product": has_product,
                "target_audience": target_audience
            },
            "next_steps": [
                "1. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù„Ø¯ÙŠÙƒ ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©",
                "2. Ù‚Ù… Ø¨Ø±ÙØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ YouTube",
                "3. Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Video ID Ù…Ù† YouTube",
                "4. Ø§Ø³ØªØ®Ø¯Ù… Video ID ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©"
            ],
            "tips": [
                "ğŸ’¡ Ø£ÙˆÙ„ 5 Ø«ÙˆØ§Ù†ÙŠ Ù‡ÙŠ Ø§Ù„Ø£Ù‡Ù… - Ø§Ø¬Ø°Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ ÙÙˆØ±Ø§Ù‹",
                "ğŸ’¡ Ø£Ø¶Ù ØªØ±Ø¬Ù…Ø§Øª Ù„Ù„ÙÙŠØ¯ÙŠÙˆ - 85% ÙŠØ´Ø§Ù‡Ø¯ÙˆÙ† Ø¨Ø¯ÙˆÙ† ØµÙˆØª",
                "ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ù… CTA ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø¨Ø§Ø´Ø±",
                "ğŸ’¡ Ø§Ø®ØªØ¨Ø± Ø¹Ø¯Ø© Ù†Ø³Ø® Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"
            ]
        })
        
        logger.info(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†: {recommendation['video_ad_type']} (Ø«Ù‚Ø©: {recommendation['confidence']}%)")
        
        return recommendation
    
    def _get_video_ad_alternatives(self, primary_type: str, goal: str, budget: float) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©"""
        alternatives = []
        
        # Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø§Ù‚ØªØ±Ø­ VIDEO_RESPONSIVE_AD ÙƒØ¨Ø¯ÙŠÙ„ Ø¢Ù…Ù†
        if primary_type != "VIDEO_RESPONSIVE_AD":
            alternatives.append({
                "video_ad_type": "VIDEO_RESPONSIVE_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ Ù…ØªØ¬Ø§ÙˆØ¨",
                "reason": "Ø¨Ø¯ÙŠÙ„ Ø¢Ù…Ù† ÙˆÙ…Ø±Ù† - ÙŠØ¹Ù…Ù„ ÙÙŠ ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„Ø§Øª",
                "confidence": 75
            })
        
        # Ø§Ù‚ØªØ±Ø­ BUMPER Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©
        if budget < 50 and primary_type != "VIDEO_BUMPER_AD":
            alternatives.append({
                "video_ad_type": "VIDEO_BUMPER_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† Bumper (6 Ø«ÙˆØ§Ù†ÙŠ)",
                "reason": "Ø¨Ø¯ÙŠÙ„ Ø£Ø±Ø®Øµ Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø© - ÙˆØµÙˆÙ„ Ø£ÙˆØ³Ø¹",
                "confidence": 70
            })
        
        # Ø§Ù‚ØªØ±Ø­ TRUEVIEW Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‡Ø¯Ù ØªØ­ÙˆÙŠÙ„Ø§Øª
        if goal in ["sales", "conversions"] and primary_type != "VIDEO_TRUEVIEW_IN_STREAM_AD" and budget >= 50:
            alternatives.append({
                "video_ad_type": "VIDEO_TRUEVIEW_IN_STREAM_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† TrueView In-Stream",
                "reason": "Ø¨Ø¯ÙŠÙ„ Ø£ÙØ¶Ù„ Ù„Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª - ØªØ¯ÙØ¹ ÙÙ‚Ø· Ù„Ù„Ù…Ù‡ØªÙ…ÙŠÙ†",
                "confidence": 80
            })
        
        # Ø§Ù‚ØªØ±Ø­ IN_FEED Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ
        if goal == "discovery" and primary_type != "IN_FEED_VIDEO_AD":
            alternatives.append({
                "video_ad_type": "IN_FEED_VIDEO_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ ÙÙŠ Ø§Ù„Ø®Ù„Ø§ØµØ©",
                "reason": "Ø¨Ø¯ÙŠÙ„ Ù„Ù„Ø§ÙƒØªØ´Ø§Ù - ÙŠØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ø¨Ø­Ø«",
                "confidence": 75
            })
        
        return alternatives

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø©
    generator = AIContentGenerator()
    
    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„
    result = generator.generate_complete_ad_content(
        product_service="Ø®Ø¯Ù…Ø§Øª Ù†Ù‚Ù„ Ø§Ù„Ø£Ø«Ø§Ø« ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶",
        website_url="https://example.com"
    )
    
    print("Ù†ØªÙŠØ¬Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ:")
    print(result)
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø°ÙƒÙŠ
    video_recommendation = generator.select_smart_video_ad_type(
        goal="sales",
        budget=100,
        video_duration=30
    )
    print("\nØªÙˆØµÙŠØ© Ù†ÙˆØ¹ Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ:")
    print(video_recommendation)

