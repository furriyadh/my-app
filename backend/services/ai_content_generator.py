#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
AI Content Generation Service for Ad Copy
"""

import os
import requests
import logging
import json
import re
from typing import Dict, List, Any, Optional
from datetime import datetime
import sys
from dotenv import load_dotenv
from bs4 import BeautifulSoup

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Ù…Ù„Ù .env.development
load_dotenv(dotenv_path=os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env.development'))

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± backend Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
backend_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(backend_path)

from cometapi_config import CometAPIConfig
from services.industry_targeting_config import detect_industry, get_industry_config

logger = logging.getLogger(__name__)

# Ø¯Ø§Ù„Ø© Ø¹Ø§Ù…Ø© Ù„Ø¥Ø²Ø§Ù„Ø© Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ (Google Ads Policy)
def remove_phone_numbers(text: str) -> str:
    """Ø¥Ø²Ø§Ù„Ø© Ø¬Ù…ÙŠØ¹ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ù…Ù† Ø§Ù„Ù†Øµ Ù„ØªØ¬Ù†Ø¨ Ø§Ù†ØªÙ‡Ø§Ùƒ Ø³ÙŠØ§Ø³Ø§Øª Google Ads"""
    if not text:
        return text
    
    # Ø£Ù†Ù…Ø§Ø· Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    patterns = [
        r'\b0\d{9,10}\b',  # Ø£Ø±Ù‚Ø§Ù… Ù…Ø­Ù„ÙŠØ© Ù…Ø«Ù„ 0558038312
        r'\b\+?\d{10,15}\b',  # Ø£Ø±Ù‚Ø§Ù… Ø¯ÙˆÙ„ÙŠØ©
        r'\b\d{3}[-.\s]?\d{3}[-.\s]?\d{4}\b',  # 555-123-4567
        r'\b\d{4}[-.\s]?\d{3}[-.\s]?\d{3}\b',  # 0555-123-456
        r'\(\d{3}\)[-.\s]?\d{3}[-.\s]?\d{4}\b',  # (555) 123-4567
    ]
    
    cleaned_text = text
    for pattern in patterns:
        cleaned_text = re.sub(pattern, '', cleaned_text)
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
    
    return cleaned_text

class AIContentGenerator:
    """Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        self.api_key = os.getenv("COMETAPI_API_KEY")
        self.base_url = os.getenv("COMETAPI_BASE_URL", "https://api.cometapi.com")
        self.text_model = os.getenv("TEXT_MODEL", "gpt-4o-mini")
        self.image_model = os.getenv("IMAGE_MODEL", "black-forest-labs/flux-1.1-pro-ultra")  # Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù„ÙˆØ§Ù‚Ø¹ÙŠØ© Ø§Ù„Ù…Ø·Ù„Ù‚Ø©
        
        # Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© Ù†Ù…ÙˆØ°Ø¬ llama-2-7b-chat ØºÙŠØ± Ø§Ù„Ù…ØªÙˆÙØ±
        if self.text_model == "llama-2-7b-chat":
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø±Ø®Øµ Ù†Ù…ÙˆØ°Ø¬ GPT (Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªÙƒÙ„ÙØ©)
            self.text_model = "gpt-4o-mini"  # $0.00015/1K tokens - Ø£Ø±Ø®Øµ GPT ÙˆØ£ÙØ¶Ù„ Ù„Ù„Ø£Ø¯Ø§Ø¡
            logger.warning(f"âš ï¸ Ù†Ù…ÙˆØ°Ø¬ llama-2-7b-chat ØºÙŠØ± Ù…ØªÙˆÙØ±ØŒ ØªÙ… Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ {self.text_model} (Ø£Ø±Ø®Øµ GPT ÙˆØ£ÙØ¶Ù„ Ù„Ù„Ø£Ø¯Ø§Ø¡)")
        
        if not self.api_key:
            raise ValueError("COMETAPI_API_KEY environment variable not set")
        
        # ØªÙ‡ÙŠØ¦Ø© Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª CometAPI
        self.logger = logging.getLogger(__name__)
        try:
            self.cometapi_config = CometAPIConfig()
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            self.cometapi_base_url = self.base_url
            self.cometapi_headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            self.logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ù…Ø¹ CometAPI")
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© CometAPI: {e}")
            self.cometapi_config = None
            self.cometapi_base_url = self.base_url
            self.cometapi_headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
    
    def get_campaign_image_requirements(self) -> Dict[str, Dict[str, Any]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØµÙˆØ± Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø©"""
        return {
                   "SEARCH": {
                       "required": True,
                       "min_images": 4,
                       "max_images": 4,
                       "images": {
                           "square_image": {
                               "size": "1200Ã—1200",
                               "aspect_ratio": "1:1",
                               "min_size": "300Ã—300",
                               "max_file_size": "5120 KB",
                               "formats": ["JPEG", "PNG"],
                               "field_type": "AD_IMAGE",
                               "description": "ØµÙˆØ±Ø© Ù…Ø±Ø¨Ø¹Ø© Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†"
                           },
                           "landscape_image": {
                               "size": "1200Ã—628",
                               "aspect_ratio": "1.91:1",
                               "min_size": "600Ã—314",
                               "max_file_size": "5120 KB",
                               "formats": ["JPEG", "PNG"],
                               "field_type": "AD_IMAGE",
                               "description": "ØµÙˆØ±Ø© Ø£ÙÙ‚ÙŠØ© Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†"
                           }
                       }
                   },
            "PERFORMANCE_MAX": {
                "required": True,
                "min_images": 4,
                "max_images": 4,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    },
                    "logo": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "LOGO",
                        "description": "Ø´Ø¹Ø§Ø± Ø§Ù„Ø¹Ù…Ù„"
                    },
                    "landscape_logo": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "LANDSCAPE_LOGO",
                        "description": "Ø´Ø¹Ø§Ø± Ø£ÙÙ‚ÙŠ"
                    }
                }
            },
            "DISPLAY": {
                "required": True,
                "min_images": 5,
                "max_images": 5,
                "images": {
                    "medium_rectangle": {
                        "size": "300Ã—250",
                        "aspect_ratio": "1.2:1",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù…Ø³ØªØ·ÙŠÙ„ Ù…ØªÙˆØ³Ø·"
                    },
                    "leaderboard": {
                        "size": "728Ã—90",
                        "aspect_ratio": "8.09:1",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù„ÙˆØ­Ø© Ø§Ù„Ù…ØªØµØ¯Ø±ÙŠÙ†"
                    },
                    "wide_skyscraper": {
                        "size": "160Ã—600",
                        "aspect_ratio": "1:3.75",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù†Ø§Ø·Ø­Ø© Ø³Ø­Ø§Ø¨ Ø¹Ø±ÙŠØ¶Ø©"
                    },
                    "large_rectangle": {
                        "size": "336Ã—280",
                        "aspect_ratio": "1.2:1",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù…Ø³ØªØ·ÙŠÙ„ ÙƒØ¨ÙŠØ±"
                    },
                    "half_page": {
                        "size": "300Ã—600",
                        "aspect_ratio": "1:2",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù†ØµÙ ØµÙØ­Ø©"
                    }
                }
            },
            "VIDEO": {
                "required": True,
                "min_images": 2,
                "max_images": 2,
                "images": {
                    "hd_thumbnail": {
                        "size": "1280Ã—720",
                        "aspect_ratio": "16:9",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "ØµÙˆØ±Ø© Ù…ØµØºØ±Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¯Ù‚Ø©"
                    },
                    "sd_thumbnail": {
                        "size": "640Ã—360",
                        "aspect_ratio": "16:9",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "ØµÙˆØ±Ø© Ù…ØµØºØ±Ø© Ø¹Ø§Ø¯ÙŠØ© Ø§Ù„Ø¯Ù‚Ø©"
                    }
                }
            },
            "SHOPPING": {
                "required": True,
                "min_images": 1,
                "max_images": 1000,
                "images": {
                    "product_images": {
                        "recommended_size": "800Ã—800",
                        "min_size": "250Ã—250",
                        "max_file_size": "16 MB",
                        "formats": ["JPEG", "PNG", "GIF"],
                        "field_type": "AD_IMAGE",
                        "description": "ØµÙˆØ± Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª - Ø¹Ø¯Ø¯ ÙØ±ÙŠØ¯ Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª"
                    }
                }
            },
            "SMART": {
                "required": True,
                "min_images": 2,
                "max_images": 2,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    }
                }
            },
            "LOCAL": {
                "required": True,
                "min_images": 2,
                "max_images": 2,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    }
                }
            },
            "DEMAND_GEN": {
                "required": True,
                "min_images": 3,
                "max_images": 3,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    },
                    "logo": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "LOGO",
                        "description": "Ø´Ø¹Ø§Ø± Ø§Ù„Ø¹Ù…Ù„"
                    }
                }
            },
                   "HOTEL": {
                       "required": False,
                       "description": "Ù„Ø§ ØªØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§ - ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙ†Ø§Ø¯Ù‚ ÙˆØ§Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ù† Hotel Center"
                   },
            "TRAVEL": {
                "required": True,
                "min_images": 2,
                "max_images": 2,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£ÙÙ‚ÙŠØ©"
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "SQUARE_MARKETING_IMAGE",
                        "description": "ØµÙˆØ±Ø© ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ù…Ø±Ø¨Ø¹Ø©"
                    }
                }
            },
            "DEMAND_GEN": {
                "required": True,
                "images": {
                    "marketing_image": {
                        "size": "1200Ã—628",
                        "aspect_ratio": "1.91:1",
                        "min_size": "600Ã—314",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"]
                    },
                    "square_marketing_image": {
                        "size": "1200Ã—1200",
                        "aspect_ratio": "1:1",
                        "min_size": "300Ã—300",
                        "max_file_size": "5120 KB",
                        "formats": ["JPEG", "PNG"]
                    }
                }
            },
            "LOCAL_SERVICES": {
                "required": False,
                "min_images": 0,
                "max_images": 0,
                "description": "Ù„Ø§ ØªØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§ - ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø© ÙˆØ§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ù† Local Services"
            },
            "MULTI_CHANNEL": {
                "required": True,
                "min_images": 3,
                "max_images": 3,
                "images": {
                    "app_icon": {
                        "size": "320Ã—50",
                        "aspect_ratio": "6.4:1",
                        "max_file_size": "150 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "Ø£ÙŠÙ‚ÙˆÙ†Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"
                    },
                    "app_screenshot": {
                        "size": "480Ã—320",
                        "aspect_ratio": "1.5:1",
                        "max_file_size": "150 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "Ù„Ù‚Ø·Ø© Ø´Ø§Ø´Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"
                    },
                    "app_banner": {
                        "size": "320Ã—480",
                        "aspect_ratio": "2:3",
                        "max_file_size": "150 KB",
                        "formats": ["JPEG", "PNG"],
                        "field_type": "AD_IMAGE",
                        "description": "Ø¨Ø§Ù†Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"
                    }
                }
            }
        }
    
    def _get_ad_copy_prompts(self, language: str = 'Arabic') -> Dict[str, str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨Ø±ÙˆÙ…Ø¨ØªØ§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© (Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©)"""
        
        # Language-specific instructions
        language_instructions = {
            'Arabic': 'Write in Arabic language. Use Arabic action words.',
            'English': 'Write in English language. Use compelling English action words.',
            'French': 'Write in French language. Use compelling French action words.',
            'German': 'Write in German language. Use compelling German action words.',
            'Spanish': 'Write in Spanish language. Use compelling Spanish action words.',
            'Italian': 'Write in Italian language. Use compelling Italian action words.',
            'Portuguese': 'Write in Portuguese language. Use compelling Portuguese action words.',
            'Russian': 'Write in Russian language. Use compelling Russian action words.',
            'Chinese (simplified)': 'Write in Simplified Chinese language.',
            'Chinese (traditional)': 'Write in Traditional Chinese language.',
            'Japanese': 'Write in Japanese language.',
            'Korean': 'Write in Korean language.',
            'Hindi': 'Write in Hindi language.',
            'Turkish': 'Write in Turkish language.',
            'Dutch': 'Write in Dutch language.',
            'Polish': 'Write in Polish language.',
            'Swedish': 'Write in Swedish language.',
            'Thai': 'Write in Thai language.',
            'Vietnamese': 'Write in Vietnamese language.',
        }
        
        lang_instruction = language_instructions.get(language, f'Write in {language} language.')
        
        return {
            "headlines": f"""
You are an expert in writing Google Ads headlines. Write 5 professional headlines for the following product/service:

Product/Service: {{product_service}}
Website: {{website_url}}
Website Content: {{website_content}}

IMPORTANT LANGUAGE REQUIREMENT:
{lang_instruction}
ALL headlines MUST be written in {language} language.

Requirements:
- Each headline maximum 30 characters
- Include key benefit
- Clear and honest (Google Ads compliant)
- Compelling and persuasive
- Suitable for {language} speaking audience

Return results in JSON format:
{{{{
    "headlines": [
        "First headline in {language}",
        "Second headline in {language}",
        "Third headline in {language}",
        "Fourth headline in {language}",
        "Fifth headline in {language}"
    ]
}}}}
""",
            "descriptions": f"""
You are an expert in writing Google Ads descriptions. Write 5 professional descriptions for the following product/service:

Product/Service: {{product_service}}
Website: {{website_url}}
Website Content: {{website_content}}

IMPORTANT LANGUAGE REQUIREMENT:
{lang_instruction}
ALL descriptions MUST be written in {language} language.

Requirements:
- Each description maximum 90 characters
- Clearly explain key benefit
- Include clear call-to-action
- Avoid misleading claims
- Google Ads compliant
- Compelling and attractive
- Suitable for {language} speaking audience

Return results in JSON format:
{{{{
    "descriptions": [
        "First description in {language}",
        "Second description in {language}",
        "Third description in {language}",
        "Fourth description in {language}",
        "Fifth description in {language}"
    ]
}}}}
""",
            "keywords": f"""
You are an expert in Google Ads keyword research. Suggest 20 keywords for the following product/service:

Product/Service: {{product_service}}
Website: {{website_url}}
Website Content: {{website_content}}

IMPORTANT LANGUAGE REQUIREMENT:
{lang_instruction}
ALL keywords MUST be in {language} language.

Requirements:
- Keywords relevant to product/service
- Suitable for {language} speaking audience
- Include long-tail keywords
- Include short direct keywords
- Suitable for Google Ads campaigns
- Varied phrasing

Return results in JSON format:
{{{{
    "keywords": [
        "First keyword in {language}",
        "Second keyword in {language}",
        "Third keyword in {language}",
        ...
    ]
}}}}
""",
            "campaign_type": """
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨. Ø­Ù„Ù„ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ§Ù‚ØªØ±Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©:

Ø§Ù„Ù…Ù†ØªØ¬/Ø§Ù„Ø®Ø¯Ù…Ø©: {product_service}
Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ: {website_url}
Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {website_content}

Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø­Ù…Ù„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
- search_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¨Ø­Ø«
- display_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©
- video_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
- shopping_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„ØªØ³ÙˆÙ‚
- performance_max: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ù‚ØµÙ‰
- app_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª
- call_ads: Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª

Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ JSON:
{{
    "recommended_campaign_type": "Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­",
    "confidence_score": 85,
    "reasoning": "Ø§Ù„Ø³Ø¨Ø¨ ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹",
    "alternative_types": ["Ù†ÙˆØ¹ Ø¨Ø¯ÙŠÙ„ 1", "Ù†ÙˆØ¹ Ø¨Ø¯ÙŠÙ„ 2"]
}}
""",
            "color_analysis": """
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©. Ø­Ù„Ù„ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:

Ø§Ù„Ù…Ù†ØªØ¬/Ø§Ù„Ø®Ø¯Ù…Ø©: {product_service}
Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ: {website_url}
Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {website_content}

Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ JSON:
{{
    "primary_color": "#1A1A1A",
    "secondary_color": "#00BFA5",
    "accent_color": "#FF6B6B",
    "text_color": "#FFFFFF",
    "background_color": "#1A1A1A",
    "color_palette": ["#1A1A1A", "#00BFA5", "#FF6B6B", "#FFFFFF"],
    "brand_style": "modern, clean, professional"
}}
"""
        }
    
    def _fetch_website_content(self, website_url: str) -> str:
        """Fetch website content using the SAME METHOD as detect_website_language (100% working!)"""
        try:
            # âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ Ù…Ù†Ø·Ù‚ detect_website_language Ø§Ù„Ù†Ø§Ø¬Ø­ 100%!
            import requests as http_requests
            import re
            from urllib.parse import urlparse
            
            # Add https:// if no scheme provided
            if not website_url.startswith(('http://', 'https://')):
                website_url = f'https://{website_url}'
            
            self.logger.info(f"Fetching website content: {website_url}")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept-Language': 'ar,en,fr,es,de,it,ja,ko,zh,*;q=0.9',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
            }
            
            # Try to fetch the website - with www fallback
            response = None
            urls_to_try = [website_url]
            
            # Add www variant if not present
            parsed = urlparse(website_url)
            if parsed.netloc and not parsed.netloc.startswith('www.'):
                www_url = f"{parsed.scheme}://www.{parsed.netloc}{parsed.path}"
                if parsed.query:
                    www_url += f"?{parsed.query}"
                urls_to_try.append(www_url)
            
            fetch_error_msg = None
            response = None
            for url_attempt in urls_to_try:
                try:
                    self.logger.info(f"ğŸ”— Fetching: {url_attempt}")
                    response = http_requests.get(url_attempt, headers=headers, timeout=20, allow_redirects=True, verify=False)
                    if response.status_code == 200:
                        self.logger.info(f"âœ… Website fetched successfully: {response.status_code}")
                        break
                except Exception as fetch_error:
                    fetch_error_msg = str(fetch_error)
                    self.logger.warning(f"âš ï¸ Failed to fetch {url_attempt}: {fetch_error}")
                    response = None
                    continue
            
            if not response or response.status_code != 200:
                self.logger.error(f"âŒ Could not fetch website from any URL variant")
                raise Exception(f"Could not fetch website: {fetch_error_msg}")
            
            # âœ… KEY FIX: Ø§Ø³ØªØ®Ø¯Ø§Ù… response.content Ù…Ø¨Ø§Ø´Ø±Ø© - Ù…Ø«Ù„ detect_website_language!
            soup = BeautifulSoup(response.content, 'html.parser')

            # ğŸ“¹ Special handling for YouTube
            if 'youtube.com' in website_url or 'youtu.be' in website_url:
                self.logger.info("ğŸ“¹ YouTube URL detected - attempting to extract video metadata")
                
                video_title = ""
                video_description = ""
                
                # 1. Try Open Graph tags (Most reliable for YouTube)
                og_title = soup.find("meta", property="og:title")
                if og_title: video_title = og_title.get("content", "")
                
                og_desc = soup.find("meta", property="og:description")
                if og_desc: video_description = og_desc.get("content", "")
                
                # 2. Fallback to standard meta tags
                if not video_title:
                    meta_title = soup.find("meta", attrs={"name": "title"})
                    if meta_title: video_title = meta_title.get("content", "")
                
                if not video_description:
                    meta_desc = soup.find("meta", attrs={"name": "description"})
                    if meta_desc: video_description = meta_desc.get("content", "")
                
                # 3. Fallback to Title tag
                if not video_title and soup.title:
                    video_title = soup.title.string

                if video_title:
                    self.logger.info(f"âœ… Extracted YouTube Metadata: {video_title}")
                    
                    # 4. Try to fetch Transcript (Subtitles) - THE GAME CHANGER ğŸš€
                    transcript_text = ""
                    try:
                        from youtube_transcript_api import YouTubeTranscriptApi
                        
                        # Extract Video ID
                        video_id = None
                        if 'v=' in website_url:
                            video_id = website_url.split('v=')[1].split('&')[0]
                        elif 'youtu.be/' in website_url:
                            video_id = website_url.split('youtu.be/')[1].split('?')[0]
                        
                        if video_id:
                            self.logger.info(f"ğŸ“œ Attempting to fetch transcript for video: {video_id}")
                            # Try to get transcript in Arabic, correct english or any available
                            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ar', 'en'])
                            
                            # Combine text
                            full_transcript = " ".join([item['text'] for item in transcript_list])
                            
                            # Limit to 3000 chars to avoid token limits but keep enough context
                            transcript_text = full_transcript[:3000]
                            self.logger.info(f"âœ… Successfully fetched transcript: {len(transcript_text)} chars")
                    except Exception as trans_error:
                        self.logger.warning(f"âš ï¸ Could not fetch transcript: {trans_error}")
                    
                    # Return rich context for the AI
                    combined_context = f"Video Title: {video_title}\n\nVideo Description: {video_description}\n\n"
                    if transcript_text:
                        combined_context += f"Video Script/Transcript (IMPORTANT - USE THIS FOR CONTENT):\n{transcript_text}\n\n"
                    else:
                        combined_context += "(YouTube Video Content)\n"
                        
                    return combined_context

            # Remove script, style, and navigation elements for cleaner text
            for element in soup(['script', 'style', 'nav', 'noscript', 'iframe', 'svg', 'header', 'footer']):
                element.decompose()
            
            # Get main content text
            text_content = soup.get_text(separator=' ', strip=True)
            # Clean up the text - remove extra whitespace
            text_content = re.sub(r'\s+', ' ', text_content).strip()
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­ØªÙ‡
            if text_content:
                self.logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(text_content)} Ø­Ø±Ù Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹")
                self.logger.info(f"ğŸ“ Ø£ÙˆÙ„ 200 Ø­Ø±Ù: {text_content[:200]}")
            else:
                self.logger.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹")
            
            # Limit content to reduce cost (first 5000 chars for better analysis)
            text_content = text_content[:5000]
            
            self.logger.info(f"Successfully fetched website content: {len(text_content)} chars")
            return text_content
                
        except Exception as e:
            self.logger.error(f"Error fetching website content: {e}")
            return ""
    
    def _extract_text_from_html(self, html_content: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ HTML - Ù†ÙØ³ Ø·Ø±ÙŠÙ‚Ø© WebsiteAnalyzer"""
        from bs4 import BeautifulSoup
        
        try:
            # Try multiple parsers - lxml is faster and better for complex HTML
            for parser in ['lxml', 'html.parser', 'html5lib']:
                try:
                    soup = BeautifulSoup(html_content, parser)
                    break
                except:
                    continue
            else:
                soup = BeautifulSoup(html_content, 'html.parser')
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª ÙˆØ§Ù„Ø£Ù†Ù…Ø§Ø·
            for script in soup(['script', 'style', 'meta', 'link', 'noscript', 'head']):
                script.decompose()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
            text = soup.get_text(separator=' ', strip=True)
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø­Ø±Ù Ø¹Ø±Ø¨ÙŠØ©/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø­Ù‚ÙŠÙ‚ÙŠØ©
            import re
            # Ø¹Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
            arabic_chars = len(re.findall(r'[\u0600-\u06FF]', text))
            english_chars = len(re.findall(r'[a-zA-Z]', text))
            
            if arabic_chars < 10 and english_chars < 10:
                self.logger.warning(f"âš ï¸ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø­Ø±Ù ÙƒØ§ÙÙŠØ©: Ø¹Ø±Ø¨ÙŠ={arabic_chars}, Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ={english_chars}")
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ - Ù†ÙØ³ Ø·Ø±ÙŠÙ‚Ø© WebsiteAnalyzer
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = ' '.join(chunk for chunk in chunks if chunk)
            
            return text.strip()
            
        except Exception as e:
            self.logger.error(f"âŒ Error extracting text from HTML: {e}")
            # Fallback to simple regex
            import re
            clean = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL)
            clean = re.sub(r'<style[^>]*>.*?</style>', '', clean, flags=re.DOTALL)
            clean = re.sub(r'<[^>]+>', ' ', clean)
            clean = re.sub(r'\s+', ' ', clean)
            return clean.strip()
    
    def _get_best_model_for_task(self, task_type: str) -> str:
        """Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©"""
        model_mapping = {
            "website_analysis": "claude-3-5-haiku-20241022",  # Ø³Ø±ÙŠØ¹ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹
            "ad_copy_generation": "qwen-2.5-7b-instruct",     # Ù…Ù…ØªØ§Ø² Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
            "keyword_extraction": "gpt-4o-mini",              # Ø£Ø±Ø®Øµ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
            "content_optimization": "gpt-4o-mini",            # Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            "arabic_content": "qwen-2.5-7b-instruct",         # Ø¬ÙŠØ¯ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
            "multilingual": "gemini-2.0-flash-exp",           # Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª
            "creative": "claude-3-5-sonnet-20241022",         # Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ
            "budget": "qwen-2.5-7b-instruct",                 # Ø£Ø±Ø®Øµ
            "premium": "gpt-4o"                               # Ø£ÙØ¶Ù„ Ø¬ÙˆØ¯Ø©
        }
        return model_mapping.get(task_type, self.text_model)
    
    def _call_cometapi(self, prompt: str, task_type: str = "general") -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.text_model,
                "messages": [
                    {
                        "role": "system",
                        "content": """You are a Google Ads expert specializing in high-converting ad copy. 

KEY REQUIREMENTS:
1. Generate exactly 30 headlines (max 30 characters each)
2. Generate exactly 4 descriptions (60-90 characters each - MINIMUM 60 chars)
3. EVERY description MUST end with a strong Call-to-Action (CTA) appropriate for the industry

DESCRIPTION BEST PRACTICES:
- Length: 60-90 characters (use full space available)
- Structure: [Value Proposition] + [Key Benefit] + [Industry-Specific CTA]
- CTA must match the business type and keywords (e.g., booking services use "Ø§Ø­Ø¬Ø² Ø§Ù„Ø¢Ù†", e-commerce uses "ØªØ³ÙˆÙ‚ Ø§Ù„Ø¢Ù†", professional services use "Ø§ØªØµÙ„ Ø¨Ù†Ø§")
- Include numbers, guarantees, or urgency when relevant to the industry
- Focus on benefits, not just features

HEADLINE BEST PRACTICES:
- Use numbers and percentages when relevant to the business
- Include location when provided in keywords
- Add urgency elements appropriate to the industry
- Use power words that match the business tone
- Focus on unique selling propositions and benefits

Base ALL content on the keywords from Google Keyword Planner and adapt to the specific industry."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 2000,
                "temperature": 0.5,
                "top_p": 0.9
            }
            
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    content = result["choices"][0]["message"]["content"]
                    return {
                        "success": True,
                        "content": content
                    }
                else:
                    return {
                        "success": False,
                        "error": "No content generated"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© JSON"""
        try:
            import json
            import re
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø£ÙˆÙ„Ø§Ù‹
            content = content.strip()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† JSON ÙÙŠ Ø§Ù„Ù†Øµ - ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø­Ø«
            json_patterns = [
                r'\{.*\}',  # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† JSON Ø¹Ø§Ø¯ÙŠ
                r'```json\s*(\{.*?\})\s*```',  # JSON ÙÙŠ code blocks
                r'```\s*(\{.*?\})\s*```',  # JSON ÙÙŠ code blocks Ø¨Ø¯ÙˆÙ† json
            ]
            
            for pattern in json_patterns:
                matches = re.findall(pattern, content, re.DOTALL)
                if matches:
                    json_str = matches[0] if isinstance(matches[0], str) else matches[0]
                    try:
                        return json.loads(json_str)
                    except json.JSONDecodeError:
                        continue
            
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ JSONØŒ Ø­Ø§ÙˆÙ„ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ù‚ÙˆØ§Ø³
            start = content.find('{')
            end = content.rfind('}') + 1
            
            if start != -1 and end != -1 and end > start:
                json_str = content[start:end]
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ JSON Ø¨Ø³ÙŠØ·
                    json_str = self._fix_json_format(json_str)
                    return json.loads(json_str)
            
            # Ø¥Ø°Ø§ ÙØ´Ù„ ÙƒÙ„ Ø´ÙŠØ¡ØŒ Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
            return self._create_fallback_response(content)
                
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON: {e}")
            return {"error": f"JSON parsing error: {str(e)}"}
    
    def _fix_json_format(self, json_str: str) -> str:
        """Ø¥ØµÙ„Ø§Ø­ ØªÙ†Ø³ÙŠÙ‚ JSON Ø§Ù„Ø¨Ø³ÙŠØ·"""
        try:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
            json_str = json_str.strip()
            
            # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
            json_str = json_str.replace("'", '"')  # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙØ±Ø¯Ø©
            json_str = re.sub(r',\s*}', '}', json_str)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ø£Ø®ÙŠØ±Ø©
            json_str = re.sub(r',\s*]', ']', json_str)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù…Ù† Ø§Ù„Ù…ØµÙÙˆÙØ§Øª
            
            return json_str
        except Exception:
            return json_str
    
    def _create_fallback_response(self, content: str) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¹Ù†Ø¯ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ JSON"""
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© Ù…Ù† Ø§Ù„Ù†Øµ
            headlines = []
            descriptions = []
            keywords = []
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù†Ø§ÙˆÙŠÙ†
            headline_patterns = [
                r'Ø¹Ù†ÙˆØ§Ù†[:\s]*([^\n]+)',
                r'headline[:\s]*([^\n]+)',
                r'Ø§Ù„Ø¹Ù†ÙˆØ§Ù†[:\s]*([^\n]+)'
            ]
            
            for pattern in headline_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                headlines.extend(matches[:5])  # Ø£ÙˆÙ„ 5 Ø¹Ù†Ø§ÙˆÙŠÙ†
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆØµØ§Ù
            desc_patterns = [
                r'ÙˆØµÙ[:\s]*([^\n]+)',
                r'description[:\s]*([^\n]+)',
                r'Ø§Ù„ÙˆØµÙ[:\s]*([^\n]+)'
            ]
            
            for pattern in desc_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                descriptions.extend(matches[:3])  # Ø£ÙˆÙ„ 3 Ø£ÙˆØµØ§Ù
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
            keyword_patterns = [
                r'ÙƒÙ„Ù…Ø©[:\s]*([^\n]+)',
                r'keyword[:\s]*([^\n]+)',
                r'Ø§Ù„ÙƒÙ„Ù…Ø©[:\s]*([^\n]+)'
            ]
            
            for pattern in keyword_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                keywords.extend(matches[:10])  # Ø£ÙˆÙ„ 10 ÙƒÙ„Ù…Ø§Øª
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
            response = {}
            if headlines:
                response['headlines'] = headlines
            if descriptions:
                response['descriptions'] = descriptions
            if keywords:
                response['keywords'] = keywords
            
            # Ø¥Ø¶Ø§ÙØ© Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
            if 'search' in content.lower() or 'Ø¨Ø­Ø«' in content:
                response['recommended_campaign_type'] = 'search_ads'
            elif 'display' in content.lower() or 'Ø¹Ø±Ø¶' in content:
                response['recommended_campaign_type'] = 'display_ads'
            else:
                response['recommended_campaign_type'] = 'search_ads'
            
            response['confidence_score'] = 60
            response['reasoning'] = 'ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ'
            
            return response
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
            return {
                'error': 'ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©',
                'headlines': ['Ø¹Ù†ÙˆØ§Ù† Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ø­ØªÙŠØ§Ø·ÙŠ'],
                'descriptions': ['ÙˆØµÙ Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ø­ØªÙŠØ§Ø·ÙŠ'],
                'keywords': ['ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©'],
                'recommended_campaign_type': 'search_ads',
                'confidence_score': 50
            }
    
    def generate_headlines(self, product_service: str, website_url: str, language: str = 'Arabic') -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©"""
        try:
            self.logger.info(f"ğŸ“ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ù„Ù„Ù…Ù†ØªØ¬: {product_service} Ø¨Ø§Ù„Ù„ØºØ©: {language}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª (Ù…Ø¹ Ø§Ù„Ù„ØºØ©)
            prompts = self._get_ad_copy_prompts(language=language)
            prompt = prompts["headlines"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "headlines" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(parsed_response['headlines'])} Ø¹Ù†ÙˆØ§Ù†")
                    return {
                        "success": True,
                        "headlines": parsed_response["headlines"],
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No headlines found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†"
            }
    
    def generate_descriptions(self, product_service: str, website_url: str, language: str = 'Arabic') -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©"""
        try:
            self.logger.info(f"ğŸ“ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù Ù„Ù„Ù…Ù†ØªØ¬: {product_service} Ø¨Ø§Ù„Ù„ØºØ©: {language}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª (Ù…Ø¹ Ø§Ù„Ù„ØºØ©)
            prompts = self._get_ad_copy_prompts(language=language)
            prompt = prompts["descriptions"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "descriptions" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(parsed_response['descriptions'])} ÙˆØµÙ")
                    return {
                        "success": True,
                        "descriptions": parsed_response["descriptions"],
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No descriptions found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØµØ§Ù"
            }
    
    def generate_keywords(self, product_service: str, website_url: str, language: str = 'Arabic') -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©"""
        try:
            self.logger.info(f"ğŸ”‘ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ù…Ù†ØªØ¬: {product_service} Ø¨Ø§Ù„Ù„ØºØ©: {language}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª (Ù…Ø¹ Ø§Ù„Ù„ØºØ©)
            prompts = self._get_ad_copy_prompts(language=language)
            prompt = prompts["keywords"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "keywords" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(parsed_response['keywords'])} ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ©")
                    return {
                        "success": True,
                        "keywords": parsed_response["keywords"],
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No keywords found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"
            }
    
    def suggest_campaign_type(self, product_service: str, website_url: str) -> Dict[str, Any]:
        """Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©"""
        try:
            self.logger.info(f"ğŸ¯ Ø¨Ø¯Ø¡ Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© Ù„Ù„Ù…Ù†ØªØ¬: {product_service}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
            prompts = self._get_ad_copy_prompts()
            prompt = prompts["campaign_type"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "recommended_campaign_type" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©: {parsed_response['recommended_campaign_type']}")
                    return {
                        "success": True,
                        "recommended_campaign_type": parsed_response["recommended_campaign_type"],
                        "confidence_score": parsed_response.get("confidence_score", 0),
                        "reasoning": parsed_response.get("reasoning", ""),
                        "alternative_types": parsed_response.get("alternative_types", []),
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No campaign type found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù‚ØªØ±Ø§Ø­ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©"
            }
    
    def analyze_website_colors(self, product_service: str, website_url: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ"""
        try:
            self.logger.info(f"ğŸ¨ Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹: {website_url}")
            
            # Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_content = self._fetch_website_content(website_url)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
            prompts = self._get_ad_copy_prompts()
            prompt = prompts["color_analysis"].format(
                product_service=product_service,
                website_url=website_url,
                website_content=website_content[:2000]  # Ø£ÙˆÙ„ 2000 Ø­Ø±Ù
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI
            response = self._call_cometapi(prompt)
            
            if response.get("success"):
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                parsed_response = self._parse_json_response(response["content"])
                
                if "primary_color" in parsed_response:
                    self.logger.info(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹")
                    return {
                        "success": True,
                        "colors": {
                            "primary": parsed_response.get("primary_color", "#1A1A1A"),
                            "secondary": parsed_response.get("secondary_color", "#00BFA5"),
                            "accent": parsed_response.get("accent_color", "#FF6B6B"),
                            "text": parsed_response.get("text_color", "#FFFFFF"),
                            "background": parsed_response.get("background_color", "#1A1A1A")
                        },
                        "color_palette": parsed_response.get("color_palette", []),
                        "brand_style": parsed_response.get("brand_style", "modern, clean, professional"),
                        "website_content": website_content,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No colors found in response",
                        "raw_response": response["content"]
                    }
            else:
                return {
                    "success": False,
                    "error": response.get("error"),
                    "message": "ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹"
            }
    
    def _get_campaign_requirements(self, campaign_type: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Google Ads Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø© - Ø­Ø³Ø¨ Google Ads API v21"""
        requirements = {
            "SEARCH": """
**SEARCH CAMPAIGN REQUIREMENTS (Google Ads API v21):**
- Responsive Search Ads (RSA)
- Headlines: 15-30 (max 30 chars) - REQUIRED for EXCELLENT Ad Strength
- Descriptions: 4-5 (60-90 chars) - MUST end with CTA
- Assets: Callouts (8-10), Sitelinks (4-8), Structured Snippets (1-2)
- Keywords: 20-50 keywords with match types (Broad, Phrase, Exact)
            """,
            "DISPLAY": """
**DISPLAY CAMPAIGN REQUIREMENTS (Google Ads API v21):**
- Responsive Display Ads
- Short Headlines: 5+ (max 30 chars)
- Long Headlines: 1-5 (max 90 chars)
- Descriptions: 5 (max 90 chars)
- Images: 15+ (Square 1200x1200 + Landscape 1200x628 required)
- Logo: 1200x1200
- Videos: 5+ (recommended)
            """,
            "VIDEO": """
**VIDEO CAMPAIGN REQUIREMENTS (Google Ads API v21):**
- Video Responsive Ads (recommended)
- Headlines: 5-15 (max 30 chars)
- Long Headlines: 1-5 (max 90 chars)  
- Descriptions: 4-5 (max 90 chars)
- Videos: 5+ (different lengths: 6s, 15s, 30s, 60s+)
- Video Formats: Horizontal 16:9 (required), Vertical 9:16, Square 1:1
- Call-to-Action: 10 chars max
            """,
            "SHOPPING": """
**SHOPPING CAMPAIGN REQUIREMENTS (Google Ads API v21):**
- Product Feed from Google Merchant Center
- Required: id, title, description, link, image_link, price, availability
- Recommended: brand, gtin, mpn, color, size, product_type
            """,
            "PERFORMANCE_MAX": """
**PERFORMANCE MAX REQUIREMENTS (Google Ads API v21):**
- Asset Groups with:
  * Headlines: 5-15 (max 30 chars)
  * Long Headlines: 1-5 (max 90 chars)
  * Descriptions: 4-5 (max 90 chars)
  * Images: 15-20 (Square, Landscape, Portrait, Logo)
  * Videos: 5+ (all formats)
  * Business Name: 25 chars max
  * Call-to-Action: required
- Audience Signals: 2-3 minimum
- Conversion Tracking: required
            """,
            "DEMAND_GEN": """
**DEMAND GEN CAMPAIGN REQUIREMENTS (Google Ads API v21):**
- Similar to Performance Max
- Headlines: 5-15 (max 30 chars)
- Long Headlines: 1-5 (max 90 chars)
- Descriptions: 4-5 (max 90 chars)  
- Images: 15-20 (all sizes)
- Videos: 5+
- Focus: Gmail, YouTube, Discover
            """,
            "APP": """
**APP CAMPAIGN REQUIREMENTS (MULTI_CHANNEL - Google Ads API v21):**
- Headlines: 5+ (max 30 chars)
- Descriptions: 5+ (max 90 chars)
- Images: 20+ images
- Videos: 5+ videos
- App Store/Play Store link required
            """,
            "LOCAL": """
**LOCAL CAMPAIGN REQUIREMENTS (Google Ads API v21):**
- Business name, address, phone
- Headlines: 3-5 (max 30 chars)
- Descriptions: 2-4 (max 90 chars)
- Images: 20+ images
            """,
            "SMART": """
**SMART CAMPAIGN REQUIREMENTS (Google Ads API v21):**
- Simplified setup
- Headlines: 3 (max 30 chars)
- Descriptions: 2 (max 90 chars)
            """,
            "HOTEL": """
**HOTEL CAMPAIGN REQUIREMENTS (Google Ads API v21):**
- Hotel name, price, images, descriptions
- Integration with Google Hotel Center
            """,
            "TRAVEL": """
**TRAVEL CAMPAIGN REQUIREMENTS (Google Ads API v21):**
- Headlines, descriptions, destination info
- Images: travel-focused
- Integration with travel feeds
            """
        }
        return requirements.get(campaign_type.upper(), requirements["DISPLAY"])
    
    def _get_video_ad_requirements(self, video_ad_type: str) -> dict:
        """Get specific requirements for each YouTube video ad type"""
        video_requirements = {
            "VIDEO_RESPONSIVE_AD": {
                "name": "Video Responsive Ad",
                "name_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ Ù…ØªØ¬Ø§ÙˆØ¨",
                "fields": {
                    "headlines": {"count": 5, "max_length": 30, "required": True},
                    "long_headlines": {"count": 5, "max_length": 90, "required": True},
                    "descriptions": {"count": 5, "max_length": 90, "required": True},
                    "call_to_action": {"max_length": 10, "required": False}
                },
                "prompt_instructions": """
Generate for VIDEO RESPONSIVE AD:
- 5 Headlines (max 30 chars each)
- 5 Long Headlines (max 90 chars each)
- 5 Descriptions (max 90 chars each, MUST end with CTA)
- 1 Call-to-Action button text (max 10 chars)
"""
            },
            "VIDEO_TRUEVIEW_IN_STREAM_AD": {
                "name": "TrueView In-Stream Ad",
                "name_ar": "Ø¥Ø¹Ù„Ø§Ù† TrueView",
                "fields": {
                    "action_button_label": {"max_length": 10, "required": True},
                    "action_headline": {"max_length": 15, "required": True}
                },
                "prompt_instructions": """
Generate for TRUEVIEW IN-STREAM AD (Skippable after 5 seconds):
- 1 Action Button Label (max 10 chars) - e.g., "Buy Now", "Learn More", "Sign Up", "Ø§Ø´ØªØ±Ù Ø§Ù„Ø¢Ù†", "ØªØ¹Ø±Ù Ø£ÙƒØ«Ø±"
- 1 Action Headline (max 15 chars) - Short compelling text shown with button
These appear as an overlay on the video. Be concise and action-oriented.
"""
            },
            "IN_FEED_VIDEO_AD": {
                "name": "In-Feed Video Ad",
                "name_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ ÙÙŠ Ø§Ù„Ø®Ù„Ø§ØµØ©",
                "fields": {
                    "headlines": {"count": 1, "max_length": 100, "required": True},
                    "descriptions": {"count": 2, "max_length": 35, "required": True}
                },
                "prompt_instructions": """
Generate for IN-FEED VIDEO AD (Appears in YouTube search & home feed):
- 1 Headline (max 100 chars) - This is the main title that makes users want to click
- 2 Descriptions (max 35 chars EACH) - Very short lines shown below the headline
The goal is to drive video views and subscribers. Be compelling but concise.
"""
            },
            "VIDEO_BUMPER_AD": {
                "name": "Bumper Ad",
                "name_ar": "Ø¥Ø¹Ù„Ø§Ù† Ø¨Ø§Ù…Ø¨Ø±",
                "fields": {
                    "action_button_label": {"max_length": 10, "required": False},
                    "action_headline": {"max_length": 15, "required": False}
                },
                "prompt_instructions": """
Generate for BUMPER AD (6 seconds, non-skippable):
- 1 Action Button Label (max 10 chars, OPTIONAL) - Short CTA if user wants to add one
- 1 Action Headline (max 15 chars, OPTIONAL) - Short text shown with button
Bumper ads are for brand awareness. Keep it simple and memorable.
"""
            },
            "VIDEO_NON_SKIPPABLE_IN_STREAM_AD": {
                "name": "Non-Skippable In-Stream Ad",
                "name_ar": "Ø¥Ø¹Ù„Ø§Ù† ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ",
                "fields": {
                    "action_button_label": {"max_length": 10, "required": False},
                    "action_headline": {"max_length": 15, "required": False}
                },
                "prompt_instructions": """
Generate for NON-SKIPPABLE IN-STREAM AD (15-20 seconds):
- 1 Action Button Label (max 10 chars, OPTIONAL) - CTA button
- 1 Action Headline (max 15 chars, OPTIONAL) - Text shown with button
Viewers must watch the full video. Content should be engaging throughout.
"""
            }
        }
        return video_requirements.get(video_ad_type, video_requirements["VIDEO_RESPONSIVE_AD"])
    
    def _generate_specialized_video_content(self, video_ad_type: str, website_url: str, target_language: str = "ar", website_content: str = None, keywords_list: list = None, industry_config: Dict = None) -> Dict[str, Any]:
        """Generate specialized content for specific video ad types (TrueView, In-Feed, Bumper, Non-Skippable)"""
        try:
            self.logger.info(f"ğŸ¬ Generating specialized content for: {video_ad_type}")
            
            # Fetch website content if not provided
            if not website_content:
                website_content = self._fetch_website_content(website_url)
            
            # Get video type requirements
            video_reqs = self._get_video_ad_requirements(video_ad_type)
            
            # Language mapping
            language_map = {
                'ar': 'Arabic', 'en': 'English', 'fr': 'French', 'de': 'German',
                'es': 'Spanish', 'it': 'Italian', 'pt': 'Portuguese', 'ru': 'Russian',
                'ja': 'Japanese', 'ko': 'Korean', 'zh-CN': 'Chinese', 'tr': 'Turkish'
            }
            language_name = language_map.get(target_language, 'English')
            
            # Keywords
            keywords_line = ', '.join(keywords_list[:10]) if keywords_list else ''
            
            # Industry Context
            industry_context = ""
            if industry_config:
                ind_name = industry_config.get('name_en', 'General')
                ind_name_ar = industry_config.get('name_ar', 'Ø¹Ø§Ù…')
                industry_context = f"\nINDUSTRY CONTEXT: {ind_name} ({ind_name_ar})\nThis ad is for the '{ind_name}' industry. Adjust tone and CTA accordingly."

            # Build type-specific prompt
            if video_ad_type == "VIDEO_TRUEVIEW_IN_STREAM_AD":
                prompt = f"""Generate YouTube TrueView In-Stream Ad content in {language_name}.
{industry_context}

Website: {website_url}
Keywords: {keywords_line}
Website Content: {website_content[:1000]}

REQUIREMENTS (Google Ads API):
- action_button_label: EXACTLY 1 text, max 10 characters. CRITICAL: Choose based on INDUSTRY, VIDEO CONTENT, TITLE, and GOAL:
  (Analyze the provided 'Website Content' which contains the Video Title and Description)
  * Education/Content/News/Entertainment: "Subscribe", "Watch Now", "Learn More"
  * E-commerce/Retail/Products: "Buy Now", "Shop Now", "Order Now"
  * Apps/Software/Tools: "Download", "Install", "Sign Up"
  * Services/B2B/Consulting: "Contact Us", "Get Quote", "Book Now"
  * If the video title implies learning (e.g. "What is...", "How to...", "Explanation"): YOU MUST USE "Watch Now" or "Subscribe".
  * If the video title implies a product offer: USE "Buy Now" or "Shop Now".
- action_headline: EXACTLY 1 text, max 15 characters (short compelling text)

ALL content MUST be in {language_name}. Be concise and action-oriented.

Return ONLY valid JSON:
{{"action_button_label": "CTA text here", "action_headline": "Headline here", "headlines": [], "descriptions": []}}"""

            elif video_ad_type == "IN_FEED_VIDEO_AD":
                prompt = f"""Generate YouTube In-Feed Video Ad content in {language_name}.
{industry_context}

Website: {website_url}
Keywords: {keywords_line}
Website Content: {website_content[:1000]}

REQUIREMENTS (Google Ads API - In-Feed appears in YouTube search & home feed):
- headline: EXACTLY 1 text, max 100 characters (main title to attract clicks)
- descriptions: EXACTLY 2 texts, max 35 characters EACH (short lines below headline)

ALL content MUST be in {language_name}. Goal: drive video views and subscribers.

Return ONLY valid JSON:
{{"headlines": ["Main headline up to 100 chars"], "descriptions": ["Short desc 1 max 35 chars", "Short desc 2 max 35 chars"], "action_button_label": "", "action_headline": ""}}"""

            elif video_ad_type in ["VIDEO_BUMPER_AD", "VIDEO_NON_SKIPPABLE_IN_STREAM_AD"]:
                ad_name = "Bumper Ad (6 seconds)" if video_ad_type == "VIDEO_BUMPER_AD" else "Non-Skippable Ad (15-20 seconds)"
                prompt = f"""Generate YouTube {ad_name} content in {language_name}.
{industry_context}

Website: {website_url}
Keywords: {keywords_line}
Website Content: {website_content[:1000]}

REQUIREMENTS (Google Ads API - These fields are OPTIONAL for brand awareness):
- action_button_label: 1 text, max 10 characters (OPTIONAL CTA button)
- action_headline: 1 text, max 15 characters (OPTIONAL text with button)

If you generate them, they MUST be in {language_name}. Focus on brand awareness.

Return ONLY valid JSON:
{{"action_button_label": "CTA or empty", "action_headline": "Text or empty", "headlines": [], "descriptions": []}}"""
            else:
                # Fallback to responsive format
                return None
            
            # Call AI
            ai_response = self._call_cometapi(prompt)
            
            if ai_response.get("success"):
                content = ai_response.get("content", "{}")
                parsed_result = self._parse_json_response(content)
                
                self.logger.info(f"âœ… Generated specialized video content: {parsed_result}")
                
                return {
                    "success": True,
                    "headlines": parsed_result.get("headlines", []),
                    "descriptions": parsed_result.get("descriptions", []),
                    "action_button_label": parsed_result.get("action_button_label", ""),
                    "action_headline": parsed_result.get("action_headline", ""),
                    "long_headlines": [],
                    "call_to_action": parsed_result.get("action_button_label", ""),
                    "keywords": keywords_list or [],
                    "video_ad_type": video_ad_type,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                self.logger.error(f"âŒ AI call failed for {video_ad_type}")
                return {
                    "success": False,
                    "error": ai_response.get("error", "AI generation failed")
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Error generating specialized video content: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    def generate_complete_ad_content(self, product_service: str, website_url: str, service_type: str = None, target_language: str = "ar", website_content: str = None, campaign_type: str = "DISPLAY", keywords_list: list = None, video_ad_type: str = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© ÙˆØªØ¹Ù„ÙŠÙ…Ø§Øª Google Ads"""
        try:
            self.logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ - Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©: {campaign_type}")
            # 1. Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø£ÙˆÙ„Ø§Ù‹ (Ù…Ø·Ù„ÙˆØ¨ Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ØµÙ†Ø§Ø¹Ø©)
            if not website_content:
                website_content = self._fetch_website_content(website_url)
                print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {len(website_content)} Ø­Ø±Ù")
            else:
                print(f"âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ù…Ø±Ø±: {len(website_content)} Ø­Ø±Ù")

            # 2. ğŸ¯ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ØµÙ†Ø§Ø¹Ø© ÙˆØªØ¬Ù‡ÙŠØ² Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù Ø§Ù„Ø°ÙƒÙŠ (Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹)
            detected_industry = detect_industry(website_content)
            industry_config = get_industry_config(detected_industry)
            self.logger.info(f"ğŸ¯ Detected Industry: {detected_industry} ({industry_config.get('name_ar')})")
            
            smart_targeting_data = {
                "industry": detected_industry,
                "industry_name_ar": industry_config.get("name_ar"),
                "age_ranges": industry_config.get("age_ranges", []),
                "gender": industry_config.get("gender"),
                "device_modifiers": industry_config.get("device_modifiers", {}),
                "frequency_cap": industry_config.get("frequency_cap", {}),
                "industry_keywords": industry_config.get("keywords", [])
            }

            if campaign_type == 'VIDEO' and video_ad_type:
                self.logger.info(f"ğŸ“¹ Video Ad Type: {video_ad_type}")
                # Use specialized video content generation for non-responsive types
                if video_ad_type != 'VIDEO_RESPONSIVE_AD':
                    specialized_result = self._generate_specialized_video_content(
                        video_ad_type=video_ad_type,
                        website_url=website_url,
                        target_language=target_language,
                        website_content=website_content,
                        keywords_list=keywords_list,
                        industry_config=industry_config # âœ… PASS INDUSTRY CONFIG
                    )
                    # Ø¯Ù…Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù Ø§Ù„Ø°ÙƒÙŠ Ù…Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                    specialized_result["smart_targeting"] = smart_targeting_data
                    return specialized_result
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
            if not website_content or len(website_content) < 100:
                print("âš ï¸ ØªØ­Ø°ÙŠØ±: Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ ÙØ§Ø±Øº!")
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø¹ÙŠÙ†Ø© Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­ØªÙ‡
            print("=" * 80)
            print(f"ğŸ“„ Ø¹ÙŠÙ†Ø© Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ (Ø£ÙˆÙ„ 300 Ø­Ø±Ù):")
            print(website_content[:300] if len(website_content) > 300 else website_content)
            print("=" * 80)

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ù…Ø±Ø±Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
            keywords_line = ""
            if keywords_list and len(keywords_list) > 0:
                keywords_line = ', '.join(keywords_list)
                print(f"âœ… ØªÙ… Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ {len(keywords_list)} ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Google!")
                print(f"âœ… Ø£ÙˆÙ„ 5 ÙƒÙ„Ù…Ø§Øª: {keywords_list[:5]}")
            else:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡Ø§ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙƒÙ†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
                if "Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Google:" in website_content:
                    keywords_line = website_content.split("Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Google:")[1].split("\n")[0].strip()
                    print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ: {keywords_line[:200]}")
                elif "Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©:" in website_content:
                    keywords_line = website_content.split("Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©:")[1].split("\n")[0].strip()
                    print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {keywords_line[:200]}")
                else:
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù†ÙØ³Ù‡ ÙƒÙ€ fallback
                    print("âš ï¸ No keywords provided - extracting from website content...")
                    import re
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø·ÙˆÙŠÙ„Ø© (Ø£ÙƒØ«Ø± Ù…Ù† 3 Ø£Ø­Ø±Ù)
                    arabic_words = re.findall(r'[\u0600-\u06FF]{4,}', website_content)
                    # Ø£Ø®Ø° Ø£ÙƒØ«Ø± 10 ÙƒÙ„Ù…Ø§Øª ØªÙƒØ±Ø§Ø±Ø§Ù‹
                    from collections import Counter
                    word_counts = Counter(arabic_words)
                    top_keywords = [word for word, count in word_counts.most_common(10)]
                    if top_keywords:
                        keywords_line = ', '.join(top_keywords)
                        print(f"âœ… Extracted {len(top_keywords)} keywords from website content: {top_keywords[:5]}")
                    else:
                        # Ø¢Ø®Ø± fallback - ÙƒÙ„Ù…Ø§Øª Ø¹Ø§Ù…Ø©
                        keywords_line = "Ù…Ù†ØªØ¬Ø§Øª, Ø®Ø¯Ù…Ø§Øª, Ø¹Ø±ÙˆØ¶, Ø¬ÙˆØ¯Ø©, Ø£Ø³Ø¹Ø§Ø±"
                        print(f"âš ï¸ Using default fallback keywords")
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Google Ads Ù„Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø©
            campaign_requirements = self._get_campaign_requirements(campaign_type)
            
            # Convert language code to language name
            language_map = {
                'ar': 'Arabic', 'en': 'English', 'fr': 'French', 'de': 'German', 
                'es': 'Spanish', 'it': 'Italian', 'pt': 'Portuguese', 'ru': 'Russian',
                'zh-CN': 'Chinese (simplified)', 'zh-TW': 'Chinese (traditional)',
                'ja': 'Japanese', 'ko': 'Korean', 'hi': 'Hindi', 'tr': 'Turkish',
                'nl': 'Dutch', 'pl': 'Polish', 'sv': 'Swedish', 'th': 'Thai',
                'vi': 'Vietnamese', 'bn': 'Bengali', 'bg': 'Bulgarian', 'ca': 'Catalan',
                'cs': 'Czech', 'da': 'Danish', 'et': 'Estonian', 'fil': 'Filipino',
                'fi': 'Finnish', 'el': 'Greek', 'gu': 'Gujarati', 'he': 'Hebrew',
                'hu': 'Hungarian', 'is': 'Icelandic', 'id': 'Indonesian', 'kn': 'Kannada',
                'lv': 'Latvian', 'lt': 'Lithuanian', 'ms': 'Malay', 'ml': 'Malayalam',
                'mr': 'Marathi', 'no': 'Norwegian', 'fa': 'Persian', 'ro': 'Romanian',
                'sr': 'Serbian', 'sk': 'Slovak', 'sl': 'Slovenian', 'ta': 'Tamil',
                'te': 'Telugu', 'uk': 'Ukrainian', 'ur': 'Urdu'
            }
            
            language_name = language_map.get(target_language, 'English')
            self.logger.info(f"ğŸŒ Generating content in {language_name} (code: {target_language})")
            
            # Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù† Google
            comprehensive_prompt = f"""
âš ï¸ CRITICAL: You MUST carefully read and analyze the ACTUAL website content below to understand the business.
DO NOT generate generic content. ALL content must be SPECIFIC to the business described in the website content.

=== WEBSITE CONTENT (READ CAREFULLY) ===
{website_content}
===========================================

Campaign Type: {campaign_type}
Website URL: {website_url}

KEYWORDS FROM GOOGLE KEYWORD PLANNER:
{keywords_line}

Google Ads Requirements for {campaign_type}:
{campaign_requirements}

CRITICAL INSTRUCTION:
1. READ the website content above THOROUGHLY
2. IDENTIFY the exact business type (e.g., pet store, restaurant, travel agency, etc.)
3. EXTRACT real services/products mentioned in the website
4. Generate content that is SPECIFIC and RELEVANT to this exact business
5. DO NOT use generic phrases like "Ø®Ø¯Ù…Ø© Ù…ØªÙ…ÙŠØ²Ø©" or "Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ©" unless they match the business

REQUIREMENTS:

**HEADLINES (30 characters max) - DIVERSITY IS KEY FOR EXCELLENT:**
- Generate EXACTLY 30 unique headlines with HIGH DIVERSITY
- MUST be based on ACTUAL services/products from the website content
- Read the website content to identify the REAL business offerings
- Use SPECIFIC product/service names mentioned in the website
- Include location if present in website or keywords

**CRITICAL: Headlines MUST include variety:**
- 30% with NUMBERS: "Ø®Ø¨Ø±Ø© 15 Ø¹Ø§Ù…Ø§Ù‹", "Ø®ØµÙ… 20%", "Ø£ÙƒØ«Ø± Ù…Ù† 1000 Ø¹Ù…ÙŠÙ„"
- 30% with OFFERS: "Ø¹Ø±Ø¶ Ø®Ø§Øµ Ø§Ù„ÙŠÙˆÙ…", "Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø®ØµÙ…", "ØªØ®ÙÙŠØ¶Ø§Øª Ø§Ù„Ù…ÙˆØ³Ù…"
- 20% with KEYWORDS: "Ø¹Ø²Ù„ Ø£Ø³Ø·Ø­ Ø¨Ø§Ù„Ø±ÙŠØ§Ø¶", "ØªÙ†Ø³ÙŠÙ‚ Ø­Ø¯Ø§Ø¦Ù‚ Ù…Ù†Ø²Ù„ÙŠØ©"
- 20% with CTAs: "Ø§Ø­Ø¬Ø² Ø§Ù„Ø¢Ù†", "Ø§ØªØµÙ„ Ø§Ù„ÙŠÙˆÙ…", "Ø§Ø·Ù„Ø¨ Ø§Ø³ØªØ´Ø§Ø±Ø© Ù…Ø¬Ø§Ù†ÙŠØ©"

DO NOT use generic headlines - be specific to this business
Examples for travel: "Ø±Ø­Ù„Ø§Øª Ø³ÙØ§Ø±ÙŠ Ø¨Ø®ØµÙ… 15%", "Ø§Ø­Ø¬Ø² Ø±Ø­Ù„ØªÙƒ Ø§Ù„Ø¢Ù†", "Ø®Ø¨Ø±Ø© 10 Ø³Ù†ÙˆØ§Øª ÙÙŠ Ø§Ù„Ø³ÙØ§Ø±ÙŠ"
Examples for pet store: "Ø·Ø¹Ø§Ù… Ø­ÙŠÙˆØ§Ù†Ø§Øª Ø£ØµÙ„ÙŠ", "Ø®ØµÙ… Ø¹Ù„Ù‰ Ù…Ø³ØªÙ„Ø²Ù…Ø§Øª Ø§Ù„Ø¹Ù†Ø§ÙŠØ©", "Ø§Ø´ØªØ±Ù Ø§Ù„Ø¢Ù† ÙˆØ§Ø³ØªÙØ¯"

**DESCRIPTIONS (60-90 characters - CRITICAL FOR EXCELLENT AD STRENGTH):**
- Generate EXACTLY 5 descriptions (Google recommends 4-5 for EXCELLENT rating)
- Length: MINIMUM 60 characters, TARGET 80-90 characters (use full space!)
- MANDATORY: Each description MUST end with a Call-to-Action (CTA)
- MUST mention SPECIFIC services/products from the website content
- Structure: [Specific Service/Product] + [Real Benefit] + [Unique Value] + [Business-Appropriate CTA]
- Read the website to identify the business type, then use appropriate CTA
- Examples for travel: "Ø§Ø­Ø¬Ø² Ø§Ù„Ø¢Ù† ÙˆØ§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø®ØµÙ…", "Ø§ØªØµÙ„ Ù„Ø­Ø¬Ø² Ø±Ø­Ù„ØªÙƒ Ø§Ù„Ù…Ù…ÙŠØ²Ø©"
- Examples for store: "Ø§Ø´ØªØ±ÙŠ Ø§Ù„Ø¢Ù† Ø¨Ø£ÙØ¶Ù„ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±", "ØªØ³ÙˆÙ‚ Ø§Ù„ÙŠÙˆÙ… ÙˆØ§Ø³ØªÙØ¯ Ù…Ù† Ø§Ù„Ø¹Ø±ÙˆØ¶"
- Include specific benefits: prices, guarantees, experience years, unique features
- DO NOT use vague descriptions - be specific about what this business offers
- Use full character space (aim for 85-90 chars for better quality score)

**CALLOUTS (25 characters max) - CRITICAL FOR EXCELLENT AD STRENGTH:**
- Generate EXACTLY 8-10 callouts (Google recommends 6-10 for EXCELLENT rating)
- Each callout: MAXIMUM 25 characters
- âš ï¸ CRITICAL: Extract callouts from ACTUAL features mentioned in website content
- Categories to cover: Features, Benefits, Guarantees, Experience, Speed, Quality, Price
- Read what services/features the website offers and create callouts based on them
- Examples: "Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ù…Ø¬Ø§Ù†ÙŠØ©", "Ø¶Ù…Ø§Ù† 5 Ø³Ù†ÙˆØ§Øª", "Ø®Ø¨Ø±Ø© 15 Ø¹Ø§Ù…Ø§Ù‹", "Ø®Ø¯Ù…Ø© 24/7", "Ø£Ø³Ø¹Ø§Ø± ØªÙ†Ø§ÙØ³ÙŠØ©"
- If website mentions "Ø±Ø­Ù„Ø§Øª Ø³ÙØ§Ø±ÙŠ", use "Ø±Ø­Ù„Ø§Øª Ø³ÙØ§Ø±ÙŠ Ù…ØªÙ…ÙŠØ²Ø©"
- If website mentions "Ø·Ø¹Ø§Ù… Ø­ÙŠÙˆØ§Ù†Ø§Øª", use "Ø·Ø¹Ø§Ù… Ø­ÙŠÙˆØ§Ù†Ø§Øª Ø£ØµÙ„ÙŠ"
- DO NOT invent features - only use what's in the website content
- Mix of: service features, time/speed, quality, price, guarantees, experience

**STRUCTURED SNIPPETS - MUST EXTRACT FROM WEBSITE (CRITICAL FOR EXCELLENT):**
- âš ï¸ CRITICAL: Generate 2 different structured snippets for better coverage
- First snippet: Main category (e.g., "Ø§Ù„Ø®Ø¯Ù…Ø§Øª" or "Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª")
- Second snippet: Sub-category or complementary (e.g., "Ø§Ù„Ø£Ù†ÙˆØ§Ø¹" or "Ø§Ù„ÙØ¦Ø§Øª")
- Choose headers from: ["Ø§Ù„Ø®Ø¯Ù…Ø§Øª", "Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª", "Ø§Ù„Ø£Ù†ÙˆØ§Ø¹", "Ø§Ù„ÙØ¦Ø§Øª", "Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª", "Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª", "Ø§Ù„Ø£Ù†Ù…Ø§Ø·"]
- Each snippet: 3-6 values
- Each value: MAXIMUM 25 characters
- Values MUST be taken from actual content on the website
- Example for pet store: 
  - Snippet 1: header "Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª" with values like "Ø·Ø¹Ø§Ù… Ø­ÙŠÙˆØ§Ù†Ø§Øª", "Ù…Ø³ØªÙ„Ø²Ù…Ø§Øª Ø¹Ù†Ø§ÙŠØ©", "Ø£Ù„Ø¹Ø§Ø¨"
  - Snippet 2: header "Ø§Ù„Ø£Ù†ÙˆØ§Ø¹" with values like "Ù„Ù„Ù‚Ø·Ø·", "Ù„Ù„ÙƒÙ„Ø§Ø¨", "Ù„Ù„Ø·ÙŠÙˆØ±"
- DO NOT make up services/products - only use what's mentioned in website

**PROMOTION - BASED ON BUSINESS TYPE:**
- Read website to understand the business type
- Generate realistic promotional offer matching that business
- Name: MAXIMUM 15 characters
- Target: MAXIMUM 30 characters  
- Examples: Travel â†’ "Ø¹Ø±Ø¶ Ø±Ø­Ù„Ø§Øª", "Ø®ØµÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¬ÙˆØ²Ø§Øª"
- Examples: Store â†’ "Ø®ØµÙ… Ø§Ù„Ø§ÙØªØªØ§Ø­", "Ø¹Ø±Ø¶ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª"
- Must match the actual business type from website content

CRITICAL LANGUAGE REQUIREMENT:
ALL content (headlines, descriptions, keywords, callouts, structured_snippets, promotion) MUST be written in {language_name} language.
Use {language_name} professional, persuasive, industry-appropriate tone.

âš ï¸ FINAL REMINDER:
- You have read the website content at the top
- You know what business this is
- Generate content SPECIFIC to this business
- DO NOT use generic/template content
- Every headline, description, callout must reflect the ACTUAL business

Return VALID JSON (use the keywords provided above):
{{
    "headlines": ["headline 1", "headline 2", "headline 3", "headline 4", "headline 5", "headline 6", "headline 7", "headline 8", "headline 9", "headline 10", "headline 11", "headline 12", "headline 13", "headline 14", "headline 15", "headline 16", "headline 17", "headline 18", "headline 19", "headline 20", "headline 21", "headline 22", "headline 23", "headline 24", "headline 25", "headline 26", "headline 27", "headline 28", "headline 29", "headline 30"],
    "descriptions": ["description 1 (80-90 chars with CTA)", "description 2 (80-90 chars with CTA)", "description 3 (80-90 chars with CTA)", "description 4 (80-90 chars with CTA)", "description 5 (80-90 chars with CTA)"],
    "keywords": ["keyword1", "keyword2", "keyword3"],
    "callouts": ["callout 1 (from website)", "callout 2 (from website)", "callout 3 (from website)", "callout 4 (from website)", "callout 5 (from website)", "callout 6 (from website)", "callout 7 (from website)", "callout 8 (from website)", "callout 9 (optional)", "callout 10 (optional)"],
    "structured_snippets": [
        {{"header": "Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª", "values": ["value 1 (from website)", "value 2 (from website)", "value 3 (from website)", "value 4 (from website)"]}},
        {{"header": "Ø§Ù„Ø£Ù†ÙˆØ§Ø¹", "values": ["type 1 (from website)", "type 2 (from website)", "type 3 (from website)"]}}
    ],
    "promotion": {{"name": "Ø¹Ø±Ø¶ Ø®Ø§Øµ", "target": "Ø¹Ø±Ø¶ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†Ø´Ø§Ø· Ø§Ù„ØªØ¬Ø§Ø±ÙŠ"}},
    "recommended_campaign_type": "{campaign_type.lower()}",
    "confidence_score": 95,
    "reasoning": "Created content based on Google keywords with industry-appropriate CTAs",
    "colors": {{"primary": "#hex", "secondary": "#hex", "accent": "#hex"}},
    "color_palette": ["#hex1", "#hex2", "#hex3"],
    "brand_style": "modern professional"
            }}
            """
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            print("=" * 80)
            print("ğŸ¤– Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù…Ø±Ø³Ù„ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:")
            print("=" * 80)
            print(f"ğŸ“Š Ø·ÙˆÙ„ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª: {len(comprehensive_prompt)} Ø­Ø±Ù")
            print(f"ğŸ“ Ø£ÙˆÙ„ 1500 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª:")
            print(comprehensive_prompt[:1500] + "..." if len(comprehensive_prompt) > 1500 else comprehensive_prompt)
            print("=" * 80)
            
            # Ø·Ù„Ø¨ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ù…
            ai_response = self._call_cometapi(comprehensive_prompt)
            
            if ai_response.get("success"):
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© ØªØ­Ù„ÙŠÙ„ JSON Ø§Ù„Ù…Ø­Ø³Ù†Ø©
                content = ai_response.get("content", "{}")
                
                print("=" * 80)
                print("âœ… Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:")
                print("=" * 80)
                print(content[:800] + "..." if len(content) > 800 else content)
                print("=" * 80)
                
                parsed_result = self._parse_json_response(content)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„
                if "error" in parsed_result:
                    self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON: {parsed_result['error']}")
                    return {
                        "success": False,
                        "error": "ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
                        "message": "Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØµØ­ÙŠØ­Ø© Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
                    }
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø­Ù„Ù„Ø©
                ad_copies = []
                headlines = parsed_result.get("headlines", [])
                descriptions = parsed_result.get("descriptions", [])
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø® Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ø£ÙˆØµØ§Ù
                for i, headline in enumerate(headlines[:5]):
                    description = descriptions[i] if i < len(descriptions) else descriptions[0] if descriptions else "ÙˆØµÙ Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ø­ØªÙŠØ§Ø·ÙŠ"
                    ad_copies.append({
                        "headline": headline,
                        "description": description,
                        "final_url": website_url,
                        "match_type": "BROAD",
                        "bid_amount": 2500000  # 2.5 Ø¯ÙˆÙ„Ø§Ø±
                    })
                
                # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
                brand_colors = parsed_result.get("colors", {})
                image_result = self.generate_ad_images(product_service, website_url, brand_colors)
                
                # ØªÙ†Ø¸ÙŠÙ Headlines Ùˆ Descriptions Ùˆ Keywords Ù…Ù† Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ (Google Ads Policy)
                self.logger.info("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡ÙˆØ§ØªÙ (Google Ads Policy)...")
                cleaned_headlines = [remove_phone_numbers(h) for h in headlines if h]
                cleaned_descriptions = [remove_phone_numbers(d) for d in descriptions if d]
                cleaned_keywords = [remove_phone_numbers(k) for k in parsed_result.get("keywords", []) if k]
                
                # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ù†ØµÙˆØµ ÙØ§Ø±ØºØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
                cleaned_headlines = [h for h in cleaned_headlines if h.strip()]
                cleaned_descriptions = [d for d in cleaned_descriptions if d.strip()]
                cleaned_keywords = [k for k in cleaned_keywords if k.strip()]
                
                self.logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(headlines)} headlines â†’ {len(cleaned_headlines)} Ù†Ø¸ÙŠÙØ©")
                self.logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(descriptions)} descriptions â†’ {len(cleaned_descriptions)} Ù†Ø¸ÙŠÙØ©")
                self.logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {len(parsed_result.get('keywords', []))} keywords â†’ {len(cleaned_keywords)} Ù†Ø¸ÙŠÙØ©")
                
                # ØªØ­Ø¯ÙŠØ« ad_copies Ø¨Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ù†Ø¸ÙØ©
                cleaned_ad_copies = []
                for i, headline in enumerate(cleaned_headlines[:5]):
                    description = cleaned_descriptions[i] if i < len(cleaned_descriptions) else cleaned_descriptions[0] if cleaned_descriptions else "ÙˆØµÙ Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ø­ØªØ±Ø§Ù"
                    cleaned_ad_copies.append({
                        "headline": headline,
                        "description": description,
                        "final_url": website_url,
                        "match_type": "BROAD",
                        "bid_amount": 2500000
                    })
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£ØµÙˆÙ„ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ù…Ù† AI Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
                callouts = parsed_result.get("callouts", [])[:10]  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 10
                structured_snippets_raw = parsed_result.get("structured_snippets", [])
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© structured_snippets - ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† array Ø£Ùˆ object
                if isinstance(structured_snippets_raw, list):
                    structured_snippets = structured_snippets_raw[:2]  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 2
                elif isinstance(structured_snippets_raw, dict):
                    # ØªØ­ÙˆÙŠÙ„ object ÙˆØ§Ø­Ø¯ Ø¥Ù„Ù‰ array
                    structured_snippets = [structured_snippets_raw]
                else:
                    structured_snippets = []
                
                promotion = parsed_result.get("promotion", {})
                
                # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø£ØµÙˆÙ„ Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ù„Ù„ØªØ£ÙƒØ¯
                if callouts:
                    print(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(callouts)} Callouts Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {callouts}")
                if structured_snippets:
                    print(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(structured_snippets)} Structured Snippets Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {structured_snippets}")
                if promotion:
                    print(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Promotion Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {promotion}")
                
                result = {
                    "success": True,
                    "smart_targeting": smart_targeting_data,
                    "product_service": product_service,
                    "website_url": website_url,
                    "headlines": cleaned_headlines,
                    "descriptions": cleaned_descriptions,
                    "keywords": cleaned_keywords,
                    "callouts": callouts if callouts else [],  # 8-10 callouts Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ EXCELLENT
                    "structured_snippets": structured_snippets if structured_snippets else [],  # 1-2 snippets
                    "promotion": promotion if promotion else {},
                    "ad_copies": cleaned_ad_copies,
                    "recommended_campaign_type": parsed_result.get("recommended_campaign_type", "search_ads"),
                    "confidence_score": parsed_result.get("confidence_score", 0),
                    "reasoning": parsed_result.get("reasoning", ""),
                    "alternative_types": parsed_result.get("alternative_types", []),
                    "colors": brand_colors,
                    "color_palette": parsed_result.get("color_palette", []),
                    "brand_style": parsed_result.get("brand_style", "modern, clean, professional"),
                    "website_content": website_content,
                    "timestamp": datetime.now().isoformat(),
                    "errors": [],
                    "images": {
                        "success": image_result.get("success", False),
                        "image_url": image_result.get("image_url", ""),
                        "error": image_result.get("error", "") if not image_result.get("success") else ""
                    }
                }
            else:
                # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ø·Ù„Ø¨ØŒ Ø¥Ø±Ø¬Ø§Ø¹ Ø®Ø·Ø£
                return {
                    "success": False,
                    "error": ai_response.get("error", "Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"),
                    "message": "Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
                }
            
            self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„"
            }
    
    def generate_single_ad_element(self, element_type: str, website_url: str, existing_content: Dict = None, keywords_list: list = None, language: str = 'ar') -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø¹Ù†ØµØ± Ø¥Ø¹Ù„Ø§Ù†ÙŠ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· (headline Ø£Ùˆ description) Ø¨Ø³Ø±Ø¹Ø©"""
        try:
            # Language mapping
            language_map = {
                'ar': 'Arabic', 'en': 'English', 'fr': 'French', 'de': 'German', 
                'es': 'Spanish', 'it': 'Italian', 'pt': 'Portuguese', 'ru': 'Russian',
                'zh-CN': 'Chinese (simplified)', 'zh-TW': 'Chinese (traditional)',
                'ja': 'Japanese', 'ko': 'Korean', 'hi': 'Hindi', 'tr': 'Turkish',
                'nl': 'Dutch', 'pl': 'Polish', 'sv': 'Swedish', 'th': 'Thai',
                'vi': 'Vietnamese'
            }
            
            language_name = language_map.get(language, 'English')
            self.logger.info(f"ğŸš€ ØªÙˆÙ„ÙŠØ¯ {element_type} ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ø¨Ù„ØºØ© {language_name}")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
            keywords_line = ""
            if keywords_list and len(keywords_list) > 0:
                keywords_line = ', '.join(keywords_list[:5])  # Ø£ÙˆÙ„ 5 ÙƒÙ„Ù…Ø§Øª ÙÙ‚Ø· Ù„Ù„Ø³Ø±Ø¹Ø©
            elif existing_content and existing_content.get('keywords'):
                keywords_line = ', '.join(existing_content['keywords'][:5])
            
            # Ø¨Ø±ÙˆÙ…Ø¨Øª Ù…Ø®ØªØµØ± ÙˆØ³Ø±ÙŠØ¹ (Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©)
            if element_type == 'headline':
                prompt = f"""Generate ONE new Google Ads headline in {language_name}.

Keywords: {keywords_line}
Website: {website_url}

CRITICAL LANGUAGE REQUIREMENT:
Write ONLY in {language_name} language. Do NOT use any other language.

Requirements:
- Maximum 30 characters
- Use keywords naturally
- Different from existing headlines
- Focus on benefits
- Professional {language_name} tone

Return ONLY JSON:
{{"headline": "your headline here in {language_name}"}}"""
            else:  # description
                prompt = f"""Generate ONE new Google Ads description in {language_name}.

Keywords: {keywords_line}
Website: {website_url}

CRITICAL LANGUAGE REQUIREMENT:
Write ONLY in {language_name} language. Do NOT use any other language.

Requirements:
- 60-90 characters (MINIMUM 60)
- MUST end with a Call-to-Action (CTA)
- Use keywords naturally
- Different from existing descriptions
- Structure: [Value] + [Benefit] + [CTA]
- Professional {language_name} tone

Return ONLY JSON:
{{"description": "your description here with CTA in {language_name}"}}"""
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø³Ø±ÙŠØ¹ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
            ai_response = self._call_cometapi(prompt)
            
            if ai_response.get("success"):
                content = ai_response.get("content", "{}")
                parsed_result = self._parse_json_response(content)
                
                if element_type == 'headline' and 'headline' in parsed_result:
                    return {
                        "success": True,
                        "text": parsed_result['headline']
                    }
                elif element_type == 'description' and 'description' in parsed_result:
                    return {
                        "success": True,
                        "text": parsed_result['description']
                    }
                else:
                    return {
                        "success": False,
                        "error": "No valid content in response"
                    }
            else:
                return {
                    "success": False,
                    "error": ai_response.get("error", "AI call failed")
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ {element_type}: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def generate_ad_images(self, product_service: str, website_url: str, brand_colors: Dict[str, str] = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DALL-E 3"""
        try:
            self.logger.info(f"ğŸ¨ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù„Ù„Ù…Ù†ØªØ¬: {product_service}")
            
            # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù„Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¬/Ø§Ù„Ø®Ø¯Ù…Ø©
            image_prompt = f"""
            Create a professional advertisement image for: {product_service}
            Website: {website_url}
            
            Requirements:
            - Professional, clean, modern design
            - Suitable for Google Ads display campaigns
            - High quality, commercial use
            - Brand colors: {brand_colors.get('primary', '#1A1A1A') if brand_colors else '#1A1A1A'}
            - Arabic-friendly design
            - No text overlay (text will be added separately)
            - 1024x1024 pixels, square format
            - Bright, engaging, trustworthy appearance
            """
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.image_model,
                "prompt": image_prompt,
                "n": 1,
                "size": "1024x1024",
                "quality": "standard",
                "style": "natural"
            }
            
            response = requests.post(
                f"{self.base_url}/v1/images/generations",
                headers=headers,
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                if "data" in result and len(result["data"]) > 0:
                    image_url = result["data"][0]["url"]
                    self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
                    return {
                        "success": True,
                        "image_url": image_url,
                        "product_service": product_service,
                        "website_url": website_url,
                        "brand_colors": brand_colors,
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "error": "No image generated",
                        "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}",
                    "message": "ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©"
            }

    def generate_campaign_images(self, campaign_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø© ÙˆÙ…Ø­ØªÙˆØ§Ù‡Ø§ ÙˆÙƒÙ„Ù…Ø§ØªÙ‡Ø§ Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        try:
            self.logger.info(f"ğŸ¨ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù„Ù„Ø­Ù…Ù„Ø©: {campaign_type}")
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØµÙˆØ± Ù„Ù„Ø­Ù…Ù„Ø©
            image_requirements = self.get_campaign_image_requirements()
            campaign_requirements = image_requirements.get(campaign_type, {})
            
            if not campaign_requirements.get("required", False):
                self.logger.info(f"âœ… Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© {campaign_type} Ù„Ø§ ÙŠØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§")
                return {
                    "success": True,
                    "message": f"Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© {campaign_type} Ù„Ø§ ÙŠØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§",
                    "campaign_type": campaign_type,
                    "images": []
                }
            
            # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù„Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰
            image_prompt = self._create_campaign_image_prompt(campaign_type, product_service, website_url, keywords, brand_colors)
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø­Ø³Ø¨ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©
            generated_images = []
            images_config = campaign_requirements.get("images", {})
            
            for image_type, image_config in images_config.items():
                try:
                    # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù…Ø­Ø¯Ø¯ Ù„ÙƒÙ„ Ù†ÙˆØ¹ ØµÙˆØ±Ø©
                    specific_prompt = f"{image_prompt}\n\nImage type: {image_type}\nSize: {image_config.get('size', '1024x1024')}\nAspect ratio: {image_config.get('aspect_ratio', '1:1')}"
                    
                    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©
                    image_result = self._generate_single_image(specific_prompt, image_config)
                    
                    if image_result.get("success"):
                        generated_images.append({
                            "type": image_type,
                            "url": image_result["image_url"],
                            "size": image_config.get("size", "1024x1024"),
                            "aspect_ratio": image_config.get("aspect_ratio", "1:1"),
                            "format": image_config.get("formats", ["JPEG", "PNG"])[0]
                        })
                        self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type} Ø¨Ù†Ø¬Ø§Ø­")
                    else:
                        self.logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {image_result.get('error')}")
                        
                except Exception as e:
                    self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {e}")
                    continue
            
            if generated_images:
                self.logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(generated_images)} ØµÙˆØ±Ø© Ù„Ù„Ø­Ù…Ù„Ø© {campaign_type}")
                return {
                    "success": True,
                    "campaign_type": campaign_type,
                    "product_service": product_service,
                    "website_url": website_url,
                    "keywords": keywords,
                    "brand_colors": brand_colors,
                    "images": generated_images,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "success": False,
                    "error": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø£ÙŠ ØµÙˆØ±Ø©",
                    "message": "Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø£ÙŠ ØµÙˆØ±Ø© Ù„Ù„Ø­Ù…Ù„Ø©"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø§Ù„Ø­Ù…Ù„Ø©: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø§Ù„Ø­Ù…Ù„Ø©"
            }
    
    def generate_campaign_images_detailed(self, campaign_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None) -> List[Dict[str, Any]]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ù„Ù„Ø­Ù…Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©"""
        try:
            logger.info(f"ğŸ¨ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© Ù„Ù„Ù…Ù†ØªØ¬: {product_service}")
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØµÙˆØ± Ù„Ù„Ø­Ù…Ù„Ø©
            image_requirements = self.get_campaign_image_requirements().get(campaign_type, {})
            
            if not image_requirements.get("required", False):
                logger.info(f"Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© {campaign_type} Ù„Ø§ ÙŠØªØ·Ù„Ø¨ ØµÙˆØ±Ù‹Ø§")
                return []
            
            generated_images = []
            images_config = image_requirements.get("images", {})
            min_images = image_requirements.get("min_images", 1)
            max_images = image_requirements.get("max_images", 10)
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù† Ø§Ù„ØµÙˆØ± Ù„ÙƒÙ„ Ù†ÙˆØ¹
            for image_type, config in images_config.items():
                try:
                    # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹
                    images_needed = min(max_images, max(min_images, 1))
                    
                    for i in range(images_needed):
                        image_data = self._generate_single_image_detailed(
                            campaign_type=campaign_type,
                            image_type=image_type,
                            product_service=product_service,
                            website_url=website_url,
                            keywords=keywords,
                            brand_colors=brand_colors,
                            config=config,
                            image_index=i + 1
                        )
                        
                        if image_data:
                            generated_images.append(image_data)
                            logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type} #{i + 1} Ø¨Ù†Ø¬Ø§Ø­")
                    
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {str(e)}")
                    continue
            
            logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(generated_images)} ØµÙˆØ±Ø© Ø¥Ø¹Ù„Ø§Ù†ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
            return generated_images
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©: {str(e)}")
            return []

    def _create_campaign_image_prompt(self, campaign_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø©"""
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ø£Ø³Ø§Ø³ÙŠ
        base_prompt = f"""
        Create a professional advertisement image for: {product_service}
        Website: {website_url}
        Keywords: {', '.join(keywords[:5])}
        Brand colors: {brand_colors.get('primary', '#1A1A1A') if brand_colors else '#1A1A1A'}
        
        Requirements:
        - Professional, clean, modern design
        - High quality, commercial use
        - Arabic-friendly design
        - NO TEXT, NO WORDS, NO LETTERS on the image (absolutely no text overlay - text will be added separately by the ad system)
        - Pure visual design without any written content
        - Bright, engaging, trustworthy appearance
        - Image only, no typography
        """
        
        # Ø¥Ø¶Ø§ÙØ© Ù…ØªØ·Ù„Ø¨Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ù„ÙƒÙ„ Ù†ÙˆØ¹ Ø­Ù…Ù„Ø©
        campaign_specific_prompts = {
            "SEARCH": """
            - Suitable for Search campaigns
            - Text-based ads with image assets for enhancement
            - Professional and trustworthy appearance
            - Clear and compelling messaging
            - Square and landscape image formats
            """,
            "PERFORMANCE_MAX": """
            - Suitable for Performance Max campaigns
            - Works across all Google networks (Search, Display, YouTube, Gmail, Discover)
            - Versatile design that works in different contexts
            - Eye-catching and conversion-focused
            """,
            "DISPLAY": """
            - Suitable for Display campaigns
            - Visual appeal for website banners and ads
            - Attention-grabbing design
            - Professional and trustworthy appearance
            """,
            "VIDEO": """
            - Suitable for Video campaign thumbnails
            - High visual impact for video content
            - Engaging and click-worthy design
            - Professional video thumbnail style
            """,
            "SHOPPING": """
            - Suitable for Shopping campaigns
            - Product-focused design
            - Clean and professional product presentation
            - E-commerce friendly appearance
            - High-quality product images
            """,
            "SMART": """
            - Suitable for Smart campaigns
            - Automated campaign friendly design
            - Simple and clear visual message
            - Professional business appearance
            """,
            "LOCAL": """
            - Suitable for Local campaigns
            - Local business focused design
            - Community and location-based appeal
            - Professional local service appearance
            """,
            "DISCOVERY": """
            - Suitable for Discovery campaigns
            - Engaging and discovery-focused design
            - Eye-catching for feed content
            - Modern and appealing appearance
            """,
            "TRAVEL": """
            - Suitable for Travel campaigns
            - Travel and tourism focused design
            - Destination and experience appeal
            - Professional travel service appearance
            """,
            "DEMAND_GEN": """
            - Suitable for Demand Gen campaigns
            - Demand generation focused design
            - Engaging and conversion-oriented
            - Professional marketing appearance
            """,
            "MULTI_CHANNEL": """
            - Suitable for Multi-Channel campaigns
            - App and mobile focused design
            - Modern app store appearance
            - Professional mobile app design
            - App icon, screenshot, and banner formats
            """
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„Ù„Ø­Ù…Ù„Ø©
        campaign_prompt = campaign_specific_prompts.get(campaign_type, "")
        
        return f"{base_prompt}\n{campaign_prompt}"
    
    def _generate_single_image(self, prompt: str, image_config: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Flux-1.1-Pro-Ultra (Ø£Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© ÙˆØ§Ù‚Ø¹ÙŠØ©)"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            # ØªØ­Ø¯ÙŠØ¯ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø© - Flux Ultra ÙŠØ¯Ø¹Ù… Ø£Ø­Ø¬Ø§Ù… Ù…Ø®ØµØµØ©
            width = 1024
            height = 1024
            
            size = image_config.get("size", "1024x1024")
            if "x" in size or "Ã—" in size:
                try:
                    dims = size.replace("Ã—", "x").split("x")
                    width = int(dims[0])
                    height = int(dims[1])
                except:
                    width, height = 1024, 1024
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4o-mini Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØµÙˆØ± ÙˆØ§Ù‚Ø¹ÙŠØ© 100%
            enhanced_prompt = self._enhance_prompt_with_gpt4o(prompt)
            
            data = {
                "model": self.image_model,
                "prompt": enhanced_prompt,
                "width": width,
                "height": height,
                "aspect_ratio": "16:9" if width > height else "1:1",  # Flux Ultra ÙŠØ¯Ø¹Ù… aspect ratios
                "output_format": "jpeg",  # JPEG Ù„Ù„ØµÙˆØ± Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©
                "safety_tolerance": 2  # Ø£Ù‚Ù„ ØªÙ‚ÙŠÙŠØ¯ Ù„Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©
            }
            
            response = requests.post(
                f"{self.base_url}/v1/images/generations",
                headers=headers,
                json=data,
                timeout=180
            )
            
            if response.status_code == 200:
                result = response.json()
                if "data" in result and len(result["data"]) > 0:
                    image_url = result["data"][0]["url"]
                    return {
                        "success": True,
                        "image_url": image_url
                    }
                else:
                    return {
                        "success": False,
                        "error": "No image generated"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _enhance_prompt_with_gpt4o(self, prompt: str) -> str:
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4o-mini"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.text_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "You are a professional photography director specializing in PHOTOREALISTIC commercial photography. Your job is to enhance image prompts to achieve 100% realistic, documentary-style photographs - NOT AI-generated looking images. Focus on: camera settings, natural lighting, authentic environments, real materials, professional workers, and genuine work scenes."
                    },
                    {
                        "role": "user",
                        "content": f"Enhance this prompt for PHOTOREALISTIC documentary photography. The result must look like a real photograph taken with a professional DSLR camera, NOT an AI-generated image:\n\n{prompt}\n\nAdd specific details about: camera angle, lighting conditions, authentic worker appearance, real tool usage, genuine environment details, natural colors, and realistic textures. Make it look 100% like real documentary photography."
                    }
                ],
                "max_tokens": 400,
                "temperature": 0.6
            }
            
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                enhanced = result["choices"][0]["message"]["content"].strip()
                self.logger.info(f"âœ¨ ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨ÙˆØ§Ø³Ø·Ø© GPT-4o-mini")
                return enhanced
            else:
                self.logger.warning(f"ÙØ´Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨ØªØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£ØµÙ„ÙŠ")
                return prompt
                
        except Exception as e:
            self.logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª: {e}")
            return prompt

    def _generate_single_image_detailed(self, campaign_type: str, image_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None, config: Dict[str, Any] = None, image_index: int = 1, website_content: str = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø®ØµØµ
            prompt = self._create_detailed_image_prompt(
                campaign_type=campaign_type,
                image_type=image_type,
                product_service=product_service,
                website_url=website_url,
                keywords=keywords,
                brand_colors=brand_colors,
                config=config,
                image_index=image_index,
                website_content=website_content
            )
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©
            response = self._call_cometapi_image(prompt, config)
            
            if response.get("success"):
                return {
                    "success": True,
                    "image_type": image_type,
                    "campaign_type": campaign_type,
                    "image_index": image_index,
                    "config": config,
                    "image_url": response.get("image_url"),
                    "prompt": prompt,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {response.get('error')}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© {image_type}: {str(e)}")
            return None

    def _analyze_service_type(self, service_context: str, product_service: str, keywords_text: str = "", website_description: str = "") -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ù…Ø®ØµØµØ©"""
        
        text = f"{service_context} {product_service}".lower()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ - Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£ÙŠ Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø«Ø§Ø¨ØªØ©
        return self._extract_fully_dynamic_service_details(text, keywords_text, website_description)

    def _extract_fully_dynamic_service_details(self, text: str, keywords_text: str, website_description: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ 100% Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙÙ‚Ø· - Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù‚ÙˆØ§Ù„Ø¨ Ø«Ø§Ø¨ØªØ©"""

        # Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
        all_text = f"{text} {keywords_text} {website_description}".lower()

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ ÙƒØ§Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø«Ø§Ø¨ØªØ©
        return {
            "worker_action": self._extract_action_dynamically(all_text),
            "tools": self._extract_tools_dynamically(all_text),
            "material_color": self._extract_materials_dynamically(all_text),
            "environment": self._extract_environment_dynamically(all_text),
            "uniform_color": self._extract_uniform_dynamically(all_text)
        }

    def _extract_action_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¹Ø§Ù„ ÙˆØ¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ
        action_patterns = [
            r"ÙŠ(\w+)",  # Ø£ÙØ¹Ø§Ù„ Ø¨Ø§Ù„ÙŠØ§Ø¡
            r"Ù†(\w+)",  # Ø£ÙØ¹Ø§Ù„ Ø¨Ø§Ù„Ù†ÙˆÙ†
            r"Øª(\w+)",  # Ø£ÙØ¹Ø§Ù„ Ø¨Ø§Ù„ØªØ§Ø¡
            r"(\w+)ing",  # Ø£ÙØ¹Ø§Ù„ Ø¨Ø§Ù„Ù€ ing
        ]

        import re
        actions = []
        for pattern in action_patterns:
            matches = re.findall(pattern, text)
            actions.extend(matches[:2])  # Ø£ÙˆÙ„ ÙƒÙ„Ù…ØªÙŠÙ† ÙÙ‚Ø·

        return actions[0] if actions else "professional work"

    def _extract_tools_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆØ§Øª
        tool_indicators = [
            "Ø´Ø§Ø­Ù†Ø©", "Ø³ÙŠØ§Ø±Ø©", "ØµÙ†Ø§Ø¯ÙŠÙ‚", "Ø£Ø¯ÙˆØ§Øª", "Ù…Ø¹Ø¯Ø§Øª", "Ø­Ø¨Ø§Ù„", "Ø´Ø±Ø§Ø¦Ø·",
            "ØºÙ„Ø§Ù", "Ø­Ù…Ø§ÙŠØ©", "ÙØ±Ø´", "Ø£Ø¬Ù‡Ø²Ø©", "Ù…Ø§ÙƒÙŠÙ†Ø§Øª", "truck", "tools",
            "equipment", "boxes", "ropes", "tape", "wrapping", "padding"
        ]

        found_tools = []
        for indicator in tool_indicators:
            if indicator in text:
                found_tools.append(indicator)

        return found_tools[0] if found_tools else "professional equipment"

    def _extract_materials_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ø£Ù„ÙˆØ§Ù†
        material_indicators = [
            "Ø®Ø´Ø¨", "Ù…Ø¹Ø¯Ù†", "Ø¨Ù„Ø§Ø³ØªÙŠÙƒ", "Ø²Ø¬Ø§Ø¬", "Ù‚Ù…Ø§Ø´", "Ø¬Ù„Ø¯", "ÙˆØ±Ù‚",
            "Ø£Ø¨ÙŠØ¶", "Ø£Ø³ÙˆØ¯", "Ø£Ø²Ø±Ù‚", "Ø£Ø­Ù…Ø±", "Ø£Ø®Ø¶Ø±", "Ø£ØµÙØ±", "Ø¨Ù†ÙŠ",
            "wood", "metal", "plastic", "glass", "fabric", "leather", "paper"
        ]

        found_materials = []
        for indicator in material_indicators:
            if indicator in text:
                found_materials.append(indicator)

        return found_materials[0] if found_materials else "standard materials"

    def _extract_environment_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ¦Ø©
        env_indicators = [
            "Ø´Ù‚Ø©", "Ù…Ù†Ø²Ù„", "Ù…ÙƒØªØ¨", "Ù…Ø³ØªÙˆØ¯Ø¹", "Ù…Ø­Ù„", "Ù…Ø¨Ù†Ù‰", "Ø®Ø§Ø±Ø¬ÙŠ", "Ø¯Ø§Ø®Ù„ÙŠ",
            "Ø³ÙƒÙ†ÙŠ", "ØªØ¬Ø§Ø±ÙŠ", "apartment", "house", "office", "warehouse", "outdoor"
        ]

        found_envs = []
        for indicator in env_indicators:
            if indicator in text:
                found_envs.append(indicator)

        return found_envs[0] if found_envs else "business location"

    def _extract_uniform_dynamically(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø²ÙŠ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
        color_indicators = [
            "Ø£Ø²Ø±Ù‚", "Ø£Ø¨ÙŠØ¶", "Ø£Ø³ÙˆØ¯", "Ø£Ø­Ù…Ø±", "Ø£Ø®Ø¶Ø±", "Ø£ØµÙØ±", "Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠ", "Ø¨Ù†ÙŠ",
            "Ø±Ù…Ø§Ø¯ÙŠ", "ÙˆØ±Ø¯ÙŠ", "blue", "white", "black", "red", "green", "yellow"
        ]

        found_colors = []
        for indicator in color_indicators:
            if indicator in text:
                found_colors.append(indicator)

        return found_colors[0] if found_colors else "professional uniform"
    
    def _create_detailed_image_prompt(self, campaign_type: str, image_type: str, product_service: str, website_url: str, keywords: List[str], brand_colors: Dict[str, str] = None, config: Dict[str, Any] = None, image_index: int = 1, website_content: str = None) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù…ÙØµÙ„ Ù„Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø­Ù…Ù„Ø© ÙˆÙ†ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø©
        size = config.get("size", "1200Ã—628") if config else "1200Ã—628"
        aspect_ratio = config.get("aspect_ratio", "1.91:1") if config else "1.91:1"
        description = config.get("description", "ØµÙˆØ±Ø© Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©") if config else "ØµÙˆØ±Ø© Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©"
        field_type = config.get("field_type", "AD_IMAGE") if config else "AD_IMAGE"
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ùˆ website_content
        top_keywords = keywords[:5] if keywords else []
        service_context = ', '.join(top_keywords) if top_keywords else product_service
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… website_content Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªÙˆÙØ±Ø§Ù‹ Ù„ØªØ­Ø³ÙŠÙ† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø©
        if website_content:
            service_context = f"{service_context}, {website_content[:300]}"  # Ø£ÙˆÙ„ 300 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ù…Ù† ÙØ­Øµ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        keywords_text = ', '.join(top_keywords[:10]) if top_keywords else product_service
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØµÙ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„ÙØ¹Ù„ÙŠ
        website_description = ""
        if website_content:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ 400 Ø­Ø±Ù Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹
            website_description = website_content[:400].strip()
        
        # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        service_analysis = self._analyze_service_type(service_context, product_service, keywords_text, website_description)
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙÙ‚Ø· - Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø«Ø§Ø¨ØªØ©
        base_prompt = self._create_fully_dynamic_prompt(
            keywords_text, website_description
        )
        
        # ØªÙˆÙ„ÙŠØ¯ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´ÙŠØ¡ Ø«Ø§Ø¨Øª - Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒØ§Ù…Ù„ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙÙ‚Ø·
        return self._generate_purely_dynamic_prompt(
            keywords_text, website_description
        )

    def _generate_purely_dynamic_prompt(self, keywords_text: str, website_description: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´ÙŠØ¡ Ø«Ø§Ø¨Øª - ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙ‚Ø·"""

        # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
        combined_text = f"{keywords_text} {website_description}"

        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ±
        analysis_result = self._ai_analyze_content(combined_text)

        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙ‚Ø·
        prompt_parts = []

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        for category, items in analysis_result.items():
            if items and len(items) > 0:
                prompt_parts.append(f"{category.upper()}: {', '.join(items[:3])}")

        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø£ÙŠ Ø¹Ù†Ø§ØµØ±ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¹Ø§Ù…
        if not prompt_parts:
            prompt_parts.append("PROFESSIONAL: High quality professional photography")
            prompt_parts.append(f"CONTENT: {keywords_text}")
            prompt_parts.append(f"DESCRIPTION: {website_description[:200]}")

        return "\n".join(prompt_parts)

    def _extract_all_info_dynamically(self, text: str) -> Dict[str, str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù‚ÙˆØ§Ù…ÙŠØ³ Ø«Ø§Ø¨ØªØ© Ø£Ùˆ Ø§ÙØªØ±Ø§Ø¶Ø§Øª"""

        info = {}

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ ÙƒØ§Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù‚ÙˆØ§Ù…ÙŠØ³ Ø«Ø§Ø¨ØªØ© - ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙƒÙŠ
        all_extracted = self._analyze_text_intelligently(text)

        # ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹Ù‡Ø§ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹
        for category, items in all_extracted.items():
            if items and len(items) > 0:
                info[category] = f"{category}: {', '.join(items[:3])}"

        return info

    # ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø«Ø§Ø¨ØªØ© - Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¢Ù† Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ 100% ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙƒÙŠ

    def _analyze_text_intelligently(self, text: str) -> Dict[str, List[str]]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù‚ÙˆØ§Ù…ÙŠØ³ Ø«Ø§Ø¨ØªØ©"""

        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ù‡Ù…Ø©
        return self._ai_analyze_content(text)

    def _ai_analyze_content(self, text: str) -> Dict[str, List[str]]:
        """Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ù‡Ù…Ø©"""

        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… TEXT_MODEL Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø°ÙƒÙŠ
            prompt = f"""
            Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ù‡Ù…Ø© Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø§Ø­ØªØ±Ø§ÙÙŠØ©:

            Ø§Ù„Ù†Øµ: {text}

            Ù‚Ù… Ø¨ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ù†Ø§ØµØ± ÙÙŠ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:
            - location: Ø£Ù…Ø§ÙƒÙ† ÙˆÙ…Ø¯Ù† Ù…Ø°ÙƒÙˆØ±Ø©
            - service: Ø®Ø¯Ù…Ø§Øª ÙˆØ£Ù†Ø´Ø·Ø© Ù…Ø°ÙƒÙˆØ±Ø©
            - workers: Ø£Ø´Ø®Ø§Øµ ÙˆØ¹Ø§Ù…Ù„ÙŠÙ† Ù…Ø°ÙƒÙˆØ±ÙŠÙ†
            - tools: Ø£Ø¯ÙˆØ§Øª ÙˆÙ…Ø¹Ø¯Ø§Øª Ù…Ø°ÙƒÙˆØ±Ø©
            - materials: Ù…ÙˆØ§Ø¯ ÙˆØ®Ø§Ù…Ø§Øª Ù…Ø°ÙƒÙˆØ±Ø©
            - environment: Ø£Ù…Ø§ÙƒÙ† ÙˆØ¨ÙŠØ¦Ø§Øª Ù…Ø°ÙƒÙˆØ±Ø©
            - actions: Ø£ÙØ¹Ø§Ù„ ÙˆØ£Ù†Ø´Ø·Ø© Ù…Ø°ÙƒÙˆØ±Ø©
            - objects: Ø£Ø´ÙŠØ§Ø¡ ÙˆÙ…ÙˆØ§Ø¯ Ù…Ø°ÙƒÙˆØ±Ø©
            - qualities: Ù…ØµØ·Ù„Ø­Ø§Øª Ø¬ÙˆØ¯Ø© Ù…Ø°ÙƒÙˆØ±Ø©

            Ø£Ø¹Ø¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠ.
            """

            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ØªØ­Ù„ÙŠÙ„
            analysis_result = self._call_text_model(prompt)

            if analysis_result and analysis_result.get('success'):
                content = analysis_result.get('content', '')

                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙƒÙ€ JSON
                try:
                    import json
                    parsed_result = json.loads(content)
                    return parsed_result
                except json.JSONDecodeError:
                    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† JSON ØµØ§Ù„Ø­ØŒ Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰
                    return self._parse_ai_response(content)
            else:
                # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ù†Ø¹ÙˆØ¯ Ø¥Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø³ÙŠØ·
                return self._fallback_text_analysis(text)

        except Exception as e:
            # ÙÙŠ Ø­Ø§Ù„Ø© ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø£ØŒ Ù†Ø¹ÙˆØ¯ Ø¥Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø³ÙŠØ·
            return self._fallback_text_analysis(text)

    def _call_text_model(self, prompt: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            data = {
                "model": self.text_model,
                "messages": [
                    {
                        "role": "system",
                        "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø­ØªÙˆÙ‰ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø§Ø­ØªØ±Ø§ÙÙŠØ©. Ø£Ø¹Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON ÙÙ‚Ø·."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.3
            }

            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"].strip()
                return {
                    "success": True,
                    "content": content
                }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code}"
                }

        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _parse_ai_response(self, content: str) -> Dict[str, List[str]]:
        """ØªØ­Ù„ÙŠÙ„ Ø±Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON"""
        elements = {
            'location': [],
            'service': [],
            'workers': [],
            'tools': [],
            'materials': [],
            'environment': [],
            'actions': [],
            'objects': [],
            'qualities': []
        }

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø©
        words = content.lower().split()
        for word in words:
            if len(word) > 3:
                # ØªØµÙ†ÙŠÙ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø­Ø³Ø¨ Ø£Ù†Ù…Ø§Ø·Ù‡Ø§
                if any(char in word for char in ['Ù…Ø¯ÙŠÙ†Ø©', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'Ù…Ø¯ÙŠÙ†Ø©']):
                    elements['location'].append(word)
                elif any(char in word for char in ['Ù†Ù‚Ù„', 'Ø®Ø¯Ù…Ø©', 'Ø´Ø±ÙƒØ©']):
                    elements['service'].append(word)
                elif any(char in word for char in ['Ø¹Ø§Ù…Ù„', 'Ù…Ù‡Ù†Ø¯Ø³', 'ÙÙ†ÙŠ']):
                    elements['workers'].append(word)
                elif any(char in word for char in ['Ø´Ø§Ø­Ù†Ø©', 'Ø£Ø¯Ø§Ø©', 'Ù…Ø¹Ø¯Ø©']):
                    elements['tools'].append(word)
                elif any(char in word for char in ['Ø®Ø´Ø¨', 'Ù…Ø¹Ø¯Ù†', 'Ø¨Ù„Ø§Ø³ØªÙŠÙƒ']):
                    elements['materials'].append(word)

        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        for category in elements:
            elements[category] = list(set(elements[category]))[:3]

        return elements

    def _fallback_text_analysis(self, text: str) -> Dict[str, List[str]]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¨Ø³ÙŠØ· ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        elements = {
            'location': [],
            'service': [],
            'workers': [],
            'tools': [],
            'materials': [],
            'environment': [],
            'actions': [],
            'objects': [],
            'qualities': []
        }

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø³ÙŠØ· Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
        words = text.split()
        long_words = [word for word in words if len(word) > 4]

        elements['objects'].extend(long_words[:5])
        elements['service'].extend([word for word in long_words if 'ing' in word or 'ment' in word])

        return elements

    def _call_cometapi_image(self, prompt: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©"""
        try:
            if not self.cometapi_config:
                return {
                    "success": False,
                    "error": "CometAPI not configured"
                }
            
            # Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ±ÙŠØ­Ø© Ø¨Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†Øµ
            enhanced_prompt = f"{prompt}\n\nIMPORTANT: DO NOT include any text, words, letters, or typography in the image. Create a pure visual design without any written content. The image should be completely text-free."
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØµÙˆØ±Ø©
            data = {
                "model": "flux-1.1-pro",
                "prompt": enhanced_prompt,
                "width": int(config.get("size", "1200Ã—628").split("Ã—")[0]),
                "height": int(config.get("size", "1200Ã—628").split("Ã—")[1]),
                "num_inference_steps": 20,
                "guidance_scale": 7.5,
                "safety_tolerance": 2
            }
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
            response = requests.post(
                f"{self.cometapi_config['base_url']}/v1/flux",
                headers={
                    "Authorization": f"Bearer {self.cometapi_config['api_key']}",
                    "Content-Type": "application/json"
                },
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                if "images" in result and len(result["images"]) > 0:
                    return {
                        "success": True,
                        "image_url": result["images"][0]["image_url"]
                    }
                else:
                    return {
                        "success": False,
                        "error": "No image generated"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _call_cometapi_image(self, prompt: str, config: Dict[str, Any] = None) -> Dict[str, Any]:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ CometAPI Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
            size = config.get("size", "1200Ã—628") if config else "1200Ã—628"
            width, height = map(int, size.split("Ã—"))
            
            # Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ±ÙŠØ­Ø© Ø¨Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†Øµ
            enhanced_prompt = f"{prompt}\n\nIMPORTANT: DO NOT include any text, words, letters, or typography in the image. Create a pure visual design without any written content. The image should be completely text-free."
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            data = {
                "model": "dall-e-3",
                "prompt": enhanced_prompt,
                "width": width,
                "height": height,
                "quality": "hd",
                "n": 1,
                "response_format": "url"
            }
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API
            response = requests.post(
                f"{self.cometapi_base_url}/v1/images/generations",
                headers=self.cometapi_headers,
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                if "data" in result and len(result["data"]) > 0:
                    return {
                        "success": True,
                        "image_url": result["data"][0]["url"],
                        "width": width,
                        "height": height
                    }
                else:
                    return {
                        "success": False,
                        "error": "No image generated"
                    }
            else:
                return {
                    "success": False,
                    "error": f"API Error: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def generate_complete_campaign_assets(self, campaign_type: str, product_service: str, website_url: str, keywords: List[str], budget: float = 25.0, language_code: str = "1019", location_ids: List[str] = None, brand_colors: Dict[str, str] = None) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© (Ù†ØµÙˆØµ + ØµÙˆØ±)"""
        try:
            logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø©: {campaign_type}")
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©
            text_assets = self.generate_complete_ad_content(
                product_service=product_service,
                website_url=website_url
            )
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©
            image_assets = self.generate_campaign_images_detailed(
                campaign_type=campaign_type,
                product_service=product_service,
                website_url=website_url,
                keywords=keywords,
                brand_colors=brand_colors
            )
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            result = {
                "success": True,
                "campaign_type": campaign_type,
                "product_service": product_service,
                "website_url": website_url,
                "keywords": keywords,
                "budget": budget,
                "language_code": language_code,
                "location_ids": location_ids,
                "text_assets": text_assets,
                "image_assets": image_assets,
                "total_assets": {
                    "headlines": len(text_assets.get("headlines", [])),
                    "descriptions": len(text_assets.get("descriptions", [])),
                    "images": len(image_assets)
                },
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­: {result['total_assets']}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø©: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "message": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø£ØµÙˆÙ„ Ø§Ù„Ø­Ù…Ù„Ø©"
            }
    
    def select_smart_video_ad_type(
        self,
        goal: str,
        budget: float,
        video_duration: int = None,
        industry: str = None,
        has_product: bool = False,
        target_audience: str = None
    ) -> Dict[str, Any]:
        """
        ğŸ¤– Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù„Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø£Ù…Ø«Ù„
        
        Args:
            goal: Ø§Ù„Ù‡Ø¯Ù ("awareness", "sales", "conversions", "discovery", "brand_message", "engagement")
            budget: Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ø¨Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±
            video_duration: Ù…Ø¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            industry: Ø§Ù„Ù…Ø¬Ø§Ù„/Ø§Ù„ØµÙ†Ø§Ø¹Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            has_product: Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ù…Ù†ØªØ¬Ø§ØªØŸ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            target_audience: Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        
        Returns:
            Dict ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù…Ø¹ Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ø¨Ø¯Ø§Ø¦Ù„
        """
        
        logger.info(f"ğŸ¯ Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ Ù„Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...")
        logger.info(f"   Ø§Ù„Ù‡Ø¯Ù: {goal}, Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©: ${budget}, Ø§Ù„Ù…Ø¯Ø©: {video_duration}s")
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 1: Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©
        if goal == "awareness" and budget < 30:
            recommendation = {
                "video_ad_type": "VIDEO_BUMPER_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† Bumper (6 Ø«ÙˆØ§Ù†ÙŠ)",
                "confidence": 95,
                "reason": "Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø© - Bumper Ad ÙŠÙˆÙØ± Ø£ÙƒØ¨Ø± ÙˆØµÙˆÙ„ Ø¨Ø£Ù‚Ù„ ØªÙƒÙ„ÙØ©",
                "reason_ar": "Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø© ($" + str(budget) + ") - Ø¥Ø¹Ù„Ø§Ù† Bumper ÙŠÙˆÙØ± Ø£ÙƒØ¨Ø± ÙˆØµÙˆÙ„ Ø¨Ø£Ù‚Ù„ ØªÙƒÙ„ÙØ©",
                "requirements": {
                    "video_duration": "6 Ø«ÙˆØ§Ù†ÙŠ Ø¨Ø§Ù„Ø¶Ø¨Ø·",
                    "video_duration_seconds": 6,
                    "cost_model": "CPM",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ±",
                    "estimated_cost_per_1000": "$0.40",
                    "estimated_daily_impressions": int(budget / 0.0004),
                    "estimated_daily_views": int(budget / 0.0004)
                },
                "pros": [
                    "Ø±Ø®ÙŠØµ Ø¬Ø¯Ø§Ù‹ - Ø£Ù‚Ù„ ØªÙƒÙ„ÙØ©",
                    "ÙˆØµÙˆÙ„ ÙˆØ§Ø³Ø¹ - ÙŠØµÙ„ Ù„Ø£ÙƒØ¨Ø± Ø¹Ø¯Ø¯",
                    "Ø³Ø±ÙŠØ¹ ÙˆÙ…Ø¨Ø§Ø´Ø± - 6 Ø«ÙˆØ§Ù†ÙŠ ÙÙ‚Ø·",
                    "ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ - Ù…Ø´Ø§Ù‡Ø¯Ø© Ù…Ø¶Ù…ÙˆÙ†Ø© 100%",
                    "Ù…Ø«Ø§Ù„ÙŠ Ù„Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©"
                ],
                "cons": [
                    "Ù…Ø¯Ø© Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ (6 Ø«ÙˆØ§Ù†ÙŠ ÙÙ‚Ø·)",
                    "Ø±Ø³Ø§Ù„Ø© Ù…Ø­Ø¯ÙˆØ¯Ø© - Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø´Ø±Ø­ ØªÙØ§ØµÙŠÙ„ ÙƒØ«ÙŠØ±Ø©",
                    "ÙŠØ­ØªØ§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ ÙÙŠ 6 Ø«ÙˆØ§Ù†ÙŠ"
                ],
                "best_for": "Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©",
                "best_for_ar": "Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ© Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©",
                "use_cases": [
                    "Ø´Ø±ÙƒØ© Ø¬Ø¯ÙŠØ¯Ø© ØªØ±ÙŠØ¯ Ø§Ù†ØªØ´Ø§Ø± Ø³Ø±ÙŠØ¹",
                    "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ø¬Ø¯ÙŠØ¯ - Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ¹Ø±ÙŠÙ",
                    "Ø­Ù…Ù„Ø© ØªØ°ÙƒÙŠØ±ÙŠØ© Ù‚ØµÙŠØ±Ø©"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 2: Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…Ø¹ ÙÙŠØ¯ÙŠÙˆ Ø·ÙˆÙŠÙ„
        elif goal in ["sales", "conversions"] and (video_duration is None or video_duration >= 30) and budget >= 50:
            recommendation = {
                "video_ad_type": "VIDEO_TRUEVIEW_IN_STREAM_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† TrueView In-Stream (Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ)",
                "confidence": 92,
                "reason": "Ù‡Ø¯Ù ØªØ­ÙˆÙŠÙ„Ø§Øª + Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø¬ÙŠØ¯Ø© - TrueView ÙŠØ¬Ø°Ø¨ Ø§Ù„Ù…Ù‡ØªÙ…ÙŠÙ† ÙÙ‚Ø·",
                "reason_ar": "Ù‡Ø¯Ù Ù…Ø¨ÙŠØ¹Ø§Øª/ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…Ø¹ Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø¬ÙŠØ¯Ø© ($" + str(budget) + ") - TrueView ÙŠØ¬Ø°Ø¨ Ø§Ù„Ù…Ù‡ØªÙ…ÙŠÙ† ÙÙ‚Ø·",
                "requirements": {
                    "video_duration": "30 Ø«Ø§Ù†ÙŠØ© Ø£Ùˆ Ø£ÙƒØ«Ø± (Ù…ÙˆØµÙ‰ Ø¨Ù‡: 15-60 Ø«Ø§Ù†ÙŠØ©)",
                    "video_duration_seconds": "30-60",
                    "cost_model": "CPV",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø©",
                    "estimated_cost_per_view": "$0.01-0.05",
                    "estimated_daily_views": int(budget / 0.03),
                    "estimated_daily_clicks": int(budget / 0.03 * 0.05),
                    "payment_condition": "ØªØ¯ÙØ¹ Ø¹Ù†Ø¯ Ù…Ø´Ø§Ù‡Ø¯Ø© 30 Ø«Ø§Ù†ÙŠØ© Ø£Ùˆ Ø§Ù„ØªÙØ§Ø¹Ù„"
                },
                "pros": [
                    "ØªØ¯ÙØ¹ ÙÙ‚Ø· Ù„Ù„Ù…Ù‡ØªÙ…ÙŠÙ† - Ù„Ø§ ØªØ¯ÙØ¹ Ø¥Ø°Ø§ ØªØ®Ø·Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…",
                    "Ù…Ø¹Ø¯Ù„ ØªØ­ÙˆÙŠÙ„ Ø¹Ø§Ù„ÙŠ - ÙŠØ¬Ø°Ø¨ Ù…Ù† Ù„Ø¯ÙŠÙ‡ Ù†ÙŠØ© Ø´Ø±Ø§Ø¡",
                    "ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© CTA Ù‚ÙˆÙŠ ÙˆÙ…Ø¨Ø§Ø´Ø±",
                    "Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ Ø¨Ø¹Ø¯ 5 Ø«ÙˆØ§Ù†ÙŠ - ÙŠØµÙÙŠ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±",
                    "Ù…Ø«Ø§Ù„ÙŠ Ù„Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª"
                ],
                "cons": [
                    "ÙŠØ­ØªØ§Ø¬ ÙÙŠØ¯ÙŠÙˆ Ø¬ÙŠØ¯ - Ø£ÙˆÙ„ 5 Ø«ÙˆØ§Ù†ÙŠ Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹",
                    "ØªÙƒÙ„ÙØ© Ø£Ø¹Ù„Ù‰ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø±Ù‰",
                    "Ù‚Ø¯ ÙŠØªØ®Ø·Ù‰ Ø§Ù„Ø¨Ø¹Ø¶ - Ù„ÙƒÙ† Ù‡Ø°Ø§ Ø¬ÙŠØ¯ (ØªØµÙÙŠØ©)"
                ],
                "best_for": "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©",
                "best_for_ar": "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©",
                "use_cases": [
                    "Ù…ØªØ¬Ø± Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙŠØ±ÙŠØ¯ Ù…Ø¨ÙŠØ¹Ø§Øª",
                    "Ø®Ø¯Ù…Ø© B2B ØªØ±ÙŠØ¯ Ø¹Ù…Ù„Ø§Ø¡ Ù…Ø­ØªÙ…Ù„ÙŠÙ†",
                    "ØªØ·Ø¨ÙŠÙ‚ ÙŠØ±ÙŠØ¯ ØªØ­Ù…ÙŠÙ„Ø§Øª"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 3: Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…ØªÙˆØ³Ø·Ø©
        elif goal in ["sales", "conversions"] and budget < 50:
            recommendation = {
                "video_ad_type": "VIDEO_RESPONSIVE_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ Ù…ØªØ¬Ø§ÙˆØ¨",
                "confidence": 85,
                "reason": "Ù‡Ø¯Ù Ù…Ø¨ÙŠØ¹Ø§Øª + Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…ØªÙˆØ³Ø·Ø© - Responsive Ad Ù…Ø±Ù† ÙˆÙ…Ù†Ø§Ø³Ø¨",
                "reason_ar": "Ù‡Ø¯Ù Ù…Ø¨ÙŠØ¹Ø§Øª Ù…Ø¹ Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…ØªÙˆØ³Ø·Ø© ($" + str(budget) + ") - Ø¥Ø¹Ù„Ø§Ù† Ù…ØªØ¬Ø§ÙˆØ¨ Ù…Ø±Ù† ÙˆÙ…Ù†Ø§Ø³Ø¨",
                "requirements": {
                    "video_duration": "Ø£ÙŠ Ù…Ø¯Ø© (Ù…ÙˆØµÙ‰ Ø¨Ù‡: 15-30 Ø«Ø§Ù†ÙŠØ©)",
                    "video_duration_seconds": "15-30",
                    "cost_model": "CPV Ø£Ùˆ CPM",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø£Ùˆ ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ±",
                    "estimated_cost": "Ù…Ø±Ù† - Google ÙŠØ­Ø³Ù† Ø§Ù„ØªÙƒÙ„ÙØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹",
                    "estimated_daily_views": int(budget / 0.02)
                },
                "pros": [
                    "Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© - ÙŠØªÙƒÙŠÙ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹",
                    "ÙŠØ¹Ù…Ù„ ÙÙŠ ÙƒÙ„ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø¹Ù„Ù‰ YouTube",
                    "Google ÙŠØ­Ø³Ù†Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ - AI ÙŠØ®ØªØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„",
                    "Ø£Ù‚Ù„ Ù…Ø®Ø§Ø·Ø±Ø© - Ø®ÙŠØ§Ø± Ø¢Ù…Ù†",
                    "ÙŠØ¯Ø¹Ù… ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"
                ],
                "cons": [
                    "Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù‡Ø¯Ù Ù…Ø­Ø¯Ø¯ Ø¬Ø¯Ø§Ù‹"
                ],
                "best_for": "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù - Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹ ÙˆÙ…Ø±ÙˆÙ†Ø©",
                "best_for_ar": "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù - Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹ ÙˆÙ…Ø±ÙˆÙ†Ø©",
                "use_cases": [
                    "Ù…ØªØ¬Ø± Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…ØªÙˆØ³Ø·Ø©",
                    "Ø­Ù…Ù„Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ù‡Ø¯Ø§Ù",
                    "Ø§Ø®ØªØ¨Ø§Ø± Ø£Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 4: Ø§Ù„Ø§ÙƒØªØ´Ø§Ù ÙˆØ§Ù„Ø¨Ø­Ø«
        elif goal == "discovery" or industry in ["education", "tutorial", "how-to"]:
            recommendation = {
                "video_ad_type": "IN_FEED_VIDEO_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ ÙÙŠ Ø§Ù„Ø®Ù„Ø§ØµØ©",
                "confidence": 88,
                "reason": "Ù…Ø­ØªÙˆÙ‰ ØªØ¹Ù„ÙŠÙ…ÙŠ/Ø§ÙƒØªØ´Ø§Ù - In-Feed ÙŠØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
                "reason_ar": "Ù…Ø­ØªÙˆÙ‰ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø£Ùˆ Ø§ÙƒØªØ´Ø§Ù - Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„Ø®Ù„Ø§ØµØ© ÙŠØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
                "requirements": {
                    "video_duration": "Ø£ÙŠ Ù…Ø¯Ø©",
                    "video_duration_seconds": "any",
                    "cost_model": "CPV",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø©",
                    "estimated_cost_per_view": "$0.01-0.03",
                    "estimated_daily_clicks": int(budget / 0.02),
                    "payment_condition": "ØªØ¯ÙØ¹ ÙÙ‚Ø· Ø¹Ù†Ø¯ Ø§Ù„Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†"
                },
                "pros": [
                    "ÙŠØ¸Ù‡Ø± ÙÙŠ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù„Ù‰ YouTube",
                    "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† ÙŠØ¨Ø­Ø«ÙˆÙ† Ø¹Ù†Ùƒ - Ù†ÙŠØ© Ø¹Ø§Ù„ÙŠØ©",
                    "ØªØ¯ÙØ¹ ÙÙ‚Ø· Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… (Ø§Ù„Ù†Ù‚Ø±)",
                    "Ù…Ø«Ø§Ù„ÙŠ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ ÙˆØ§Ù„Ø¯Ø±ÙˆØ³",
                    "ÙŠØ¨Ù†ÙŠ Ø¬Ù…Ù‡ÙˆØ± Ù…Ù‡ØªÙ… Ø­Ù‚ÙŠÙ‚ÙŠ"
                ],
                "cons": [
                    "ÙˆØµÙˆÙ„ Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø±Ù‰",
                    "ÙŠØ­ØªØ§Ø¬ Ø¹Ù†ÙˆØ§Ù† Ø¬Ø°Ø§Ø¨ Ø¬Ø¯Ø§Ù‹",
                    "ÙŠØ­ØªØ§Ø¬ ØµÙˆØ±Ø© Ù…ØµØºØ±Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©"
                ],
                "best_for": "Ø§Ù„Ø§ÙƒØªØ´Ø§Ù ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ",
                "best_for_ar": "Ø§Ù„Ø§ÙƒØªØ´Ø§Ù ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ",
                "use_cases": [
                    "Ù‚Ù†Ø§Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ©",
                    "Ø´Ø±ÙƒØ© ØªÙ‚Ø¯Ù… Ø¯Ø±ÙˆØ³ ÙˆÙ…Ø­ØªÙˆÙ‰",
                    "Ù…Ø­ØªÙˆÙ‰ How-To"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 5: Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© ØºÙŠØ± Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ®Ø·ÙŠ
        elif goal == "brand_message" and budget >= 70 and (video_duration is None or video_duration <= 20):
            recommendation = {
                "video_ad_type": "VIDEO_NON_SKIPPABLE_IN_STREAM_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ",
                "confidence": 90,
                "reason": "Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© + Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø¬ÙŠØ¯Ø© - Non-Skippable ÙŠØ¶Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©",
                "reason_ar": "Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© Ù…Ø¹ Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø¬ÙŠØ¯Ø© ($" + str(budget) + ") - Ø¥Ø¹Ù„Ø§Ù† ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®Ø·ÙŠ ÙŠØ¶Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© 100%",
                "requirements": {
                    "video_duration": "15-20 Ø«Ø§Ù†ÙŠØ©",
                    "video_duration_seconds": "15-20",
                    "cost_model": "CPM",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ±",
                    "estimated_cost_per_1000": "$2-5",
                    "estimated_daily_impressions": int(budget / 0.0035),
                    "estimated_daily_views": int(budget / 0.0035)
                },
                "pros": [
                    "Ù…Ø´Ø§Ù‡Ø¯Ø© Ù…Ø¶Ù…ÙˆÙ†Ø© 100% - Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ®Ø·ÙŠ",
                    "Ø±Ø³Ø§Ù„Ø© ÙƒØ§Ù…Ù„Ø© - ÙŠØ´Ø§Ù‡Ø¯ ÙƒÙ„ Ø´ÙŠØ¡",
                    "Ù…Ø«Ø§Ù„ÙŠ Ù„Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ù…Ù‡Ù…",
                    "ØªØ£Ø«ÙŠØ± Ù‚ÙˆÙŠ - Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø¶Ø­Ø©"
                ],
                "cons": [
                    "Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ø²Ø¹Ø¬Ø§Ù‹ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†",
                    "ØªÙƒÙ„ÙØ© Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø±Ù‰",
                    "ÙŠØ­ØªØ§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ - Ù„Ø§ Ù…Ø¬Ø§Ù„ Ù„Ù„Ø®Ø·Ø£",
                    "Ù‚Ø¯ ÙŠØ¤Ø«Ø± Ø³Ù„Ø¨Ø§Ù‹ Ø¹Ù„Ù‰ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"
                ],
                "best_for": "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ø¬Ø¯ÙŠØ¯ Ø£Ùˆ Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹",
                "best_for_ar": "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ø¬Ø¯ÙŠØ¯ Ø£Ùˆ Ø±Ø³Ø§Ù„Ø© Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹",
                "use_cases": [
                    "Ø¥Ø·Ù„Ø§Ù‚ Ù…Ù†ØªØ¬ Ø«ÙˆØ±ÙŠ",
                    "Ø¥Ø¹Ù„Ø§Ù† Ø­ÙƒÙˆÙ…ÙŠ Ù…Ù‡Ù…",
                    "Ø±Ø³Ø§Ù„Ø© Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ© Ù…Ù‡Ù…Ø©"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 6: Ø§Ù„ØªÙØ§Ø¹Ù„ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
        elif goal == "engagement":
            recommendation = {
                "video_ad_type": "VIDEO_RESPONSIVE_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ Ù…ØªØ¬Ø§ÙˆØ¨",
                "confidence": 87,
                "reason": "Ù‡Ø¯Ù ØªÙØ§Ø¹Ù„ - Responsive Ad ÙŠØ²ÙŠØ¯ ÙØ±Øµ Ø§Ù„ØªÙØ§Ø¹Ù„ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹",
                "reason_ar": "Ù‡Ø¯Ù ØªÙØ§Ø¹Ù„ ÙˆÙ…Ø´Ø§Ø±ÙƒØ© - Ø¥Ø¹Ù„Ø§Ù† Ù…ØªØ¬Ø§ÙˆØ¨ ÙŠØ²ÙŠØ¯ ÙØ±Øµ Ø§Ù„ØªÙØ§Ø¹Ù„ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹",
                "requirements": {
                    "video_duration": "15-30 Ø«Ø§Ù†ÙŠØ© (Ù…ÙˆØµÙ‰ Ø¨Ù‡)",
                    "video_duration_seconds": "15-30",
                    "cost_model": "CPV Ø£Ùˆ CPM",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø£Ùˆ ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ±",
                    "estimated_daily_engagements": int(budget / 0.02 * 0.1)
                },
                "pros": [
                    "Ù…Ø±Ù† - ÙŠØ¸Ù‡Ø± ÙÙŠ Ø£Ù…Ø§ÙƒÙ† Ù…ØªØ¹Ø¯Ø¯Ø©",
                    "ÙŠØ²ÙŠØ¯ ÙØ±Øµ Ø§Ù„ØªÙØ§Ø¹Ù„",
                    "Google ÙŠØ­Ø³Ù†Ù‡ Ù„Ù„ØªÙØ§Ø¹Ù„",
                    "ÙŠØ¯Ø¹Ù… CTAs Ù…ØªØ¹Ø¯Ø¯Ø©"
                ],
                "cons": [
                    "Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ ÙˆÙ‚Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†"
                ],
                "best_for": "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©",
                "best_for_ar": "Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©",
                "use_cases": [
                    "Ø­Ù…Ù„Ø© ØªÙØ§Ø¹Ù„ÙŠØ©",
                    "Ù…Ø³Ø§Ø¨Ù‚Ø© Ø£Ùˆ ØªØ­Ø¯ÙŠ",
                    "Ø¨Ù†Ø§Ø¡ Ù…Ø¬ØªÙ…Ø¹"
                ]
            }
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ 7: Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø¢Ù…Ù† (Default)
        else:
            recommendation = {
                "video_ad_type": "VIDEO_RESPONSIVE_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ Ù…ØªØ¬Ø§ÙˆØ¨",
                "confidence": 80,
                "reason": "Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© ÙˆØ£Ù…Ø§Ù†Ø§Ù‹ - ÙŠØªÙƒÙŠÙ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹ ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù",
                "reason_ar": "Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© ÙˆØ£Ù…Ø§Ù†Ø§Ù‹ - ÙŠØªÙƒÙŠÙ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹ ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù",
                "requirements": {
                    "video_duration": "Ø£ÙŠ Ù…Ø¯Ø© (Ù…ÙˆØµÙ‰ Ø¨Ù‡: 15-30 Ø«Ø§Ù†ÙŠØ©)",
                    "video_duration_seconds": "15-30",
                    "cost_model": "CPV Ø£Ùˆ CPM (Ù…Ø±Ù†)",
                    "cost_model_ar": "ØªÙƒÙ„ÙØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø£Ùˆ ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ù„Ù Ø¸Ù‡ÙˆØ± (Ù…Ø±Ù†)",
                    "estimated_cost": "Ù…Ø±Ù† - Google ÙŠØ­Ø³Ù† Ø§Ù„ØªÙƒÙ„ÙØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"
                },
                "pros": [
                    "Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© - ÙŠØ¹Ù…Ù„ ÙÙŠ ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„Ø§Øª",
                    "ÙŠØ¹Ù…Ù„ ÙÙŠ ÙƒÙ„ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹ Ø¹Ù„Ù‰ YouTube",
                    "Google ÙŠØ­Ø³Ù†Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
                    "Ø£Ù‚Ù„ Ù…Ø®Ø§Ø·Ø±Ø© - Ø®ÙŠØ§Ø± Ø¢Ù…Ù† Ø¬Ø¯Ø§Ù‹",
                    "ÙŠØ¯Ø¹Ù… ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© (1-5 ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª)"
                ],
                "cons": [
                    "Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù‡Ø¯Ù Ù…Ø­Ø¯Ø¯ Ø¬Ø¯Ø§Ù‹"
                ],
                "best_for": "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù - Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹",
                "best_for_ar": "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù - Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹",
                "use_cases": [
                    "Ø¹Ù…ÙŠÙ„ ØºÙŠØ± Ù…ØªØ£ÙƒØ¯ Ù…Ù† Ù‡Ø¯ÙÙ‡",
                    "Ø­Ù…Ù„Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ù‡Ø¯Ø§Ù",
                    "Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø³ÙˆÙ‚"
                ]
            }
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„
        alternatives = self._get_video_ad_alternatives(recommendation["video_ad_type"], goal, budget)
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        recommendation.update({
            "alternatives": alternatives,
            "input_parameters": {
                "goal": goal,
                "budget": budget,
                "video_duration": video_duration,
                "industry": industry,
                "has_product": has_product,
                "target_audience": target_audience
            },
            "next_steps": [
                "1. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù„Ø¯ÙŠÙƒ ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©",
                "2. Ù‚Ù… Ø¨Ø±ÙØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ YouTube",
                "3. Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Video ID Ù…Ù† YouTube",
                "4. Ø§Ø³ØªØ®Ø¯Ù… Video ID ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø­Ù…Ù„Ø©"
            ],
            "tips": [
                "ğŸ’¡ Ø£ÙˆÙ„ 5 Ø«ÙˆØ§Ù†ÙŠ Ù‡ÙŠ Ø§Ù„Ø£Ù‡Ù… - Ø§Ø¬Ø°Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ ÙÙˆØ±Ø§Ù‹",
                "ğŸ’¡ Ø£Ø¶Ù ØªØ±Ø¬Ù…Ø§Øª Ù„Ù„ÙÙŠØ¯ÙŠÙˆ - 85% ÙŠØ´Ø§Ù‡Ø¯ÙˆÙ† Ø¨Ø¯ÙˆÙ† ØµÙˆØª",
                "ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ù… CTA ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø¨Ø§Ø´Ø±",
                "ğŸ’¡ Ø§Ø®ØªØ¨Ø± Ø¹Ø¯Ø© Ù†Ø³Ø® Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"
            ]
        })
        
        logger.info(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†: {recommendation['video_ad_type']} (Ø«Ù‚Ø©: {recommendation['confidence']}%)")
        
        return recommendation
    
    def _get_video_ad_alternatives(self, primary_type: str, goal: str, budget: float) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©"""
        alternatives = []
        
        # Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø§Ù‚ØªØ±Ø­ VIDEO_RESPONSIVE_AD ÙƒØ¨Ø¯ÙŠÙ„ Ø¢Ù…Ù†
        if primary_type != "VIDEO_RESPONSIVE_AD":
            alternatives.append({
                "video_ad_type": "VIDEO_RESPONSIVE_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ Ù…ØªØ¬Ø§ÙˆØ¨",
                "reason": "Ø¨Ø¯ÙŠÙ„ Ø¢Ù…Ù† ÙˆÙ…Ø±Ù† - ÙŠØ¹Ù…Ù„ ÙÙŠ ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„Ø§Øª",
                "confidence": 75
            })
        
        # Ø§Ù‚ØªØ±Ø­ BUMPER Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©
        if budget < 50 and primary_type != "VIDEO_BUMPER_AD":
            alternatives.append({
                "video_ad_type": "VIDEO_BUMPER_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† Bumper (6 Ø«ÙˆØ§Ù†ÙŠ)",
                "reason": "Ø¨Ø¯ÙŠÙ„ Ø£Ø±Ø®Øµ Ù„Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø© - ÙˆØµÙˆÙ„ Ø£ÙˆØ³Ø¹",
                "confidence": 70
            })
        
        # Ø§Ù‚ØªØ±Ø­ TRUEVIEW Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‡Ø¯Ù ØªØ­ÙˆÙŠÙ„Ø§Øª
        if goal in ["sales", "conversions"] and primary_type != "VIDEO_TRUEVIEW_IN_STREAM_AD" and budget >= 50:
            alternatives.append({
                "video_ad_type": "VIDEO_TRUEVIEW_IN_STREAM_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† TrueView In-Stream",
                "reason": "Ø¨Ø¯ÙŠÙ„ Ø£ÙØ¶Ù„ Ù„Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª - ØªØ¯ÙØ¹ ÙÙ‚Ø· Ù„Ù„Ù…Ù‡ØªÙ…ÙŠÙ†",
                "confidence": 80
            })
        
        # Ø§Ù‚ØªØ±Ø­ IN_FEED Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ
        if goal == "discovery" and primary_type != "IN_FEED_VIDEO_AD":
            alternatives.append({
                "video_ad_type": "IN_FEED_VIDEO_AD",
                "video_ad_type_ar": "Ø¥Ø¹Ù„Ø§Ù† ÙÙŠØ¯ÙŠÙˆ ÙÙŠ Ø§Ù„Ø®Ù„Ø§ØµØ©",
                "reason": "Ø¨Ø¯ÙŠÙ„ Ù„Ù„Ø§ÙƒØªØ´Ø§Ù - ÙŠØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ø¨Ø­Ø«",
                "confidence": 75
            })
        
        return alternatives

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø©
    generator = AIContentGenerator()
    
    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„
    result = generator.generate_complete_ad_content(
        product_service="Ø®Ø¯Ù…Ø§Øª Ù†Ù‚Ù„ Ø§Ù„Ø£Ø«Ø§Ø« ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶",
        website_url="https://example.com"
    )
    
    print("Ù†ØªÙŠØ¬Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠ:")
    print(result)
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø°ÙƒÙŠ
    video_recommendation = generator.select_smart_video_ad_type(
        goal="sales",
        budget=100,
        video_duration=30
    )
    print("\nØªÙˆØµÙŠØ© Ù†ÙˆØ¹ Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ:")
    print(video_recommendation)

