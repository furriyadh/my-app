"""
Queue Manager Module
ÙˆØ­Ø¯Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ§Ù„Ø·ÙˆØ§Ø¨ÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©

ÙŠÙˆÙØ± Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ù…Ù‡Ø§Ù… Ø´Ø§Ù…Ù„ ÙˆÙ…ØªØ·ÙˆØ± Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ:
- Ø¥Ø¯Ø§Ø±Ø© Ø·ÙˆØ§Ø¨ÙŠØ± Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
- Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ
- Ù…Ø±Ø§Ù‚Ø¨Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡
- Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØ§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
- Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø°ÙƒÙŠ
- ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„ØªØªØ¨Ø¹
- Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
- ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Redis Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª

Author: Google Ads AI Platform Team
Version: 2.2.0
Security Level: Enterprise
Performance: High-Performance Queue Management
"""

import os
import asyncio
import json
import time
import threading
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any, Tuple, Union, Set, Callable, Awaitable
from dataclasses import dataclass, field, asdict
from enum import Enum, auto
from functools import wraps
from concurrent.futures import ThreadPoolExecutor, as_completed, Future
from collections import defaultdict, deque
import hashlib
import uuid
import pickle
import gzip
import logging
import heapq
import weakref
from queue import Queue, PriorityQueue, Empty
import signal
import sys

# Local imports
try:
    from utils.helpers import (
        generate_unique_id, sanitize_text, calculate_hash,
        format_timestamp, compress_data, decompress_data
    )
    HELPERS_AVAILABLE = True
except ImportError:
    HELPERS_AVAILABLE = False

try:
    from utils.redis_config import cache_set, cache_get, cache_delete
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
logger = logging.getLogger(__name__)

class TaskStatus(Enum):
    """Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ù‡Ø§Ù…"""
    PENDING = "pending"
    QUEUED = "queued"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    RETRYING = "retrying"
    PAUSED = "paused"

class TaskPriority(Enum):
    """Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ø§Ù„Ù…Ù‡Ø§Ù…"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    URGENT = 4
    CRITICAL = 5

class QueueType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±"""
    FIFO = "fifo"  # First In, First Out
    LIFO = "lifo"  # Last In, First Out
    PRIORITY = "priority"  # Priority-based
    ROUND_ROBIN = "round_robin"  # Round Robin
    WEIGHTED = "weighted"  # Weighted distribution

@dataclass
class TaskConfig:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©"""
    task_id: str
    task_type: str
    function_name: str
    args: Tuple[Any, ...] = field(default_factory=tuple)
    kwargs: Dict[str, Any] = field(default_factory=dict)
    priority: TaskPriority = TaskPriority.NORMAL
    max_retries: int = 3
    retry_delay: float = 1.0
    timeout: Optional[float] = None
    depends_on: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    scheduled_time: Optional[datetime] = None
    expires_at: Optional[datetime] = None

@dataclass
class TaskResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ù‡Ù…Ø©"""
    task_id: str
    status: TaskStatus
    created_at: datetime
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    result: Any = None
    error: Optional[str] = None
    retry_count: int = 0
    execution_time_seconds: float = 0.0
    worker_id: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class QueueStats:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø·Ø§Ø¨ÙˆØ±"""
    queue_name: str
    total_tasks: int = 0
    pending_tasks: int = 0
    running_tasks: int = 0
    completed_tasks: int = 0
    failed_tasks: int = 0
    average_execution_time: float = 0.0
    throughput_per_minute: float = 0.0
    last_updated: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

@dataclass
class WorkerStats:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ù„"""
    worker_id: str
    tasks_processed: int = 0
    tasks_failed: int = 0
    average_task_time: float = 0.0
    current_task: Optional[str] = None
    status: str = "idle"
    last_activity: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

class Task:
    """ÙØ¦Ø© Ø§Ù„Ù…Ù‡Ù…Ø©"""
    
    def __init__(self, config: TaskConfig):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ù‡Ù…Ø©"""
        self.config = config
        self.result = TaskResult(
            task_id=config.task_id,
            status=TaskStatus.PENDING,
            created_at=datetime.now(timezone.utc)
        )
        self._future: Optional[Future] = None
        self._dependencies_met = threading.Event()
        
        # ÙØ­Øµ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª
        if not config.depends_on:
            self._dependencies_met.set()
    
    def __lt__(self, other):
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ù„Ù„Ø£ÙˆÙ„ÙˆÙŠØ©"""
        return self.config.priority.value > other.config.priority.value
    
    def mark_dependency_met(self, dependency_id: str):
        """ØªØ­Ø¯ÙŠØ¯ Ø£Ù† ØªØ¨Ø¹ÙŠØ© ØªÙ… Ø§Ù„ÙˆÙØ§Ø¡ Ø¨Ù‡Ø§"""
        if dependency_id in self.config.depends_on:
            self.config.depends_on.remove(dependency_id)
            if not self.config.depends_on:
                self._dependencies_met.set()
    
    def are_dependencies_met(self) -> bool:
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ù…Ø³ØªÙˆÙØ§Ø©"""
        return self._dependencies_met.is_set()
    
    def is_expired(self) -> bool:
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©"""
        if self.config.expires_at:
            return datetime.now(timezone.utc) > self.config.expires_at
        return False
    
    def should_execute_now(self) -> bool:
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø¢Ù†"""
        if self.config.scheduled_time:
            return datetime.now(timezone.utc) >= self.config.scheduled_time
        return True

class TaskQueue:
    """Ø·Ø§Ø¨ÙˆØ± Ø§Ù„Ù…Ù‡Ø§Ù…"""
    
    def __init__(self, name: str, queue_type: QueueType = QueueType.FIFO, max_size: Optional[int] = None):
        """ØªÙ‡ÙŠØ¦Ø© Ø·Ø§Ø¨ÙˆØ± Ø§Ù„Ù…Ù‡Ø§Ù…"""
        self.name = name
        self.queue_type = queue_type
        self.max_size = max_size
        
        # Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„Ø·Ø§Ø¨ÙˆØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        if queue_type == QueueType.PRIORITY:
            self._queue = PriorityQueue(maxsize=max_size or 0)
        else:
            self._queue = Queue(maxsize=max_size or 0)
        
        self._tasks: Dict[str, Task] = {}
        self._lock = threading.RLock()
        self.stats = QueueStats(queue_name=name)
        
        # Ù„Ù„Ø·ÙˆØ§Ø¨ÙŠØ± Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„Ø©
        self._scheduled_tasks: List[Task] = []
        self._scheduler_thread = None
        self._scheduler_running = False
        
        self._start_scheduler()
    
    def _start_scheduler(self):
        """Ø¨Ø¯Ø¡ Ù…Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‡Ø§Ù…"""
        if self._scheduler_thread is None or not self._scheduler_thread.is_alive():
            self._scheduler_running = True
            self._scheduler_thread = threading.Thread(target=self._scheduler_loop, daemon=True)
            self._scheduler_thread.start()
    
    def _scheduler_loop(self):
        """Ø­Ù„Ù‚Ø© Ù…Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‡Ø§Ù…"""
        while self._scheduler_running:
            try:
                current_time = datetime.now(timezone.utc)
                tasks_to_queue = []
                
                with self._lock:
                    # ÙØ­Øµ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„Ø©
                    for task in self._scheduled_tasks[:]:
                        if task.should_execute_now() and task.are_dependencies_met():
                            if not task.is_expired():
                                tasks_to_queue.append(task)
                                self._scheduled_tasks.remove(task)
                            else:
                                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
                                self._scheduled_tasks.remove(task)
                                task.result.status = TaskStatus.CANCELLED
                                task.result.error = "Task expired"
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‡Ø§Ù… Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±
                for task in tasks_to_queue:
                    self._enqueue_task(task)
                
                time.sleep(1)  # ÙØ­Øµ ÙƒÙ„ Ø«Ø§Ù†ÙŠØ©
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‡Ø§Ù…: {e}")
                time.sleep(5)
    
    def put(self, task: Task) -> bool:
        """Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±"""
        try:
            with self._lock:
                if task.config.task_id in self._tasks:
                    logger.warning(f"Ø§Ù„Ù…Ù‡Ù…Ø© {task.config.task_id} Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø§Ù„ÙØ¹Ù„")
                    return False
                
                # ÙØ­Øµ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø­Ø¬Ù…
                if self.max_size and len(self._tasks) >= self.max_size:
                    logger.warning(f"Ø§Ù„Ø·Ø§Ø¨ÙˆØ± {self.name} Ù…Ù…ØªÙ„Ø¦")
                    return False
                
                self._tasks[task.config.task_id] = task
                
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ø¬Ø¯ÙˆÙ„Ø©
                if task.config.scheduled_time and task.config.scheduled_time > datetime.now(timezone.utc):
                    self._scheduled_tasks.append(task)
                    task.result.status = TaskStatus.QUEUED
                    logger.info(f"ØªÙ… Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ù…Ø© {task.config.task_id} Ù„Ù„ØªÙ†ÙÙŠØ° ÙÙŠ {task.config.scheduled_time}")
                else:
                    # Ø¥Ø¶Ø§ÙØ© ÙÙˆØ±ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ù…Ø³ØªÙˆÙØ§Ø©
                    if task.are_dependencies_met():
                        self._enqueue_task(task)
                    else:
                        task.result.status = TaskStatus.PENDING
                        logger.info(f"Ø§Ù„Ù…Ù‡Ù…Ø© {task.config.task_id} ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª")
                
                self.stats.total_tasks += 1
                self.stats.pending_tasks += 1
                return True
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            return False
    
    def _enqueue_task(self, task: Task):
        """Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨ÙˆØ± Ø§Ù„ÙØ¹Ù„ÙŠ"""
        try:
            if self.queue_type == QueueType.PRIORITY:
                self._queue.put(task, block=False)
            elif self.queue_type == QueueType.LIFO:
                # Ù…Ø­Ø§ÙƒØ§Ø© LIFO Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Queue Ø¹Ø§Ø¯ÙŠ
                self._queue.put(task, block=False)
            else:  # FIFO
                self._queue.put(task, block=False)
            
            task.result.status = TaskStatus.QUEUED
            logger.debug(f"ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‡Ù…Ø© {task.config.task_id} Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‡Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±: {e}")
            task.result.status = TaskStatus.FAILED
            task.result.error = str(e)
    
    def get(self, timeout: Optional[float] = None) -> Optional[Task]:
        """Ø¬Ù„Ø¨ Ù…Ù‡Ù…Ø© Ù…Ù† Ø§Ù„Ø·Ø§Ø¨ÙˆØ±"""
        try:
            task = self._queue.get(timeout=timeout)
            
            with self._lock:
                if task.config.task_id in self._tasks:
                    task.result.status = TaskStatus.RUNNING
                    task.result.started_at = datetime.now(timezone.utc)
                    self.stats.pending_tasks = max(0, self.stats.pending_tasks - 1)
                    self.stats.running_tasks += 1
                    return task
            
            return None
            
        except Empty:
            return None
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            return None
    
    def task_done(self, task: Task):
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø©"""
        try:
            with self._lock:
                if task.config.task_id in self._tasks:
                    task.result.completed_at = datetime.now(timezone.utc)
                    if task.result.started_at:
                        task.result.execution_time_seconds = (
                            task.result.completed_at - task.result.started_at
                        ).total_seconds()
                    
                    self.stats.running_tasks = max(0, self.stats.running_tasks - 1)
                    
                    if task.result.status == TaskStatus.COMPLETED:
                        self.stats.completed_tasks += 1
                        # Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ§Ø¨Ø¹Ø©
                        self._notify_dependent_tasks(task.config.task_id)
                    elif task.result.status == TaskStatus.FAILED:
                        self.stats.failed_tasks += 1
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                    self._update_stats()
            
            self._queue.task_done()
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
    
    def _notify_dependent_tasks(self, completed_task_id: str):
        """Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ§Ø¨Ø¹Ø©"""
        try:
            tasks_to_queue = []
            
            for task in self._tasks.values():
                if completed_task_id in task.config.depends_on:
                    task.mark_dependency_met(completed_task_id)
                    if task.are_dependencies_met() and task.result.status == TaskStatus.PENDING:
                        if task.should_execute_now():
                            tasks_to_queue.append(task)
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±
            for task in tasks_to_queue:
                self._enqueue_task(task)
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ§Ø¨Ø¹Ø©: {e}")
    
    def _update_stats(self):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
        try:
            completed_tasks = [t for t in self._tasks.values() if t.result.status == TaskStatus.COMPLETED]
            
            if completed_tasks:
                total_time = sum(t.result.execution_time_seconds for t in completed_tasks)
                self.stats.average_execution_time = total_time / len(completed_tasks)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© (Ù…Ù‡Ø§Ù… ÙÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©)
            now = datetime.now(timezone.utc)
            one_minute_ago = now - timedelta(minutes=1)
            recent_completions = [
                t for t in completed_tasks 
                if t.result.completed_at and t.result.completed_at >= one_minute_ago
            ]
            self.stats.throughput_per_minute = len(recent_completions)
            self.stats.last_updated = now
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")
    
    def get_task(self, task_id: str) -> Optional[Task]:
        """Ø¬Ù„Ø¨ Ù…Ù‡Ù…Ø© Ø¨Ø§Ù„Ù…Ø¹Ø±Ù"""
        with self._lock:
            return self._tasks.get(task_id)
    
    def cancel_task(self, task_id: str) -> bool:
        """Ø¥Ù„ØºØ§Ø¡ Ù…Ù‡Ù…Ø©"""
        try:
            with self._lock:
                task = self._tasks.get(task_id)
                if task:
                    if task.result.status in [TaskStatus.PENDING, TaskStatus.QUEUED]:
                        task.result.status = TaskStatus.CANCELLED
                        task.result.completed_at = datetime.now(timezone.utc)
                        
                        # Ø¥Ø²Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„Ø©
                        if task in self._scheduled_tasks:
                            self._scheduled_tasks.remove(task)
                        
                        return True
                    elif task.result.status == TaskStatus.RUNNING:
                        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø¬Ø§Ø±ÙŠØ©
                        if task._future:
                            task._future.cancel()
                        task.result.status = TaskStatus.CANCELLED
                        return True
            
            return False
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            return False
    
    def size(self) -> int:
        """Ø­Ø¬Ù… Ø§Ù„Ø·Ø§Ø¨ÙˆØ±"""
        return self._queue.qsize()
    
    def is_empty(self) -> bool:
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø·Ø§Ø¨ÙˆØ± ÙØ§Ø±Øº"""
        return self._queue.empty()
    
    def clear(self):
        """Ù…Ø³Ø­ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±"""
        try:
            with self._lock:
                while not self._queue.empty():
                    try:
                        self._queue.get_nowait()
                        self._queue.task_done()
                    except Empty:
                        break
                
                # Ø¥Ù„ØºØ§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ù…
                for task in self._tasks.values():
                    if task.result.status in [TaskStatus.PENDING, TaskStatus.QUEUED, TaskStatus.RUNNING]:
                        task.result.status = TaskStatus.CANCELLED
                
                self._scheduled_tasks.clear()
                self.stats = QueueStats(queue_name=self.name)
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±: {e}")
    
    def stop_scheduler(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‡Ø§Ù…"""
        self._scheduler_running = False
        if self._scheduler_thread and self._scheduler_thread.is_alive():
            self._scheduler_thread.join(timeout=5)

class Worker:
    """Ø¹Ø§Ù…Ù„ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ø§Ù…"""
    
    def __init__(self, worker_id: str, queue_manager: 'QueueManager'):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ø§Ù…Ù„"""
        self.worker_id = worker_id
        self.queue_manager = queue_manager
        self.stats = WorkerStats(worker_id=worker_id)
        self._running = False
        self._thread: Optional[threading.Thread] = None
        self._current_task: Optional[Task] = None
        self._executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix=f"worker_{worker_id}")
    
    def start(self):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ø§Ù…Ù„"""
        if not self._running:
            self._running = True
            self._thread = threading.Thread(target=self._work_loop, daemon=True)
            self._thread.start()
            logger.info(f"ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ø§Ù…Ù„ {self.worker_id}")
    
    def stop(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ø§Ù…Ù„"""
        self._running = False
        if self._thread and self._thread.is_alive():
            self._thread.join(timeout=10)
        
        self._executor.shutdown(wait=True)
        logger.info(f"ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ø§Ù…Ù„ {self.worker_id}")
    
    def _work_loop(self):
        """Ø­Ù„Ù‚Ø© Ø¹Ù…Ù„ Ø§Ù„Ø¹Ø§Ù…Ù„"""
        while self._running:
            try:
                # Ø¬Ù„Ø¨ Ù…Ù‡Ù…Ø© Ù…Ù† Ø£ÙŠ Ø·Ø§Ø¨ÙˆØ± Ù…ØªØ§Ø­
                task = self.queue_manager.get_next_task(timeout=1.0)
                
                if task:
                    self._current_task = task
                    self.stats.current_task = task.config.task_id
                    self.stats.status = "working"
                    self.stats.last_activity = datetime.now(timezone.utc)
                    
                    # ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø©
                    success = self._execute_task(task)
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                    if success:
                        self.stats.tasks_processed += 1
                    else:
                        self.stats.tasks_failed += 1
                    
                    # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°
                    if task.result.execution_time_seconds > 0:
                        total_time = self.stats.average_task_time * (self.stats.tasks_processed - 1)
                        total_time += task.result.execution_time_seconds
                        self.stats.average_task_time = total_time / self.stats.tasks_processed
                    
                    self._current_task = None
                    self.stats.current_task = None
                    self.stats.status = "idle"
                else:
                    # Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‡Ø§Ù…ØŒ Ø§Ù†ØªØ¸Ø§Ø± Ù‚ØµÙŠØ±
                    time.sleep(0.1)
                    
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ù„Ù‚Ø© Ø¹Ù…Ù„ Ø§Ù„Ø¹Ø§Ù…Ù„ {self.worker_id}: {e}")
                time.sleep(1)
    
    def _execute_task(self, task: Task) -> bool:
        """ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø©"""
        try:
            # ÙØ­Øµ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
            if task.is_expired():
                task.result.status = TaskStatus.CANCELLED
                task.result.error = "Task expired before execution"
                self.queue_manager._complete_task(task)
                return False
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ø¹ timeout
            future = self._executor.submit(self._run_task_function, task)
            task._future = future
            
            try:
                if task.config.timeout:
                    result = future.result(timeout=task.config.timeout)
                else:
                    result = future.result()
                
                task.result.result = result
                task.result.status = TaskStatus.COMPLETED
                task.result.worker_id = self.worker_id
                
                logger.info(f"ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø© {task.config.task_id} Ø¨Ù†Ø¬Ø§Ø­")
                self.queue_manager._complete_task(task)
                return True
                
            except TimeoutError:
                future.cancel()
                task.result.status = TaskStatus.FAILED
                task.result.error = "Task timeout"
                logger.error(f"Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø© {task.config.task_id}")
                
            except Exception as e:
                task.result.status = TaskStatus.FAILED
                task.result.error = str(e)
                logger.error(f"ÙØ´Ù„ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø© {task.config.task_id}: {e}")
            
            # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            if task.result.retry_count < task.config.max_retries:
                return self._retry_task(task)
            else:
                self.queue_manager._complete_task(task)
                return False
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            task.result.status = TaskStatus.FAILED
            task.result.error = str(e)
            self.queue_manager._complete_task(task)
            return False
    
    def _run_task_function(self, task: Task) -> Any:
        """ØªØ´ØºÙŠÙ„ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©"""
        try:
            # Ø¬Ù„Ø¨ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ù† queue_manager
            function = self.queue_manager.get_task_function(task.config.function_name)
            if not function:
                raise ValueError(f"Ø§Ù„Ø¯Ø§Ù„Ø© {task.config.function_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ù„Ø©
            if asyncio.iscoroutinefunction(function):
                # Ø¯Ø§Ù„Ø© async
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    return loop.run_until_complete(function(*task.config.args, **task.config.kwargs))
                finally:
                    loop.close()
            else:
                # Ø¯Ø§Ù„Ø© Ø¹Ø§Ø¯ÙŠØ©
                return function(*task.config.args, **task.config.kwargs)
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            raise
    
    def _retry_task(self, task: Task) -> bool:
        """Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©"""
        try:
            task.result.retry_count += 1
            task.result.status = TaskStatus.RETRYING
            
            logger.info(f"Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ù…Ø© {task.config.task_id} - Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {task.result.retry_count}")
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
            time.sleep(task.config.retry_delay * task.result.retry_count)
            
            # Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±
            task.result.status = TaskStatus.PENDING
            return self.queue_manager.requeue_task(task)
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            return False

class QueueManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    
    def __init__(self, max_workers: int = 10):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±"""
        self.max_workers = max_workers
        self.queues: Dict[str, TaskQueue] = {}
        self.workers: Dict[str, Worker] = {}
        self.task_functions: Dict[str, Callable] = {}
        self.global_stats = {
            'total_tasks_processed': 0,
            'total_tasks_failed': 0,
            'average_processing_time': 0.0,
            'uptime_start': datetime.now(timezone.utc)
        }
        
        self._running = False
        self._lock = threading.RLock()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ù„Ù„Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø¢Ù…Ù†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """Ù…Ø¹Ø§Ù„Ø¬ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        logger.info(f"ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¥Ø´Ø§Ø±Ø© {signum}ØŒ Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¯ÙŠØ± Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±...")
        self.shutdown()
        sys.exit(0)
    
    def create_queue(self, name: str, queue_type: QueueType = QueueType.FIFO, max_size: Optional[int] = None) -> TaskQueue:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø·Ø§Ø¨ÙˆØ± Ø¬Ø¯ÙŠØ¯"""
        try:
            with self._lock:
                if name in self.queues:
                    logger.warning(f"Ø§Ù„Ø·Ø§Ø¨ÙˆØ± {name} Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„")
                    return self.queues[name]
                
                queue = TaskQueue(name, queue_type, max_size)
                self.queues[name] = queue
                
                logger.info(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø·Ø§Ø¨ÙˆØ± {name} Ù…Ù† Ù†ÙˆØ¹ {queue_type.value}")
                return queue
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±: {e}")
            raise
    
    def register_task_function(self, name: str, function: Callable):
        """ØªØ³Ø¬ÙŠÙ„ Ø¯Ø§Ù„Ø© Ù…Ù‡Ù…Ø©"""
        try:
            self.task_functions[name] = function
            logger.info(f"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø© {name}")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
    
    def get_task_function(self, name: str) -> Optional[Callable]:
        """Ø¬Ù„Ø¨ Ø¯Ø§Ù„Ø© Ù…Ù‡Ù…Ø©"""
        return self.task_functions.get(name)
    
    def submit_task(self, queue_name: str, task_config: TaskConfig) -> bool:
        """Ø¥Ø±Ø³Ø§Ù„ Ù…Ù‡Ù…Ø© Ø¥Ù„Ù‰ Ø·Ø§Ø¨ÙˆØ±"""
        try:
            queue = self.queues.get(queue_name)
            if not queue:
                logger.error(f"Ø§Ù„Ø·Ø§Ø¨ÙˆØ± {queue_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
                return False
            
            task = Task(task_config)
            success = queue.put(task)
            
            if success:
                logger.info(f"ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© {task_config.task_id} Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨ÙˆØ± {queue_name}")
                
                # Ø­ÙØ¸ ÙÙŠ Redis Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
                if REDIS_AVAILABLE:
                    self._cache_task(task)
            
            return success
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            return False
    
    def get_next_task(self, timeout: Optional[float] = None) -> Optional[Task]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù…Ù† Ø£ÙŠ Ø·Ø§Ø¨ÙˆØ±"""
        try:
            # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Round Robin Ù„Ù„Ø·ÙˆØ§Ø¨ÙŠØ±
            queue_names = list(self.queues.keys())
            if not queue_names:
                return None
            
            for queue_name in queue_names:
                queue = self.queues[queue_name]
                task = queue.get(timeout=0.1)  # timeout Ù‚ØµÙŠØ± Ù„ÙƒÙ„ Ø·Ø§Ø¨ÙˆØ±
                if task:
                    return task
            
            return None
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: {e}")
            return None
    
    def requeue_task(self, task: Task) -> bool:
        """Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø·Ø§Ø¨ÙˆØ± Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‡Ù…Ø©
            for queue in self.queues.values():
                if task.config.task_id in queue._tasks:
                    return queue.put(task)
            
            logger.error(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø·Ø§Ø¨ÙˆØ± Ù„Ù„Ù…Ù‡Ù…Ø© {task.config.task_id}")
            return False
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            return False
    
    def _complete_task(self, task: Task):
        """Ø¥ÙƒÙ…Ø§Ù„ Ù…Ù‡Ù…Ø©"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø·Ø§Ø¨ÙˆØ± ÙˆØ¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù…Ù‡Ù…Ø©
            for queue in self.queues.values():
                if task.config.task_id in queue._tasks:
                    queue.task_done(task)
                    break
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
            self.global_stats['total_tasks_processed'] += 1
            if task.result.status == TaskStatus.FAILED:
                self.global_stats['total_tasks_failed'] += 1
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Redis
            if REDIS_AVAILABLE:
                self._cache_task_result(task)
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
    
    def start_workers(self, num_workers: Optional[int] = None):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ù…Ø§Ù„"""
        try:
            if self._running:
                logger.warning("Ø§Ù„Ø¹Ù…Ø§Ù„ ÙŠØ¹Ù…Ù„ÙˆÙ† Ø¨Ø§Ù„ÙØ¹Ù„")
                return
            
            num_workers = num_workers or self.max_workers
            
            with self._lock:
                for i in range(num_workers):
                    worker_id = f"worker_{i+1}"
                    worker = Worker(worker_id, self)
                    self.workers[worker_id] = worker
                    worker.start()
                
                self._running = True
                logger.info(f"ØªÙ… Ø¨Ø¯Ø¡ {num_workers} Ø¹Ø§Ù…Ù„")
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ù…Ø§Ù„: {e}")
    
    def stop_workers(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ø§Ù„"""
        try:
            with self._lock:
                for worker in self.workers.values():
                    worker.stop()
                
                self.workers.clear()
                self._running = False
                logger.info("ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ø§Ù„")
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ø§Ù„: {e}")
    
    def get_task_status(self, task_id: str) -> Optional[TaskResult]:
        """Ø¬Ù„Ø¨ Ø­Ø§Ù„Ø© Ù…Ù‡Ù…Ø©"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±
            for queue in self.queues.values():
                task = queue.get_task(task_id)
                if task:
                    return task.result
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Redis
            if REDIS_AVAILABLE:
                cached_result = cache_get(f"task_result_{task_id}")
                if cached_result:
                    return TaskResult(**json.loads(cached_result))
            
            return None
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            return None
    
    def cancel_task(self, task_id: str) -> bool:
        """Ø¥Ù„ØºØ§Ø¡ Ù…Ù‡Ù…Ø©"""
        try:
            for queue in self.queues.values():
                if queue.cancel_task(task_id):
                    logger.info(f"ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø© {task_id}")
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
            return False
    
    def get_queue_stats(self, queue_name: str) -> Optional[QueueStats]:
        """Ø¬Ù„Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø·Ø§Ø¨ÙˆØ±"""
        queue = self.queues.get(queue_name)
        return queue.stats if queue else None
    
    def get_worker_stats(self, worker_id: str) -> Optional[WorkerStats]:
        """Ø¬Ù„Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ù„"""
        worker = self.workers.get(worker_id)
        return worker.stats if worker else None
    
    def get_global_stats(self) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©"""
        stats = self.global_stats.copy()
        stats['uptime_seconds'] = (datetime.now(timezone.utc) - stats['uptime_start']).total_seconds()
        stats['active_workers'] = len([w for w in self.workers.values() if w._running])
        stats['total_queues'] = len(self.queues)
        stats['total_pending_tasks'] = sum(q.stats.pending_tasks for q in self.queues.values())
        stats['total_running_tasks'] = sum(q.stats.running_tasks for q in self.queues.values())
        return stats
    
    def _cache_task(self, task: Task):
        """Ø­ÙØ¸ Ù…Ù‡Ù…Ø© ÙÙŠ Ø§Ù„ÙƒØ§Ø´"""
        try:
            if REDIS_AVAILABLE:
                cache_key = f"task_{task.config.task_id}"
                cache_data = json.dumps(asdict(task.config), default=str)
                cache_set(cache_key, cache_data, expire=86400)  # 24 Ø³Ø§Ø¹Ø©
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø§Ù„ÙƒØ§Ø´: {e}")
    
    def _cache_task_result(self, task: Task):
        """Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ù…Ù‡Ù…Ø© ÙÙŠ Ø§Ù„ÙƒØ§Ø´"""
        try:
            if REDIS_AVAILABLE:
                cache_key = f"task_result_{task.config.task_id}"
                cache_data = json.dumps(asdict(task.result), default=str)
                cache_set(cache_key, cache_data, expire=86400)  # 24 Ø³Ø§Ø¹Ø©
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø§Ù„ÙƒØ§Ø´: {e}")
    
    def shutdown(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ù…Ø¯ÙŠØ± Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±"""
        try:
            logger.info("Ø¨Ø¯Ø¡ Ø¥ØºÙ„Ø§Ù‚ Ù…Ø¯ÙŠØ± Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±...")
            
            # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ø§Ù„
            self.stop_workers()
            
            # Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¬Ø¯ÙˆÙ„Ø§Øª Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±
            for queue in self.queues.values():
                queue.stop_scheduler()
            
            # Ù…Ø³Ø­ Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±
            self.queues.clear()
            
            logger.info("ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ù…Ø¯ÙŠØ± Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ± Ø¨Ù†Ø¬Ø§Ø­")
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥ØºÙ„Ø§Ù‚ Ù…Ø¯ÙŠØ± Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ±: {e}")

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ± Ø§Ù„Ø¹Ø§Ù…
queue_manager = QueueManager()

# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³Ù‡Ù„
def create_queue(name: str, queue_type: QueueType = QueueType.FIFO, max_size: Optional[int] = None) -> TaskQueue:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø·Ø§Ø¨ÙˆØ± Ø¬Ø¯ÙŠØ¯"""
    return queue_manager.create_queue(name, queue_type, max_size)

def register_task_function(name: str, function: Callable):
    """ØªØ³Ø¬ÙŠÙ„ Ø¯Ø§Ù„Ø© Ù…Ù‡Ù…Ø©"""
    queue_manager.register_task_function(name, function)

def submit_task(queue_name: str, task_id: str, function_name: str, 
               *args, priority: TaskPriority = TaskPriority.NORMAL, **kwargs) -> bool:
    """Ø¥Ø±Ø³Ø§Ù„ Ù…Ù‡Ù…Ø© Ø¨Ø³ÙŠØ·Ø©"""
    config = TaskConfig(
        task_id=task_id,
        task_type="simple",
        function_name=function_name,
        args=args,
        kwargs=kwargs,
        priority=priority
    )
    return queue_manager.submit_task(queue_name, config)

def get_task_status(task_id: str) -> Optional[TaskResult]:
    """Ø¬Ù„Ø¨ Ø­Ø§Ù„Ø© Ù…Ù‡Ù…Ø©"""
    return queue_manager.get_task_status(task_id)

def start_workers(num_workers: Optional[int] = None):
    """Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ù…Ø§Ù„"""
    queue_manager.start_workers(num_workers)

def stop_workers():
    """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ø§Ù„"""
    queue_manager.stop_workers()

# ØªØ³Ø¬ÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨Ø¯Ø¡
logger.info(f"ğŸš€ ØªÙ… ØªØ­Ù…ÙŠÙ„ Queue Manager Module v2.2.0")
logger.info(f"ğŸ’¾ Redis Ù…ØªØ§Ø­: {REDIS_AVAILABLE}")
logger.info(f"ğŸ”§ Helpers Ù…ØªØ§Ø­: {HELPERS_AVAILABLE}")
logger.info(f"âš¡ Ù…Ø¯ÙŠØ± Ø§Ù„Ø·ÙˆØ§Ø¨ÙŠØ± Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…")

