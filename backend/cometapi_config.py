#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª CometAPI - Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ø±Ø³Ù…ÙŠØ©
CometAPI Configuration based on official documentation
"""

import os
import requests
import logging
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Ù…Ù„Ù .env.development
load_dotenv(dotenv_path='.env.development')

logger = logging.getLogger(__name__)

class CometAPIConfig:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª CometAPI Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ø±Ø³Ù…ÙŠØ©"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª CometAPI"""
        self.api_key = os.getenv("COMETAPI_API_KEY")
        self.base_url = "https://api.cometapi.com"
        
        if not self.api_key:
            raise ValueError("COMETAPI_API_KEY environment variable not set")
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª CometAPI")
    
    def get_available_models(self) -> Dict[str, List[str]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ù† CometAPI - Ù…Ø­Ø¯Ø« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ¹Ù„ÙŠØ©"""
        return {
            "text_models": [
                "gpt-4o",
                "gpt-4o-mini", 
                "gpt-4-turbo",
                "gpt-3.5-turbo",
                "claude-3-5-sonnet-20241022",
                "claude-3-5-haiku-20241022",
                "claude-3-opus-20240229",
                "gemini-2.0-flash-exp",
                "gemini-1.5-pro",
                "gemini-1.5-flash",
                "llama-2-13b-chat",
                "llama-2-70b-chat",
                "mistral-7b-instruct",
                "mistral-8x7b-instruct",
                "qwen-2.5-7b-instruct",
                "qwen-2.5-14b-instruct",
                "qwen-2.5-32b-instruct",
                "deepseek-chat",
                "deepseek-coder",
                # Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø¶Ø§ÙÙŠØ© Ù…ØªØ§Ø­Ø©
                "gpt-4o-all",
                "gpt-4o-mini-2024-07-18",
                "claude-3-5-sonnet-latest",
                "claude-3-5-haiku-latest",
                "gemini-2.0-flash",
                "gemini-2.5-flash",
                "gemini-2.5-pro",
                "qwen-max",
                "qwen-plus",
                "qwen-turbo",
                "deepseek-v3",
                "deepseek-r1",
                "o1-mini",
                "o1-preview",
                "grok-2",
                "grok-3"
            ],
            "image_models": [
                "dall-e-3",
                "dall-e-2",
                "midjourney",
                "stable-diffusion-v1.5",
                "stable-diffusion-v2.1",
                "stable-diffusion-xl",
                "flux-1.1-pro",
                "flux-1.1-schnell",
                # Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø¶Ø§ÙÙŠØ© Ù…ØªØ§Ø­Ø©
                "flux-pro",
                "flux-dev",
                "flux-kontext-max",
                "flux-kontext-pro",
                "stable-diffusion-3",
                "stable-diffusion-3.5-large",
                "stable-diffusion-3.5-medium",
                "ideogram-v3/generate",
                "ideogram-v3/edit",
                "runwayml_text_to_image",
                "kling_image"
            ],
            "audio_models": [
                "suno-v3",
                "suno-v3.5",
                "udio-v1",
                "whisper-1",
                # Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø¶Ø§ÙÙŠØ© Ù…ØªØ§Ø­Ø©
                "suno_music",
                "suno_lyrics",
                "tts-1",
                "tts-1-hd",
                "kling_audio_text_to_audio"
            ],
            "vision_models": [
                "gpt-4o",
                "gpt-4o-mini",
                "claude-3-5-sonnet-20241022",
                "claude-3-5-haiku-20241022",
                "claude-3-opus-20240229",
                "gemini-2.0-flash-exp",
                "gemini-1.5-pro",
                "gemini-1.5-flash",
                # Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø¶Ø§ÙÙŠØ© Ù…ØªØ§Ø­Ø©
                "gpt-4o-image",
                "gpt-4-vision",
                "claude-3-5-sonnet-latest",
                "claude-3-5-haiku-latest",
                "gemini-2.0-flash",
                "gemini-2.5-flash",
                "gemini-2.5-pro",
                "qwen-vl-max",
                "qwen-vl-plus",
                "qwen2-vl-72b-instruct",
                "qwen2-vl-7b-instruct",
                "grok-2-vision-1212",
                "grok-3-deepersearch",
                "grok-3-deepsearch",
                "grok-3-search"
            ]
        }
    
    def get_model_pricing(self) -> Dict[str, Dict[str, float]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (ØªÙ‚Ø¯ÙŠØ±ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ CometAPI)"""
        return {
            "text_models": {
                "gpt-4o": {"input": 0.0025, "output": 0.01},
                "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},
                "gpt-4-turbo": {"input": 0.01, "output": 0.03},
                "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015},
                "claude-3-5-sonnet-20241022": {"input": 0.003, "output": 0.015},
                "claude-3-5-haiku-20241022": {"input": 0.00025, "output": 0.00125},
                "claude-3-opus-20240229": {"input": 0.015, "output": 0.075},
                "gemini-2.0-flash-exp": {"input": 0.000075, "output": 0.0003},
                "gemini-1.5-pro": {"input": 0.00125, "output": 0.005},
                "gemini-1.5-flash": {"input": 0.000075, "output": 0.0003},
                "llama-2-13b-chat": {"input": 0.0003, "output": 0.0003},
                "llama-2-70b-chat": {"input": 0.0007, "output": 0.0007},
                "mistral-7b-instruct": {"input": 0.0002, "output": 0.0002},
                "mistral-8x7b-instruct": {"input": 0.0003, "output": 0.0003},
                "qwen-2.5-7b-instruct": {"input": 0.0002, "output": 0.0002},
                "qwen-2.5-14b-instruct": {"input": 0.0003, "output": 0.0003},
                "qwen-2.5-32b-instruct": {"input": 0.0005, "output": 0.0005},
                "deepseek-chat": {"input": 0.0002, "output": 0.0002},
                "deepseek-coder": {"input": 0.0002, "output": 0.0002}
            },
            "image_models": {
                "dall-e-3": {"1024x1024": 0.04, "1024x1792": 0.08, "1792x1024": 0.08},
                "dall-e-2": {"1024x1024": 0.02, "512x512": 0.018, "256x256": 0.016},
                "midjourney": {"standard": 0.05, "hd": 0.1},
                "stable-diffusion-v1.5": {"standard": 0.01},
                "stable-diffusion-v2.1": {"standard": 0.01},
                "stable-diffusion-xl": {"standard": 0.02},
                "flux-1.1-pro": {"standard": 0.03},
                "flux-1.1-schnell": {"standard": 0.015}
            },
            "audio_models": {
                "suno-v3": {"standard": 0.1},
                "suno-v3.5": {"standard": 0.12},
                "udio-v1": {"standard": 0.08},
                "whisper-1": {"per_minute": 0.006}
            }
        }
    
    def get_recommended_models_for_ads(self) -> Dict[str, str]:
        """Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§ Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙƒÙ„ÙØ© ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡ - Ù…Ø­Ø¯Ø« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ¹Ù„ÙŠØ©"""
        return {
            "text_generation": "gpt-4o-mini",  # Ø£Ø±Ø®Øµ Ù„Ù„Ù†ØµÙˆØµ
            "text_advanced": "gpt-4o-mini",  # Ù…ØªÙˆØ§Ø²Ù† Ù„Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªÙƒÙ„ÙØ©
            "text_premium": "gpt-4o",  # Ø£ÙØ¶Ù„ Ø¬ÙˆØ¯Ø©
            "text_budget": "qwen-2.5-7b-instruct",  # Ø£Ø±Ø®Øµ Ø¨Ø¯ÙŠÙ„
            "text_creative": "claude-3-5-sonnet-20241022",  # Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ Ù„Ù„Ù†ØµÙˆØµ
            "image_generation": "dall-e-3",  # Ø£ÙØ¶Ù„ Ø¬ÙˆØ¯Ø© Ù„Ù„ØµÙˆØ±
            "image_budget": "stable-diffusion-v1.5",  # Ø£Ø±Ø®Øµ Ù„Ù„ØµÙˆØ±
            "image_creative": "flux-1.1-pro",  # Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ Ù„Ù„ØµÙˆØ±
            "image_advanced": "stable-diffusion-3.5-large",  # Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØµÙˆØ±
            "vision_analysis": "gpt-4o-mini",  # Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±
            "vision_advanced": "gpt-4o",  # Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±
            "keyword_extraction": "gpt-4o-mini",  # Ø£Ø±Ø®Øµ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
            "ad_copy_generation": "mistral-7b-instruct",  # Ø¬ÙŠØ¯ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©
            "website_analysis": "claude-3-5-haiku-20241022",  # Ø³Ø±ÙŠØ¹ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹
            "content_optimization": "gpt-4o-mini",  # Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            "arabic_content": "qwen-2.5-7b-instruct",  # Ø¬ÙŠØ¯ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
            "multilingual": "gemini-2.0-flash-exp"  # Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª
        }
    
    def get_api_endpoints(self) -> Dict[str, str]:
        """Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© CometAPI"""
        return {
            "chat_completions": f"{self.base_url}/v1/chat/completions",
            "images_generations": f"{self.base_url}/v1/images/generations",
            "audio_transcriptions": f"{self.base_url}/v1/audio/transcriptions",
            "audio_generations": f"{self.base_url}/v1/audio/generations",
            "models_list": f"{self.base_url}/v1/models",
            "usage": f"{self.base_url}/v1/usage"
        }
    
    def get_headers(self) -> Dict[str, str]:
        """Ø±Ø¤ÙˆØ³ HTTP Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù€ CometAPI"""
        return {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "User-Agent": "CometAPI-Python-Client/1.0"
        }
    
    def test_connection(self) -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ CometAPI"""
        try:
            self.logger.info("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ CometAPI...")
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            response = requests.get(
                self.get_api_endpoints()["models_list"],
                headers=self.get_headers(),
                timeout=10
            )
            
            if response.status_code == 200:
                models_data = response.json()
                self.logger.info("âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ CometAPI Ø¨Ù†Ø¬Ø§Ø­")
                return {
                    "success": True,
                    "status": "connected",
                    "models_count": len(models_data.get("data", [])),
                    "available_models": [model.get("id") for model in models_data.get("data", [])]
                }
            else:
                self.logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ CometAPI: {response.status_code}")
                return {
                    "success": False,
                    "status": "failed",
                    "error": f"HTTP {response.status_code}",
                    "message": response.text
                }
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
            return {
                "success": False,
                "status": "error",
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„"
            }
    
    def get_usage_info(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
        try:
            response = requests.get(
                self.get_api_endpoints()["usage"],
                headers=self.get_headers(),
                timeout=10
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}",
                    "message": response.text
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "message": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"
            }

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    config = CometAPIConfig()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„
    connection_test = config.test_connection()
    print("Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„:")
    print(connection_test)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
    models = config.get_available_models()
    print("\nØ§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©:")
    for category, model_list in models.items():
        print(f"{category}: {len(model_list)} Ù†Ù…ÙˆØ°Ø¬")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§
    recommended = config.get_recommended_models_for_ads()
    print("\nØ§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§ Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª:")
    for purpose, model in recommended.items():
        print(f"{purpose}: {model}")
    
    # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    usage = config.get_usage_info()
    print("\nÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:")
    print(usage)
