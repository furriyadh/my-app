"""
AI Recommendations Service
Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ

Ø®Ø¯Ù…Ø© Ù…ØªØ·ÙˆØ±Ø© Ù„ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø°ÙƒÙŠØ© ÙˆÙ…Ø®ØµØµØ© Ù„ØªØ­Ø³ÙŠÙ† Ø­Ù…Ù„Ø§Øª Google Ads
ØªØªØ¶Ù…Ù† ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©ØŒ Ø§Ù„Ø¹Ø±ÙˆØ¶ØŒ Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§ÙØŒ ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰

Author: AI Recommendations Team
Version: 3.0.0
Security Level: Enterprise
Performance: AI-Optimized & ML-Powered
"""

import asyncio
import logging
import time
import hashlib
import json
import math
from typing import Dict, List, Any, Optional, Union, Tuple, Set
from datetime import datetime, timezone, timedelta
from dataclasses import dataclass, field
from enum import Enum, auto
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from functools import wraps, lru_cache

# Flask imports
from flask import Blueprint, request, jsonify, current_app
from flask_jwt_extended import jwt_required, get_jwt_identity

# AI and ML imports
try:
    import numpy as np
    import pandas as pd
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
    from sklearn.cluster import KMeans
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, mean_squared_error
    import nltk
    from textblob import TextBlob
    ML_AVAILABLE = True
except ImportError as e:
    ML_AVAILABLE = False
    logging.warning(f"Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­Ø©: {e}")

# Local imports
try:
    from utils.helpers import (
        validate_input, sanitize_text, generate_unique_id,
        cache_result, get_cached_result, log_performance
    )
    from utils.redis_config import get_redis_client
    from services.google_ads_client import GoogleAdsClient
except ImportError as e:
    logging.warning(f"Ø¨Ø¹Ø¶ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© ØºÙŠØ± Ù…ØªØ§Ø­Ø©: {e}")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logger = logging.getLogger(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯ Blueprint
ai_recommendations_bp = Blueprint(
    'ai_recommendations',
    __name__,
    url_prefix='/api/ai/recommendations'
)

# Ø¥Ø¹Ø¯Ø§Ø¯ Thread Pool Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©
recommendations_executor = ThreadPoolExecutor(max_workers=20, thread_name_prefix="recommendations_worker")

class RecommendationType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    KEYWORD_EXPANSION = "keyword_expansion"           # ØªÙˆØ³ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
    BID_OPTIMIZATION = "bid_optimization"             # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ø±ÙˆØ¶
    AD_COPY_IMPROVEMENT = "ad_copy_improvement"       # ØªØ­Ø³ÙŠÙ† Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†
    AUDIENCE_TARGETING = "audience_targeting"         # Ø§Ø³ØªÙ‡Ø¯Ø§Ù Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±
    BUDGET_ALLOCATION = "budget_allocation"           # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©
    LANDING_PAGE_OPTIMIZATION = "landing_page_optimization"  # ØªØ­Ø³ÙŠÙ† ØµÙØ­Ø© Ø§Ù„Ù‡Ø¨ÙˆØ·
    NEGATIVE_KEYWORDS = "negative_keywords"           # Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø³Ù„Ø¨ÙŠØ©
    CAMPAIGN_STRUCTURE = "campaign_structure"         # Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø­Ù…Ù„Ø©
    SCHEDULING_OPTIMIZATION = "scheduling_optimization"  # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©
    DEVICE_TARGETING = "device_targeting"             # Ø§Ø³ØªÙ‡Ø¯Ø§Ù Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©

class RecommendationPriority(Enum):
    """Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    CRITICAL = "critical"     # Ø­Ø±Ø¬
    HIGH = "high"            # Ø¹Ø§Ù„ÙŠ
    MEDIUM = "medium"        # Ù…ØªÙˆØ³Ø·
    LOW = "low"              # Ù…Ù†Ø®ÙØ¶

class RecommendationStatus(Enum):
    """Ø­Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ©"""
    PENDING = "pending"           # ÙÙŠ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±
    APPLIED = "applied"           # Ù…Ø·Ø¨Ù‚Ø©
    REJECTED = "rejected"         # Ù…Ø±ÙÙˆØ¶Ø©
    EXPIRED = "expired"           # Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©

class ImpactLevel(Enum):
    """Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ£Ø«ÙŠØ±"""
    HIGH = "high"        # Ø¹Ø§Ù„ÙŠ
    MEDIUM = "medium"    # Ù…ØªÙˆØ³Ø·
    LOW = "low"          # Ù…Ù†Ø®ÙØ¶

@dataclass
class KeywordRecommendation:
    """ØªÙˆØµÙŠØ© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
    keyword: str
    match_type: str
    estimated_cpc: float
    search_volume: int
    competition_level: str
    relevance_score: float
    potential_impressions: int
    potential_clicks: int
    potential_conversions: float
    confidence_score: float

@dataclass
class BidRecommendation:
    """ØªÙˆØµÙŠØ© Ø§Ù„Ø¹Ø±ÙˆØ¶"""
    keyword_or_adgroup: str
    current_bid: float
    recommended_bid: float
    bid_change_percentage: float
    expected_position_change: float
    expected_cost_change: float
    expected_conversion_change: float
    reasoning: str

@dataclass
class AdCopyRecommendation:
    """ØªÙˆØµÙŠØ© Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†"""
    current_headline: str
    recommended_headline: str
    current_description: str
    recommended_description: str
    improvement_reason: str
    expected_ctr_improvement: float
    a_b_test_suggestion: bool

@dataclass
class AudienceRecommendation:
    """ØªÙˆØµÙŠØ© Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±"""
    audience_type: str
    audience_name: str
    audience_size: int
    targeting_criteria: Dict[str, Any]
    expected_performance: Dict[str, float]
    overlap_with_existing: float

@dataclass
class RecommendationData:
    """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙˆØµÙŠØ©"""
    recommendation_id: str
    recommendation_type: RecommendationType
    priority: RecommendationPriority
    title: str
    description: str
    impact_level: ImpactLevel
    estimated_impact: Dict[str, float]
    implementation_effort: str
    implementation_steps: List[str]
    expected_results: Dict[str, Any]
    confidence_score: float
    supporting_data: Dict[str, Any]
    expiry_date: datetime
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    status: RecommendationStatus = RecommendationStatus.PENDING

@dataclass
class RecommendationsRequest:
    """Ø·Ù„Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    campaign_ids: List[str]
    recommendation_types: List[RecommendationType]
    priority_filter: Optional[RecommendationPriority] = None
    max_recommendations: int = 20
    include_implementation_guide: bool = True
    performance_goals: Dict[str, float] = field(default_factory=dict)

@dataclass
class RecommendationsResponse:
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    request_id: str
    total_recommendations: int
    recommendations: List[RecommendationData]
    summary: Dict[str, Any]
    processing_time: float
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

class AIRecommendationsService:
    """Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        self.cache_ttl = 1800  # 30 Ø¯Ù‚ÙŠÙ‚Ø©
        self.redis_client = None
        self.google_ads_client = None
        self.ml_models = {}
        self.keyword_database = {}
        self.performance_metrics = {
            'total_recommendations': 0,
            'successful_recommendations': 0,
            'failed_recommendations': 0,
            'applied_recommendations': 0,
            'average_processing_time': 0.0,
            'average_confidence_score': 0.0
        }
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
        self._initialize_clients()
        
        # ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ
        if ML_AVAILABLE:
            self._initialize_ml_models()
        
        # ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        self._load_keyword_database()
        
        logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    
    def _initialize_clients(self) -> None:
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠÙŠÙ†"""
        try:
            self.redis_client = get_redis_client()
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Redis Ù„Ù„ØªÙˆØµÙŠØ§Øª")
        except Exception as e:
            logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… ØªÙ‡ÙŠØ¦Ø© Redis: {e}")
        
        try:
            self.google_ads_client = GoogleAdsClient()
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Google Ads Ù„Ù„ØªÙˆØµÙŠØ§Øª")
        except Exception as e:
            logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… ØªÙ‡ÙŠØ¦Ø© Google Ads: {e}")
    
    def _initialize_ml_models(self) -> None:
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù„ØªÙˆØµÙŠØ§Øª"""
        try:
            # Ù†Ù…ÙˆØ°Ø¬ ØªÙˆÙ‚Ø¹ Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            self.ml_models['keyword_performance'] = {
                'model': RandomForestClassifier(n_estimators=100, random_state=42),
                'scaler': StandardScaler(),
                'encoder': LabelEncoder()
            }
            
            # Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ø±ÙˆØ¶
            self.ml_models['bid_optimizer'] = {
                'model': GradientBoostingRegressor(n_estimators=100, random_state=42),
                'scaler': StandardScaler()
            }
            
            # Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª
            self.ml_models['ad_copy_analyzer'] = {
                'vectorizer': TfidfVectorizer(max_features=1000, stop_words='english'),
                'similarity_threshold': 0.7
            }
            
            # Ù†Ù…ÙˆØ°Ø¬ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±
            self.ml_models['audience_clusterer'] = {
                'model': KMeans(n_clusters=8, random_state=42),
                'scaler': StandardScaler()
            }
            
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù„ØªÙˆØµÙŠØ§Øª")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ: {e}")
    
    def _load_keyword_database(self) -> None:
        """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        # Ù…Ø­Ø§ÙƒØ§Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        self.keyword_database = {
            'technology': {
                'keywords': ['software', 'app', 'digital', 'tech', 'innovation', 'AI', 'machine learning'],
                'avg_cpc': 2.5,
                'competition': 'high'
            },
            'marketing': {
                'keywords': ['advertising', 'promotion', 'brand', 'campaign', 'social media', 'SEO'],
                'avg_cpc': 3.2,
                'competition': 'high'
            },
            'business': {
                'keywords': ['consulting', 'strategy', 'management', 'enterprise', 'solution'],
                'avg_cpc': 4.1,
                'competition': 'medium'
            },
            'ecommerce': {
                'keywords': ['online store', 'shopping', 'buy', 'sale', 'discount', 'product'],
                'avg_cpc': 1.8,
                'competition': 'high'
            }
        }
        
        logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©")
    
    def _generate_cache_key(self, request_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        request_str = json.dumps(request_data, sort_keys=True, ensure_ascii=False)
        return f"recommendations:{hashlib.md5(request_str.encode()).hexdigest()}"
    
    def _simulate_campaign_data(self, campaign_id: str) -> Dict[str, Any]:
        """Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù…Ù„Ø©"""
        np.random.seed(hash(campaign_id) % 2**32)
        
        return {
            'campaign_id': campaign_id,
            'current_keywords': [
                f"keyword_{i}" for i in range(np.random.randint(10, 30))
            ],
            'current_performance': {
                'impressions': np.random.randint(1000, 10000),
                'clicks': np.random.randint(50, 500),
                'conversions': np.random.randint(5, 50),
                'cost': np.random.uniform(100, 1000),
                'ctr': np.random.uniform(1, 8),
                'cpc': np.random.uniform(0.5, 5.0),
                'conversion_rate': np.random.uniform(2, 15)
            },
            'current_bids': {
                f"keyword_{i}": np.random.uniform(0.5, 3.0)
                for i in range(np.random.randint(5, 15))
            },
            'ad_copies': [
                {
                    'headline': f"Ø¹Ù†ÙˆØ§Ù† Ø¥Ø¹Ù„Ø§Ù† {i}",
                    'description': f"ÙˆØµÙ Ø¥Ø¹Ù„Ø§Ù† {i}",
                    'ctr': np.random.uniform(1, 6)
                }
                for i in range(np.random.randint(2, 5))
            ],
            'target_audiences': [
                f"Ø¬Ù…Ù‡ÙˆØ±_{i}" for i in range(np.random.randint(1, 4))
            ],
            'budget': np.random.uniform(500, 5000),
            'goals': {
                'target_cpa': np.random.uniform(10, 50),
                'target_roas': np.random.uniform(300, 800)
            }
        }
    
    def _generate_keyword_recommendations(self, campaign_data: Dict[str, Any]) -> List[RecommendationData]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        recommendations = []
        
        try:
            current_keywords = set(campaign_data.get('current_keywords', []))
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø©
            category = self._detect_campaign_category(current_keywords)
            
            if category in self.keyword_database:
                suggested_keywords = self.keyword_database[category]['keywords']
                
                for keyword in suggested_keywords:
                    if keyword not in current_keywords:
                        # Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
                        keyword_data = KeywordRecommendation(
                            keyword=keyword,
                            match_type="broad",
                            estimated_cpc=np.random.uniform(1.0, 4.0),
                            search_volume=np.random.randint(1000, 10000),
                            competition_level="medium",
                            relevance_score=np.random.uniform(0.7, 0.95),
                            potential_impressions=np.random.randint(500, 5000),
                            potential_clicks=np.random.randint(25, 250),
                            potential_conversions=np.random.uniform(2, 25),
                            confidence_score=np.random.uniform(0.75, 0.95)
                        )
                        
                        recommendation = RecommendationData(
                            recommendation_id=generate_unique_id(),
                            recommendation_type=RecommendationType.KEYWORD_EXPANSION,
                            priority=RecommendationPriority.HIGH,
                            title=f"Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {keyword}",
                            description=f"ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„ØµÙ„Ø© Ø¨Ø­Ø¬Ù… Ø¨Ø­Ø« {keyword_data.search_volume:,}",
                            impact_level=ImpactLevel.MEDIUM,
                            estimated_impact={
                                'impressions_increase': keyword_data.potential_impressions,
                                'clicks_increase': keyword_data.potential_clicks,
                                'conversions_increase': keyword_data.potential_conversions,
                                'cost_increase': keyword_data.estimated_cpc * keyword_data.potential_clicks
                            },
                            implementation_effort="Ø³Ù‡Ù„",
                            implementation_steps=[
                                f"Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© '{keyword}' Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ÙŠØ©",
                                f"ØªØ¹ÙŠÙŠÙ† Ø¹Ø±Ø¶ Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠ {keyword_data.estimated_cpc:.2f}",
                                "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù…Ø¯Ø© Ø£Ø³Ø¨ÙˆØ¹",
                                "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¶ Ø­Ø³Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"
                            ],
                            expected_results={
                                'timeline': '1-2 Ø£Ø³Ø§Ø¨ÙŠØ¹',
                                'success_probability': keyword_data.confidence_score
                            },
                            confidence_score=keyword_data.confidence_score,
                            supporting_data=keyword_data.__dict__,
                            expiry_date=datetime.now(timezone.utc) + timedelta(days=30)
                        )
                        
                        recommendations.append(recommendation)
                        
                        if len(recommendations) >= 5:  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 5 ØªÙˆØµÙŠØ§Øª ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
                            break
        
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {e}")
        
        return recommendations
    
    def _detect_campaign_category(self, keywords: Set[str]) -> str:
        """ØªØ­Ø¯ÙŠØ¯ ÙØ¦Ø© Ø§Ù„Ø­Ù…Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
        category_scores = {}
        
        for category, data in self.keyword_database.items():
            score = 0
            for keyword in keywords:
                for category_keyword in data['keywords']:
                    if category_keyword.lower() in keyword.lower():
                        score += 1
            category_scores[category] = score
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ÙØ¦Ø© Ø°Ø§Øª Ø£Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø· Ø£Ùˆ ÙØ¦Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        return max(category_scores, key=category_scores.get) if category_scores else 'business'
    
    def _generate_bid_recommendations(self, campaign_data: Dict[str, Any]) -> List[RecommendationData]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ø±ÙˆØ¶"""
        recommendations = []
        
        try:
            current_bids = campaign_data.get('current_bids', {})
            performance = campaign_data.get('current_performance', {})
            
            for keyword, current_bid in current_bids.items():
                # Ù…Ø­Ø§ÙƒØ§Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØªÙˆØµÙŠØ© Ø§Ù„Ø¹Ø±Ø¶
                performance_score = np.random.uniform(0.3, 1.0)
                
                if performance_score < 0.6:  # Ø£Ø¯Ø§Ø¡ Ø¶Ø¹ÙŠÙ
                    # ØªÙˆØµÙŠØ© Ø¨Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¹Ø±Ø¶
                    recommended_bid = current_bid * np.random.uniform(1.1, 1.5)
                    change_percentage = (recommended_bid - current_bid) / current_bid * 100
                    
                    bid_rec = BidRecommendation(
                        keyword_or_adgroup=keyword,
                        current_bid=current_bid,
                        recommended_bid=recommended_bid,
                        bid_change_percentage=change_percentage,
                        expected_position_change=np.random.uniform(0.5, 2.0),
                        expected_cost_change=change_percentage,
                        expected_conversion_change=np.random.uniform(10, 30),
                        reasoning="Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¹Ø±Ø¶ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…ÙˆØ¶Ø¹ ÙˆØ§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù†Ù‚Ø±Ø§Øª"
                    )
                    
                    recommendation = RecommendationData(
                        recommendation_id=generate_unique_id(),
                        recommendation_type=RecommendationType.BID_OPTIMIZATION,
                        priority=RecommendationPriority.HIGH,
                        title=f"Ø²ÙŠØ§Ø¯Ø© Ø¹Ø±Ø¶ {keyword}",
                        description=f"Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¹Ø±Ø¶ Ù…Ù† {current_bid:.2f} Ø¥Ù„Ù‰ {recommended_bid:.2f}",
                        impact_level=ImpactLevel.MEDIUM,
                        estimated_impact={
                            'cost_increase_percentage': change_percentage,
                            'position_improvement': bid_rec.expected_position_change,
                            'conversion_increase_percentage': bid_rec.expected_conversion_change
                        },
                        implementation_effort="Ø³Ù‡Ù„",
                        implementation_steps=[
                            f"ØªØºÙŠÙŠØ± Ø¹Ø±Ø¶ '{keyword}' Ø¥Ù„Ù‰ {recommended_bid:.2f}",
                            "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù…Ø¯Ø© 3-5 Ø£ÙŠØ§Ù…",
                            "ØªØ­Ø³ÙŠÙ† Ø¥Ø¶Ø§ÙÙŠ Ø­Ø³Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"
                        ],
                        expected_results={
                            'timeline': '3-7 Ø£ÙŠØ§Ù…',
                            'success_probability': 0.8
                        },
                        confidence_score=0.8,
                        supporting_data=bid_rec.__dict__,
                        expiry_date=datetime.now(timezone.utc) + timedelta(days=14)
                    )
                    
                    recommendations.append(recommendation)
                    
                    if len(recommendations) >= 3:  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 3 ØªÙˆØµÙŠØ§Øª Ø¹Ø±ÙˆØ¶
                        break
        
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ø±ÙˆØ¶: {e}")
        
        return recommendations
    
    def _generate_ad_copy_recommendations(self, campaign_data: Dict[str, Any]) -> List[RecommendationData]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†"""
        recommendations = []
        
        try:
            ad_copies = campaign_data.get('ad_copies', [])
            
            for i, ad_copy in enumerate(ad_copies):
                current_ctr = ad_copy.get('ctr', 0)
                
                if current_ctr < 3.0:  # CTR Ù…Ù†Ø®ÙØ¶
                    # ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª ØªØ­Ø³ÙŠÙ†
                    improved_headline = self._improve_headline(ad_copy.get('headline', ''))
                    improved_description = self._improve_description(ad_copy.get('description', ''))
                    
                    ad_copy_rec = AdCopyRecommendation(
                        current_headline=ad_copy.get('headline', ''),
                        recommended_headline=improved_headline,
                        current_description=ad_copy.get('description', ''),
                        recommended_description=improved_description,
                        improvement_reason="ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø± Ù…Ù† Ø®Ù„Ø§Ù„ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø£ÙƒØ«Ø± Ø¬Ø§Ø°Ø¨ÙŠØ©",
                        expected_ctr_improvement=np.random.uniform(15, 40),
                        a_b_test_suggestion=True
                    )
                    
                    recommendation = RecommendationData(
                        recommendation_id=generate_unique_id(),
                        recommendation_type=RecommendationType.AD_COPY_IMPROVEMENT,
                        priority=RecommendationPriority.MEDIUM,
                        title=f"ØªØ­Ø³ÙŠÙ† Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† {i+1}",
                        description="ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„ÙˆØµÙ Ù„Ø²ÙŠØ§Ø¯Ø© Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù‚Ø±",
                        impact_level=ImpactLevel.MEDIUM,
                        estimated_impact={
                            'ctr_improvement_percentage': ad_copy_rec.expected_ctr_improvement,
                            'clicks_increase_percentage': ad_copy_rec.expected_ctr_improvement * 0.8
                        },
                        implementation_effort="Ù…ØªÙˆØ³Ø·",
                        implementation_steps=[
                            "Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ù† Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†",
                            "ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± A/B Ù„Ù…Ø¯Ø© Ø£Ø³Ø¨ÙˆØ¹ÙŠÙ†",
                            "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„",
                            "ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¹Ù„Ù‰ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª"
                        ],
                        expected_results={
                            'timeline': '2-3 Ø£Ø³Ø§Ø¨ÙŠØ¹',
                            'success_probability': 0.75
                        },
                        confidence_score=0.75,
                        supporting_data=ad_copy_rec.__dict__,
                        expiry_date=datetime.now(timezone.utc) + timedelta(days=21)
                    )
                    
                    recommendations.append(recommendation)
                    
                    if len(recommendations) >= 2:  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 2 ØªÙˆØµÙŠØ§Øª Ù†Øµ Ø¥Ø¹Ù„Ø§Ù†
                        break
        
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†: {e}")
        
        return recommendations
    
    def _improve_headline(self, current_headline: str) -> str:
        """ØªØ­Ø³ÙŠÙ† Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†"""
        improvements = [
            "ğŸ”¥ Ø¹Ø±Ø¶ Ø®Ø§Øµ - ",
            "âœ… Ø§Ù„Ø£ÙØ¶Ù„ ÙÙŠ ",
            "ğŸ’¯ Ø¬ÙˆØ¯Ø© Ù…Ø¶Ù…ÙˆÙ†Ø© - ",
            "âš¡ Ø³Ø±ÙŠØ¹ ÙˆÙ…ÙˆØ«ÙˆÙ‚ - ",
            "ğŸ¯ Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ù…Ø«Ù„ Ù„Ù€ "
        ]
        
        if current_headline:
            return np.random.choice(improvements) + current_headline
        else:
            return "Ø¹Ù†ÙˆØ§Ù† Ù…Ø­Ø³Ù† Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
    
    def _improve_description(self, current_description: str) -> str:
        """ØªØ­Ø³ÙŠÙ† ÙˆØµÙ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†"""
        improvements = [
            " - Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙŠÙˆÙ…!",
            " - Ø¬Ø±Ø¨ Ø§Ù„Ø¢Ù† Ù…Ø¬Ø§Ù†Ø§Ù‹!",
            " - Ø®ØµÙ… Ø®Ø§Øµ Ù„ÙØªØ±Ø© Ù…Ø­Ø¯ÙˆØ¯Ø©!",
            " - Ø§ÙƒØªØ´Ù Ø§Ù„ÙØ±Ù‚ Ø¨Ù†ÙØ³Ùƒ!",
            " - Ø§Ù†Ø¶Ù… Ù„Ø¢Ù„Ø§Ù Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø±Ø§Ø¶ÙŠÙ†!"
        ]
        
        if current_description:
            return current_description + np.random.choice(improvements)
        else:
            return "ÙˆØµÙ Ù…Ø­Ø³Ù† Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
    
    def _generate_audience_recommendations(self, campaign_data: Dict[str, Any]) -> List[RecommendationData]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±"""
        recommendations = []
        
        try:
            current_audiences = campaign_data.get('target_audiences', [])
            
            # ØªÙˆØµÙŠØ§Øª Ø¬Ù…Ø§Ù‡ÙŠØ± Ø¬Ø¯ÙŠØ¯Ø©
            suggested_audiences = [
                {
                    'name': 'Ø§Ù„Ù…Ù‡ØªÙ…ÙˆÙ† Ø¨Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§',
                    'type': 'interest',
                    'size': np.random.randint(50000, 500000),
                    'criteria': {'interests': ['technology', 'innovation', 'gadgets']}
                },
                {
                    'name': 'Ø§Ù„Ù…ØªØ³ÙˆÙ‚ÙˆÙ† Ø¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª',
                    'type': 'behavior',
                    'size': np.random.randint(100000, 1000000),
                    'criteria': {'behaviors': ['online_shopping', 'frequent_buyers']}
                },
                {
                    'name': 'Ø£ØµØ­Ø§Ø¨ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„',
                    'type': 'demographic',
                    'size': np.random.randint(30000, 300000),
                    'criteria': {'job_titles': ['CEO', 'Manager', 'Director']}
                }
            ]
            
            for audience in suggested_audiences:
                if audience['name'] not in current_audiences:
                    audience_rec = AudienceRecommendation(
                        audience_type=audience['type'],
                        audience_name=audience['name'],
                        audience_size=audience['size'],
                        targeting_criteria=audience['criteria'],
                        expected_performance={
                            'ctr': np.random.uniform(2.5, 5.0),
                            'conversion_rate': np.random.uniform(3.0, 8.0),
                            'cpc': np.random.uniform(1.0, 3.0)
                        },
                        overlap_with_existing=np.random.uniform(10, 30)
                    )
                    
                    recommendation = RecommendationData(
                        recommendation_id=generate_unique_id(),
                        recommendation_type=RecommendationType.AUDIENCE_TARGETING,
                        priority=RecommendationPriority.MEDIUM,
                        title=f"Ø§Ø³ØªÙ‡Ø¯Ø§Ù Ø¬Ù…Ù‡ÙˆØ±: {audience['name']}",
                        description=f"Ø¬Ù…Ù‡ÙˆØ± Ø¬Ø¯ÙŠØ¯ Ø¨Ø­Ø¬Ù… {audience['size']:,} Ù…Ø³ØªØ®Ø¯Ù…",
                        impact_level=ImpactLevel.HIGH,
                        estimated_impact={
                            'reach_increase': audience['size'],
                            'ctr_improvement': audience_rec.expected_performance['ctr'],
                            'conversion_rate': audience_rec.expected_performance['conversion_rate']
                        },
                        implementation_effort="Ù…ØªÙˆØ³Ø·",
                        implementation_steps=[
                            f"Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…Ù‡ÙˆØ± Ø¬Ø¯ÙŠØ¯: {audience['name']}",
                            "ØªØ¹ÙŠÙŠÙ† Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù",
                            "ØªØ´ØºÙŠÙ„ Ø­Ù…Ù„Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø¨Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø©",
                            "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù"
                        ],
                        expected_results={
                            'timeline': '1-2 Ø£Ø³Ø§Ø¨ÙŠØ¹',
                            'success_probability': 0.7
                        },
                        confidence_score=0.7,
                        supporting_data=audience_rec.__dict__,
                        expiry_date=datetime.now(timezone.utc) + timedelta(days=28)
                    )
                    
                    recommendations.append(recommendation)
                    
                    if len(recommendations) >= 2:  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 2 ØªÙˆØµÙŠØ§Øª Ø¬Ù…Ù‡ÙˆØ±
                        break
        
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±: {e}")
        
        return recommendations
    
    def _generate_budget_recommendations(self, campaign_data: Dict[str, Any]) -> List[RecommendationData]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©"""
        recommendations = []
        
        try:
            current_budget = campaign_data.get('budget', 0)
            performance = campaign_data.get('current_performance', {})
            
            # ØªØ­Ù„ÙŠÙ„ ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©
            cost = performance.get('cost', 0)
            conversions = performance.get('conversions', 0)
            
            if conversions > 0 and cost > 0:
                current_cpa = cost / conversions
                target_cpa = campaign_data.get('goals', {}).get('target_cpa', current_cpa * 1.2)
                
                if current_cpa < target_cpa:  # Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯
                    # ØªÙˆØµÙŠØ© Ø¨Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©
                    recommended_budget = current_budget * np.random.uniform(1.2, 1.5)
                    
                    recommendation = RecommendationData(
                        recommendation_id=generate_unique_id(),
                        recommendation_type=RecommendationType.BUDGET_ALLOCATION,
                        priority=RecommendationPriority.HIGH,
                        title="Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©",
                        description=f"Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ù† {current_budget:.0f} Ø¥Ù„Ù‰ {recommended_budget:.0f}",
                        impact_level=ImpactLevel.HIGH,
                        estimated_impact={
                            'budget_increase_percentage': (recommended_budget - current_budget) / current_budget * 100,
                            'conversions_increase_percentage': np.random.uniform(20, 40),
                            'revenue_increase_percentage': np.random.uniform(25, 50)
                        },
                        implementation_effort="Ø³Ù‡Ù„",
                        implementation_steps=[
                            f"Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ø¥Ù„Ù‰ {recommended_budget:.0f}",
                            "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù…Ø¯Ø© Ø£Ø³Ø¨ÙˆØ¹",
                            "ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡"
                        ],
                        expected_results={
                            'timeline': '1 Ø£Ø³Ø¨ÙˆØ¹',
                            'success_probability': 0.85
                        },
                        confidence_score=0.85,
                        supporting_data={
                            'current_budget': current_budget,
                            'recommended_budget': recommended_budget,
                            'current_cpa': current_cpa,
                            'target_cpa': target_cpa
                        },
                        expiry_date=datetime.now(timezone.utc) + timedelta(days=7)
                    )
                    
                    recommendations.append(recommendation)
        
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©: {e}")
        
        return recommendations
    
    def _generate_negative_keyword_recommendations(self, campaign_data: Dict[str, Any]) -> List[RecommendationData]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø³Ù„Ø¨ÙŠØ©"""
        recommendations = []
        
        try:
            # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©
            suggested_negative_keywords = [
                'Ù…Ø¬Ø§Ù†ÙŠ', 'free', 'Ù…Ø¬Ø§Ù†Ø§', 'Ø¨Ù„Ø§ Ù…Ù‚Ø§Ø¨Ù„',
                'Ø±Ø®ÙŠØµ', 'cheap', 'ÙˆØ¸ÙŠÙØ©', 'job',
                'ØªØ­Ù…ÙŠÙ„', 'download', 'ÙƒØ±Ø§Ùƒ', 'crack'
            ]
            
            recommendation = RecommendationData(
                recommendation_id=generate_unique_id(),
                recommendation_type=RecommendationType.NEGATIVE_KEYWORDS,
                priority=RecommendationPriority.MEDIUM,
                title="Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø³Ù„Ø¨ÙŠØ©",
                description="Ù…Ù†Ø¹ Ø¸Ù‡ÙˆØ± Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ù„Ù„Ø¨Ø­Ø«Ø§Øª ØºÙŠØ± Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©",
                impact_level=ImpactLevel.MEDIUM,
                estimated_impact={
                    'cost_reduction_percentage': np.random.uniform(10, 25),
                    'ctr_improvement_percentage': np.random.uniform(5, 15),
                    'quality_score_improvement': np.random.uniform(0.5, 1.5)
                },
                implementation_effort="Ø³Ù‡Ù„",
                implementation_steps=[
                    "Ù…Ø±Ø§Ø¬Ø¹Ø© ØªÙ‚Ø±ÙŠØ± Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¨Ø­Ø«",
                    "ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©",
                    "Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©",
                    "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ£Ø«ÙŠØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡"
                ],
                expected_results={
                    'timeline': '3-5 Ø£ÙŠØ§Ù…',
                    'success_probability': 0.9
                },
                confidence_score=0.9,
                supporting_data={
                    'suggested_negative_keywords': suggested_negative_keywords,
                    'expected_cost_savings': np.random.uniform(50, 200)
                },
                expiry_date=datetime.now(timezone.utc) + timedelta(days=14)
            )
            
            recommendations.append(recommendation)
        
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ©: {e}")
        
        return recommendations
    
    async def generate_recommendations(self, request: RecommendationsRequest) -> RecommendationsResponse:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
        start_time = time.time()
        request_id = generate_unique_id()
        
        try:
            # ÙØ­Øµ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
            cache_key = self._generate_cache_key(request.__dict__)
            cached_result = self._get_cached_result(cache_key)
            
            if cached_result:
                logger.info(f"ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {request_id}")
                return RecommendationsResponse(**cached_result)
            
            all_recommendations = []
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù„ÙƒÙ„ Ø­Ù…Ù„Ø©
            for campaign_id in request.campaign_ids:
                campaign_data = self._simulate_campaign_data(campaign_id)
                
                # ØªÙˆÙ„ÙŠØ¯ Ø£Ù†ÙˆØ§Ø¹ Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„ØªÙˆØµÙŠØ§Øª
                for rec_type in request.recommendation_types:
                    if rec_type == RecommendationType.KEYWORD_EXPANSION:
                        recommendations = self._generate_keyword_recommendations(campaign_data)
                        all_recommendations.extend(recommendations)
                    
                    elif rec_type == RecommendationType.BID_OPTIMIZATION:
                        recommendations = self._generate_bid_recommendations(campaign_data)
                        all_recommendations.extend(recommendations)
                    
                    elif rec_type == RecommendationType.AD_COPY_IMPROVEMENT:
                        recommendations = self._generate_ad_copy_recommendations(campaign_data)
                        all_recommendations.extend(recommendations)
                    
                    elif rec_type == RecommendationType.AUDIENCE_TARGETING:
                        recommendations = self._generate_audience_recommendations(campaign_data)
                        all_recommendations.extend(recommendations)
                    
                    elif rec_type == RecommendationType.BUDGET_ALLOCATION:
                        recommendations = self._generate_budget_recommendations(campaign_data)
                        all_recommendations.extend(recommendations)
                    
                    elif rec_type == RecommendationType.NEGATIVE_KEYWORDS:
                        recommendations = self._generate_negative_keyword_recommendations(campaign_data)
                        all_recommendations.extend(recommendations)
            
            # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡Ø§
            if request.priority_filter:
                all_recommendations = [
                    rec for rec in all_recommendations 
                    if rec.priority == request.priority_filter
                ]
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ÙˆØ§Ù„Ø«Ù‚Ø©
            priority_order = {
                RecommendationPriority.CRITICAL: 0,
                RecommendationPriority.HIGH: 1,
                RecommendationPriority.MEDIUM: 2,
                RecommendationPriority.LOW: 3
            }
            
            all_recommendations.sort(
                key=lambda x: (priority_order[x.priority], -x.confidence_score)
            )
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            all_recommendations = all_recommendations[:request.max_recommendations]
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ
            summary = self._create_recommendations_summary(all_recommendations)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
            processing_time = time.time() - start_time
            response = RecommendationsResponse(
                request_id=request_id,
                total_recommendations=len(all_recommendations),
                recommendations=all_recommendations,
                summary=summary,
                processing_time=processing_time
            )
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
            self._cache_result(cache_key, response.__dict__)
            
            # ØªØ­Ø¯ÙŠØ« Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
            self.performance_metrics['total_recommendations'] += len(all_recommendations)
            self.performance_metrics['successful_recommendations'] += 1
            
            if all_recommendations:
                avg_confidence = sum(rec.confidence_score for rec in all_recommendations) / len(all_recommendations)
                self.performance_metrics['average_confidence_score'] = avg_confidence
            
            logger.info(f"ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {request_id} ÙÙŠ {processing_time:.3f}s")
            return response
            
        except Exception as e:
            self.performance_metrics['failed_recommendations'] += 1
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª {request_id}: {e}")
            raise
    
    def _get_cached_result(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        if not self.redis_client:
            return None
        
        try:
            cached_data = self.redis_client.get(cache_key)
            if cached_data:
                return json.loads(cached_data)
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø©: {e}")
        
        return None
    
    def _cache_result(self, cache_key: str, result: Dict[str, Any]) -> None:
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        if not self.redis_client:
            return
        
        try:
            self.redis_client.setex(
                cache_key,
                self.cache_ttl,
                json.dumps(result, ensure_ascii=False, default=str)
            )
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø©: {e}")
    
    def _create_recommendations_summary(self, recommendations: List[RecommendationData]) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        if not recommendations:
            return {}
        
        # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        by_type = {}
        for rec in recommendations:
            rec_type = rec.recommendation_type.value
            if rec_type not in by_type:
                by_type[rec_type] = 0
            by_type[rec_type] += 1
        
        # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        by_priority = {}
        for rec in recommendations:
            priority = rec.priority.value
            if priority not in by_priority:
                by_priority[priority] = 0
            by_priority[priority] += 1
        
        # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©
        avg_confidence = sum(rec.confidence_score for rec in recommendations) / len(recommendations)
        
        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        total_estimated_impact = {
            'potential_cost_change': 0,
            'potential_conversion_increase': 0,
            'implementation_complexity': 'Ù…ØªÙˆØ³Ø·'
        }
        
        return {
            'total_recommendations': len(recommendations),
            'by_type': by_type,
            'by_priority': by_priority,
            'average_confidence_score': avg_confidence,
            'estimated_total_impact': total_estimated_impact,
            'high_priority_count': by_priority.get('high', 0) + by_priority.get('critical', 0),
            'quick_wins': len([rec for rec in recommendations if rec.implementation_effort == "Ø³Ù‡Ù„"]),
            'analysis_timestamp': datetime.now(timezone.utc).isoformat()
        }
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        return {
            **self.performance_metrics,
            'success_rate': (
                self.performance_metrics['successful_recommendations'] / 
                max(self.performance_metrics['total_recommendations'], 1) * 100
            ),
            'ml_available': ML_AVAILABLE,
            'redis_available': self.redis_client is not None,
            'google_ads_available': self.google_ads_client is not None
        }

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø©
recommendations_service = AIRecommendationsService()

# Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø©
def validate_recommendations_request(data: Dict[str, Any]) -> RecommendationsRequest:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø·Ù„Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    if not data.get('campaign_ids'):
        raise ValueError("campaign_ids Ù…Ø·Ù„ÙˆØ¨")
    
    if not isinstance(data['campaign_ids'], list):
        raise ValueError("campaign_ids ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù‚Ø§Ø¦Ù…Ø©")
    
    if len(data['campaign_ids']) > 5:
        raise ValueError("Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù…Ù„Ø§Øª Ù„Ø§ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ¬Ø§ÙˆØ² 5")
    
    # ØªØ­ÙˆÙŠÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù…Ù† Ù†Øµ Ø¥Ù„Ù‰ enum
    if 'recommendation_types' in data:
        data['recommendation_types'] = [
            RecommendationType(rec_type) for rec_type in data['recommendation_types']
        ]
    
    # ØªØ­ÙˆÙŠÙ„ ÙÙ„ØªØ± Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
    if 'priority_filter' in data and data['priority_filter']:
        data['priority_filter'] = RecommendationPriority(data['priority_filter'])
    
    return RecommendationsRequest(**data)

# Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
def recommendations_monitor(func):
    """Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„ØªÙˆØµÙŠØ§Øª"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            processing_time = time.time() - start_time
            logger.info(f"ØªÙ… ØªÙ†ÙÙŠØ° {func.__name__} ÙÙŠ {processing_time:.3f}s")
            return result
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ {func.__name__} Ø¨Ø¹Ø¯ {processing_time:.3f}s: {e}")
            raise
    return wrapper

# ===== API Routes =====

@ai_recommendations_bp.route('/generate', methods=['POST'])
@jwt_required()
@recommendations_monitor
async def generate_recommendations():
    """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ©"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª'}), 400
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        recommendations_request = validate_recommendations_request(data)
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙˆÙ„ÙŠØ¯
        result = await recommendations_service.generate_recommendations(recommendations_request)
        
        return jsonify({
            'success': True,
            'data': {
                'request_id': result.request_id,
                'total_recommendations': result.total_recommendations,
                'recommendations': [
                    {
                        'recommendation_id': rec.recommendation_id,
                        'type': rec.recommendation_type.value,
                        'priority': rec.priority.value,
                        'title': rec.title,
                        'description': rec.description,
                        'impact_level': rec.impact_level.value,
                        'estimated_impact': rec.estimated_impact,
                        'implementation_effort': rec.implementation_effort,
                        'implementation_steps': rec.implementation_steps,
                        'expected_results': rec.expected_results,
                        'confidence_score': rec.confidence_score,
                        'expiry_date': rec.expiry_date.isoformat(),
                        'status': rec.status.value
                    }
                    for rec in result.recommendations
                ],
                'summary': result.summary,
                'processing_time': result.processing_time
            }
        })
        
    except ValueError as e:
        return jsonify({'error': str(e)}), 400
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {e}")
        return jsonify({'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'}), 500

@ai_recommendations_bp.route('/keywords', methods=['POST'])
@jwt_required()
async def recommend_keywords():
    """ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"""
    try:
        data = request.get_json()
        campaign_ids = data.get('campaign_ids', [])
        
        if not campaign_ids:
            return jsonify({'error': 'Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø­Ù…Ù„Ø§Øª Ù…Ø·Ù„ÙˆØ¨Ø©'}), 400
        
        all_recommendations = []
        for campaign_id in campaign_ids:
            campaign_data = recommendations_service._simulate_campaign_data(campaign_id)
            recommendations = recommendations_service._generate_keyword_recommendations(campaign_data)
            all_recommendations.extend(recommendations)
        
        return jsonify({
            'success': True,
            'data': {
                'total_recommendations': len(all_recommendations),
                'keyword_recommendations': [
                    {
                        'recommendation_id': rec.recommendation_id,
                        'title': rec.title,
                        'description': rec.description,
                        'priority': rec.priority.value,
                        'confidence_score': rec.confidence_score,
                        'keyword_data': rec.supporting_data,
                        'implementation_steps': rec.implementation_steps
                    }
                    for rec in all_recommendations
                ]
            }
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {e}")
        return jsonify({'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'}), 500

@ai_recommendations_bp.route('/bids', methods=['POST'])
@jwt_required()
async def recommend_bids():
    """ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ø±ÙˆØ¶"""
    try:
        data = request.get_json()
        campaign_ids = data.get('campaign_ids', [])
        
        if not campaign_ids:
            return jsonify({'error': 'Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø­Ù…Ù„Ø§Øª Ù…Ø·Ù„ÙˆØ¨Ø©'}), 400
        
        all_recommendations = []
        for campaign_id in campaign_ids:
            campaign_data = recommendations_service._simulate_campaign_data(campaign_id)
            recommendations = recommendations_service._generate_bid_recommendations(campaign_data)
            all_recommendations.extend(recommendations)
        
        return jsonify({
            'success': True,
            'data': {
                'total_recommendations': len(all_recommendations),
                'bid_recommendations': [
                    {
                        'recommendation_id': rec.recommendation_id,
                        'title': rec.title,
                        'description': rec.description,
                        'priority': rec.priority.value,
                        'confidence_score': rec.confidence_score,
                        'bid_data': rec.supporting_data,
                        'estimated_impact': rec.estimated_impact
                    }
                    for rec in all_recommendations
                ]
            }
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ø±ÙˆØ¶: {e}")
        return jsonify({'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'}), 500

@ai_recommendations_bp.route('/ad-copy', methods=['POST'])
@jwt_required()
async def recommend_ad_copy():
    """ØªÙˆØµÙŠØ§Øª Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†"""
    try:
        data = request.get_json()
        campaign_ids = data.get('campaign_ids', [])
        
        if not campaign_ids:
            return jsonify({'error': 'Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø­Ù…Ù„Ø§Øª Ù…Ø·Ù„ÙˆØ¨Ø©'}), 400
        
        all_recommendations = []
        for campaign_id in campaign_ids:
            campaign_data = recommendations_service._simulate_campaign_data(campaign_id)
            recommendations = recommendations_service._generate_ad_copy_recommendations(campaign_data)
            all_recommendations.extend(recommendations)
        
        return jsonify({
            'success': True,
            'data': {
                'total_recommendations': len(all_recommendations),
                'ad_copy_recommendations': [
                    {
                        'recommendation_id': rec.recommendation_id,
                        'title': rec.title,
                        'description': rec.description,
                        'priority': rec.priority.value,
                        'confidence_score': rec.confidence_score,
                        'ad_copy_data': rec.supporting_data,
                        'implementation_steps': rec.implementation_steps
                    }
                    for rec in all_recommendations
                ]
            }
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆØµÙŠØ§Øª Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†: {e}")
        return jsonify({'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'}), 500

@ai_recommendations_bp.route('/audience', methods=['POST'])
@jwt_required()
async def recommend_audience():
    """ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±"""
    try:
        data = request.get_json()
        campaign_ids = data.get('campaign_ids', [])
        
        if not campaign_ids:
            return jsonify({'error': 'Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø­Ù…Ù„Ø§Øª Ù…Ø·Ù„ÙˆØ¨Ø©'}), 400
        
        all_recommendations = []
        for campaign_id in campaign_ids:
            campaign_data = recommendations_service._simulate_campaign_data(campaign_id)
            recommendations = recommendations_service._generate_audience_recommendations(campaign_data)
            all_recommendations.extend(recommendations)
        
        return jsonify({
            'success': True,
            'data': {
                'total_recommendations': len(all_recommendations),
                'audience_recommendations': [
                    {
                        'recommendation_id': rec.recommendation_id,
                        'title': rec.title,
                        'description': rec.description,
                        'priority': rec.priority.value,
                        'confidence_score': rec.confidence_score,
                        'audience_data': rec.supporting_data,
                        'estimated_impact': rec.estimated_impact
                    }
                    for rec in all_recommendations
                ]
            }
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±: {e}")
        return jsonify({'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'}), 500

@ai_recommendations_bp.route('/metrics', methods=['GET'])
@jwt_required()
async def get_recommendations_metrics():
    """Ø¬Ù„Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    try:
        metrics = recommendations_service.get_performance_metrics()
        return jsonify({
            'success': True,
            'data': metrics
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {e}")
        return jsonify({'error': 'Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'}), 500

@ai_recommendations_bp.route('/health', methods=['GET'])
async def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    try:
        health_status = {
            'service': 'AI Recommendations',
            'status': 'healthy',
            'ml_available': ML_AVAILABLE,
            'redis_available': recommendations_service.redis_client is not None,
            'google_ads_available': recommendations_service.google_ads_client is not None,
            'performance': recommendations_service.get_performance_metrics(),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
        return jsonify(health_status)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ ØµØ­Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª: {e}")
        return jsonify({
            'service': 'AI Recommendations',
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }), 500

# ØªØµØ¯ÙŠØ± Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
__all__ = ['ai_recommendations_bp', 'AIRecommendationsService', 'recommendations_service']

