"""
AI Services Package
ุญุฒูุฉ ุฎุฏูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุชุทูุฑุฉ

ุชุญุชูู ุนูู ุฎุฏูุงุช ุฐูุงุก ุงุตุทูุงุนู ุดุงููุฉ ููุชุทูุฑุฉ ูุชุญุณูู Google Ads ุจูุง ูู ุฐูู:
- ุจุญุซ ุงููููุงุช ุงูููุชุงุญูุฉ ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู
- ุชุญุณูู ุงูุญููุงุช ุงูุฐูู ูุงูุชููุงุฆู
- ุฑุคู ุฐููุฉ ูุชุทูุฑุฉ ูุชุญูููุงุช ุนูููุฉ
- ุชูุตูุงุช ุฐููุฉ ูุฎุตุตุฉ ููุชูุฏูุฉ
- ุชุนูู ุขูู ูุชูุฏู ูุชุญููู ุชูุจุคู

Author: AI Platform Team
Version: 3.0.0
Security Level: Enterprise
Performance: AI-Optimized & ML-Powered
"""

import os
import asyncio
import logging
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
from dataclasses import dataclass, field
from enum import Enum, auto

# ุฅุนุฏุงุฏ ุงูุชุณุฌูู ุงููุชูุฏู
logger = logging.getLogger(__name__)

# ุฅุนุฏุงุฏ Thread Pool ููุนูููุงุช ุงููุชูุงุฒูุฉ
ai_executor = ThreadPoolExecutor(max_workers=20, thread_name_prefix="ai_worker")

# ุญุงูุฉ ุชุญููู ุฎุฏูุงุช AI
AI_SERVICES_STATUS = {
    'keyword_research': False,
    'optimization': False,
    'insights': False,
    'recommendations': False,
    'core_dependencies': False,
    'ml_models': False,
    'data_processing': False,
    'analytics_engine': False
}

AVAILABLE_AI_SERVICES = []
AI_LOADING_METRICS = {
    'start_time': time.time(),
    'load_times': {},
    'total_load_time': 0.0,
    'errors': [],
    'warnings': []
}

class AIServiceType(Enum):
    """ุฃููุงุน ุฎุฏูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู"""
    KEYWORD_RESEARCH = "keyword_research"
    OPTIMIZATION = "optimization"
    INSIGHTS = "insights"
    RECOMMENDATIONS = "recommendations"
    ANALYTICS = "analytics"
    PREDICTION = "prediction"

class AIModelStatus(Enum):
    """ุญุงูุฉ ููุงุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู"""
    LOADING = "loading"
    READY = "ready"
    ERROR = "error"
    UPDATING = "updating"
    OFFLINE = "offline"

@dataclass
class AIServiceConfig:
    """ุฅุนุฏุงุฏุงุช ุฎุฏูุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู"""
    service_name: str
    service_type: AIServiceType
    enabled: bool = True
    model_version: str = "1.0.0"
    max_concurrent_requests: int = 10
    timeout_seconds: int = 30
    cache_enabled: bool = True
    cache_ttl: int = 3600
    performance_monitoring: bool = True
    auto_scaling: bool = True
    ml_models: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)

@dataclass
class AIPerformanceMetrics:
    """ููุงููุณ ุฃุฏุงุก ุงูุฐูุงุก ุงูุงุตุทูุงุนู"""
    service_name: str
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    average_response_time: float = 0.0
    cache_hit_rate: float = 0.0
    model_accuracy: float = 0.0
    throughput_per_second: float = 0.0
    error_rate: float = 0.0
    last_updated: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

def load_ai_service_safely(service_name: str) -> Tuple[str, Any, float, Optional[str]]:
    """ุชุญููู ุฎุฏูุฉ AI ุจุฃูุงู ูุน ููุงุณ ุงูููุช"""
    start_time = time.time()
    try:
        if service_name == 'keyword_research':
            from .keyword_research import ai_keyword_research_bp, AIKeywordResearchService
            return service_name, ai_keyword_research_bp, time.time() - start_time, None
        elif service_name == 'optimization':
            from .optimization import ai_optimization_bp, AIOptimizationService
            return service_name, ai_optimization_bp, time.time() - start_time, None
        elif service_name == 'insights':
            from .insights import ai_insights_bp, AIInsightsService
            return service_name, ai_insights_bp, time.time() - start_time, None
        elif service_name == 'recommendations':
            from .recommendations import ai_recommendations_bp, AIRecommendationsService
            return service_name, ai_recommendations_bp, time.time() - start_time, None
        else:
            return service_name, None, time.time() - start_time, f"ุฎุฏูุฉ ุบูุฑ ูุนุฑููุฉ: {service_name}"
    except ImportError as e:
        return service_name, None, time.time() - start_time, f"ุฎุทุฃ ูู ุงูุงุณุชูุฑุงุฏ: {str(e)}"
    except Exception as e:
        return service_name, None, time.time() - start_time, f"ุฎุทุฃ ุนุงู: {str(e)}"

# ุชุญููู ุฎุฏูุงุช AI ุจุงูุชูุงุฒู
ai_services = ['keyword_research', 'optimization', 'insights', 'recommendations']

# ุชุดุบูู ุงูุชุญููู ุงููุชูุงุฒู
future_to_service = {
    ai_executor.submit(load_ai_service_safely, service): service 
    for service in ai_services
}

# ุฌูุน ุงููุชุงุฆุฌ
for future in as_completed(future_to_service):
    service_name = future_to_service[future]
    try:
        name, service_bp, load_time, error = future.result()
        AI_LOADING_METRICS['load_times'][name] = load_time
        
        if error:
            AI_SERVICES_STATUS[name] = False
            AI_LOADING_METRICS['errors'].append(f"{name}: {error}")
            logger.warning(f"โ๏ธ ุฎุฏูุฉ {name} ุบูุฑ ูุชุงุญุฉ: {error}")
        else:
            AI_SERVICES_STATUS[name] = True
            AVAILABLE_AI_SERVICES.append(service_bp)
            logger.info(f"โ ุชู ุชุญููู ุฎุฏูุฉ {name} ูู {load_time:.3f}s")
            
    except Exception as e:
        AI_SERVICES_STATUS[service_name] = False
        AI_LOADING_METRICS['errors'].append(f"{service_name}: {str(e)}")
        logger.error(f"โ ุฎุทุฃ ูู ุชุญููู ุฎุฏูุฉ {service_name}: {e}")

# ูุญุต ุงูุชุจุนูุงุช ุงูุฃุณุงุณูุฉ
try:
    import numpy as np
    import pandas as pd
    from sklearn.base import BaseEstimator
    AI_SERVICES_STATUS['core_dependencies'] = True
    logger.info("โ ุชู ุชุญููู ุงูุชุจุนูุงุช ุงูุฃุณุงุณูุฉ ููุฐูุงุก ุงูุงุตุทูุงุนู")
except ImportError as e:
    AI_SERVICES_STATUS['core_dependencies'] = False
    AI_LOADING_METRICS['warnings'].append(f"ุชุจุนูุงุช ุฃุณุงุณูุฉ ููููุฏุฉ: {e}")
    logger.warning(f"โ๏ธ ุชุจุนูุงุช ุฃุณุงุณูุฉ ููููุฏุฉ: {e}")

# ูุญุต ููุงุฐุฌ ุงูุชุนูู ุงูุขูู
try:
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.linear_model import LinearRegression, LogisticRegression
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    AI_SERVICES_STATUS['ml_models'] = True
    logger.info("โ ุชู ุชุญููู ููุงุฐุฌ ุงูุชุนูู ุงูุขูู")
except ImportError as e:
    AI_SERVICES_STATUS['ml_models'] = False
    AI_LOADING_METRICS['warnings'].append(f"ููุงุฐุฌ ุงูุชุนูู ุงูุขูู ููููุฏุฉ: {e}")
    logger.warning(f"โ๏ธ ููุงุฐุฌ ุงูุชุนูู ุงูุขูู ููููุฏุฉ: {e}")

# ูุญุต ูุนุงูุฌุฉ ุงูุจูุงูุงุช
try:
    import scipy.stats as stats
    from scipy.optimize import minimize
    AI_SERVICES_STATUS['data_processing'] = True
    logger.info("โ ุชู ุชุญููู ุฃุฏูุงุช ูุนุงูุฌุฉ ุงูุจูุงูุงุช")
except ImportError as e:
    AI_SERVICES_STATUS['data_processing'] = False
    AI_LOADING_METRICS['warnings'].append(f"ุฃุฏูุงุช ูุนุงูุฌุฉ ุงูุจูุงูุงุช ููููุฏุฉ: {e}")
    logger.warning(f"โ๏ธ ุฃุฏูุงุช ูุนุงูุฌุฉ ุงูุจูุงูุงุช ููููุฏุฉ: {e}")

# ูุญุต ูุญุฑู ุงูุชุญูููุงุช
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    AI_SERVICES_STATUS['analytics_engine'] = True
    logger.info("โ ุชู ุชุญููู ูุญุฑู ุงูุชุญูููุงุช")
except ImportError as e:
    AI_SERVICES_STATUS['analytics_engine'] = False
    AI_LOADING_METRICS['warnings'].append(f"ูุญุฑู ุงูุชุญูููุงุช ููููุฏ: {e}")
    logger.warning(f"โ๏ธ ูุญุฑู ุงูุชุญูููุงุช ููููุฏ: {e}")

# ุญุณุงุจ ุงูููุช ุงูุฅุฌูุงูู
AI_LOADING_METRICS['total_load_time'] = time.time() - AI_LOADING_METRICS['start_time']

# ุฅุบูุงู Thread Pool
ai_executor.shutdown(wait=True)

# ุชุตุฏูุฑ ุงูุฎุฏูุงุช ุงููุชุงุญุฉ
__all__ = []

if AI_SERVICES_STATUS['keyword_research']:
    __all__.append('ai_keyword_research_bp')

if AI_SERVICES_STATUS['optimization']:
    __all__.append('ai_optimization_bp')

if AI_SERVICES_STATUS['insights']:
    __all__.append('ai_insights_bp')

if AI_SERVICES_STATUS['recommendations']:
    __all__.append('ai_recommendations_bp')

# ูุนูููุงุช ุญุฒูุฉ AI
AI_PACKAGE_INFO = {
    'name': 'AI Services Package',
    'version': '3.0.0',
    'description': 'ุฎุฏูุงุช ุฐูุงุก ุงุตุทูุงุนู ูุชุทูุฑุฉ ูุชุญุณูู Google Ads',
    'total_services': len(ai_services),
    'available_services': len(AVAILABLE_AI_SERVICES),
    'services_status': AI_SERVICES_STATUS,
    'loading_metrics': AI_LOADING_METRICS,
    'capabilities': [
        'AI-Powered Keyword Research',
        'Intelligent Campaign Optimization',
        'Advanced Analytics & Insights',
        'Smart Recommendations Engine',
        'Machine Learning Models',
        'Predictive Analytics',
        'Real-time Performance Monitoring',
        'Automated Decision Making'
    ],
    'ml_models_supported': [
        'Random Forest',
        'Gradient Boosting',
        'Linear Regression',
        'Logistic Regression',
        'K-Means Clustering',
        'Neural Networks',
        'Decision Trees',
        'Support Vector Machines'
    ],
    'performance': {
        'parallel_loading': True,
        'total_load_time': f"{AI_LOADING_METRICS['total_load_time']:.3f}s",
        'average_load_time': f"{sum(AI_LOADING_METRICS['load_times'].values()) / len(AI_LOADING_METRICS['load_times']):.3f}s" if AI_LOADING_METRICS['load_times'] else "0.000s",
        'fastest_service': min(AI_LOADING_METRICS['load_times'].items(), key=lambda x: x[1]) if AI_LOADING_METRICS['load_times'] else None,
        'slowest_service': max(AI_LOADING_METRICS['load_times'].items(), key=lambda x: x[1]) if AI_LOADING_METRICS['load_times'] else None
    },
    'last_updated': datetime.now(timezone.utc).isoformat()
}

class AIServiceManager:
    """ูุฏูุฑ ุฎุฏูุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู"""
    
    def __init__(self):
        """ุชููุฆุฉ ูุฏูุฑ ุฎุฏูุงุช AI"""
        self.services = {}
        self.performance_metrics = {}
        self.model_status = {}
        self.service_configs = {}
        
        # ุชููุฆุฉ ููุงููุณ ุงูุฃุฏุงุก ููู ุฎุฏูุฉ
        for service_name in ai_services:
            if AI_SERVICES_STATUS.get(service_name, False):
                self.performance_metrics[service_name] = AIPerformanceMetrics(service_name=service_name)
                self.model_status[service_name] = AIModelStatus.READY
                self.service_configs[service_name] = AIServiceConfig(
                    service_name=service_name,
                    service_type=AIServiceType(service_name)
                )
        
        logger.info(f"๐ค ุชู ุชููุฆุฉ ูุฏูุฑ ุฎุฏูุงุช AI - {len(self.services)} ุฎุฏูุฉ ูุชุงุญุฉ")
    
    def get_service_status(self, service_name: str) -> Dict[str, Any]:
        """ุฌูุจ ุญุงูุฉ ุฎุฏูุฉ ูุนููุฉ"""
        return {
            'service_name': service_name,
            'available': AI_SERVICES_STATUS.get(service_name, False),
            'model_status': self.model_status.get(service_name, AIModelStatus.OFFLINE).value,
            'performance_metrics': self.performance_metrics.get(service_name),
            'config': self.service_configs.get(service_name),
            'last_checked': datetime.now(timezone.utc).isoformat()
        }
    
    def get_all_services_status(self) -> Dict[str, Any]:
        """ุฌูุจ ุญุงูุฉ ุฌููุน ุงูุฎุฏูุงุช"""
        return {
            'package_info': AI_PACKAGE_INFO,
            'services_status': AI_SERVICES_STATUS,
            'available_services': len(AVAILABLE_AI_SERVICES),
            'total_services': len(ai_services),
            'health_status': 'healthy' if any(AI_SERVICES_STATUS.values()) else 'unhealthy',
            'performance_summary': {
                'total_requests': sum(metrics.total_requests for metrics in self.performance_metrics.values()),
                'average_response_time': sum(metrics.average_response_time for metrics in self.performance_metrics.values()) / len(self.performance_metrics) if self.performance_metrics else 0,
                'overall_success_rate': sum(metrics.successful_requests for metrics in self.performance_metrics.values()) / max(sum(metrics.total_requests for metrics in self.performance_metrics.values()), 1) * 100
            },
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
    
    def update_performance_metrics(self, service_name: str, response_time: float, 
                                 success: bool, cache_hit: bool = False) -> None:
        """ุชุญุฏูุซ ููุงููุณ ุงูุฃุฏุงุก"""
        if service_name in self.performance_metrics:
            metrics = self.performance_metrics[service_name]
            metrics.total_requests += 1
            
            if success:
                metrics.successful_requests += 1
            else:
                metrics.failed_requests += 1
            
            # ุชุญุฏูุซ ูุชูุณุท ููุช ุงูุงุณุชุฌุงุจุฉ
            total_requests = metrics.total_requests
            current_avg = metrics.average_response_time
            metrics.average_response_time = (current_avg * (total_requests - 1) + response_time) / total_requests
            
            # ุชุญุฏูุซ ูุนุฏู ูุฌุงุญ ุงูุชุฎุฒูู ุงููุคูุช
            if cache_hit:
                metrics.cache_hit_rate = (metrics.cache_hit_rate * (total_requests - 1) + 1) / total_requests
            else:
                metrics.cache_hit_rate = (metrics.cache_hit_rate * (total_requests - 1)) / total_requests
            
            # ุชุญุฏูุซ ูุนุฏู ุงูุฎุทุฃ
            metrics.error_rate = (metrics.failed_requests / metrics.total_requests) * 100
            
            # ุชุญุฏูุซ ุงูุฅูุชุงุฌูุฉ
            time_diff = (datetime.now(timezone.utc) - metrics.last_updated).total_seconds()
            if time_diff > 0:
                metrics.throughput_per_second = 1 / time_diff
            
            metrics.last_updated = datetime.now(timezone.utc)
    
    def get_available_endpoints(self) -> List[str]:
        """ุฌูุจ ูุงุฆูุฉ ุงููุณุงุฑุงุช ุงููุชุงุญุฉ"""
        endpoints = []
        
        if AI_SERVICES_STATUS['keyword_research']:
            endpoints.extend([
                '/api/ai/keyword-research/research',
                '/api/ai/keyword-research/intent-analysis',
                '/api/ai/keyword-research/long-tail',
                '/api/ai/keyword-research/difficulty-analysis',
                '/api/ai/keyword-research/optimizations'
            ])
        
        if AI_SERVICES_STATUS['optimization']:
            endpoints.extend([
                '/api/ai/optimization/campaigns',
                '/api/ai/optimization/bids',
                '/api/ai/optimization/budgets',
                '/api/ai/optimization/keywords',
                '/api/ai/optimization/ads'
            ])
        
        if AI_SERVICES_STATUS['insights']:
            endpoints.extend([
                '/api/ai/insights/performance',
                '/api/ai/insights/trends',
                '/api/ai/insights/anomalies',
                '/api/ai/insights/predictions',
                '/api/ai/insights/competitive'
            ])
        
        if AI_SERVICES_STATUS['recommendations']:
            endpoints.extend([
                '/api/ai/recommendations/campaigns',
                '/api/ai/recommendations/keywords',
                '/api/ai/recommendations/budgets',
                '/api/ai/recommendations/audiences',
                '/api/ai/recommendations/creative'
            ])
        
        return endpoints
    
    def health_check(self) -> Dict[str, Any]:
        """ูุญุต ุตุญุฉ ุฌููุน ุฎุฏูุงุช AI"""
        health_status = {
            'overall_status': 'healthy' if any(AI_SERVICES_STATUS.values()) else 'unhealthy',
            'services': {},
            'dependencies': {
                'core_dependencies': AI_SERVICES_STATUS['core_dependencies'],
                'ml_models': AI_SERVICES_STATUS['ml_models'],
                'data_processing': AI_SERVICES_STATUS['data_processing'],
                'analytics_engine': AI_SERVICES_STATUS['analytics_engine']
            },
            'summary': {
                'total_services': len(ai_services),
                'healthy_services': sum(AI_SERVICES_STATUS[service] for service in ai_services),
                'unhealthy_services': len(ai_services) - sum(AI_SERVICES_STATUS[service] for service in ai_services),
                'dependency_issues': len([dep for dep, status in AI_SERVICES_STATUS.items() if not status and dep not in ai_services])
            },
            'performance': AI_PACKAGE_INFO['performance'],
            'errors': AI_LOADING_METRICS['errors'],
            'warnings': AI_LOADING_METRICS['warnings'],
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
        for service_name in ai_services:
            health_status['services'][service_name] = {
                'status': 'healthy' if AI_SERVICES_STATUS.get(service_name, False) else 'unhealthy',
                'available': AI_SERVICES_STATUS.get(service_name, False),
                'model_status': self.model_status.get(service_name, AIModelStatus.OFFLINE).value,
                'load_time': AI_LOADING_METRICS['load_times'].get(service_name, 0),
                'performance': self.performance_metrics.get(service_name)
            }
        
        return health_status

# ุฅูุดุงุก ูุซูู ูุฏูุฑ ุฎุฏูุงุช AI
ai_service_manager = AIServiceManager()

def get_ai_package_status() -> Dict[str, Any]:
    """ุฌูุจ ุญุงูุฉ ุญุฒูุฉ AI ูุน ููุงููุณ ุงูุฃุฏุงุก"""
    return ai_service_manager.get_all_services_status()

def get_available_ai_endpoints() -> List[str]:
    """ุฌูุจ ูุงุฆูุฉ ูุณุงุฑุงุช AI ุงููุชุงุญุฉ"""
    return ai_service_manager.get_available_endpoints()

def get_ai_health_status() -> Dict[str, Any]:
    """ูุญุต ุตุญุฉ ุฌููุน ุฎุฏูุงุช AI"""
    return ai_service_manager.health_check()

# ุชุณุฌูู ูุนูููุงุช ุงูุชุญููู
logger.info(f"๐ ุชู ุชุญููู AI Services Package ูู {AI_LOADING_METRICS['total_load_time']:.3f}s")
logger.info(f"๐ค ุงูุญุงูุฉ: {len(AVAILABLE_AI_SERVICES)}/{len(ai_services)} ุฎุฏูุงุช AI ูุชุงุญุฉ")
logger.info(f"โ ุฎุฏูุงุช AI ุงููุชุงุญุฉ: {[name for name in ai_services if AI_SERVICES_STATUS.get(name, False)]}")

if AI_LOADING_METRICS['errors']:
    logger.warning(f"โ๏ธ ุฃุฎุทุงุก ุงูุชุญููู: {len(AI_LOADING_METRICS['errors'])}")
    for error in AI_LOADING_METRICS['errors']:
        logger.warning(f"   - {error}")

if AI_LOADING_METRICS['warnings']:
    logger.warning(f"โ๏ธ ุชุญุฐูุฑุงุช: {len(AI_LOADING_METRICS['warnings'])}")
    for warning in AI_LOADING_METRICS['warnings']:
        logger.warning(f"   - {warning}")

if not any(AI_SERVICES_STATUS[service] for service in ai_services):
    logger.error("โ ูุง ุชูุฌุฏ ุฎุฏูุงุช AI ูุชุงุญุฉ - ุชุญูู ูู ุงูุชุจุนูุงุช")
elif len(AVAILABLE_AI_SERVICES) < len(ai_services):
    missing_services = [name for name in ai_services if not AI_SERVICES_STATUS.get(name, False)]
    logger.warning(f"โ๏ธ ุจุนุถ ุฎุฏูุงุช AI ุบูุฑ ูุชุงุญุฉ: {missing_services}")
else:
    logger.info("๐ ุฌููุน ุฎุฏูุงุช AI ูุชุงุญุฉ ููุญููุฉ ุจูุฌุงุญ")

# ุฅุถุงูุฉ ูุนูููุงุช ุงูุฃุฏุงุก
if AI_LOADING_METRICS['load_times']:
    fastest = min(AI_LOADING_METRICS['load_times'].items(), key=lambda x: x[1])
    slowest = max(AI_LOADING_METRICS['load_times'].items(), key=lambda x: x[1])
    logger.info(f"โก ุฃุณุฑุน ุชุญููู: {fastest[0]} ({fastest[1]:.3f}s)")
    logger.info(f"๐ ุฃุจุทุฃ ุชุญููู: {slowest[0]} ({slowest[1]:.3f}s)")

# ุชุญุฏูุฏ ูุณุชูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุชุงุญ
ai_capability_level = "basic"
if AI_SERVICES_STATUS['core_dependencies'] and AI_SERVICES_STATUS['ml_models']:
    if sum(AI_SERVICES_STATUS[service] for service in ai_services) >= 3:
        ai_capability_level = "advanced"
    elif sum(AI_SERVICES_STATUS[service] for service in ai_services) >= 2:
        ai_capability_level = "intermediate"

logger.info(f"๐ง ูุณุชูู ูุฏุฑุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู: {ai_capability_level}")

# ุฅุถุงูุฉ ูุนูููุงุช ุงููุฏุฑุงุช ููุญุฒูุฉ
AI_PACKAGE_INFO['ai_capability_level'] = ai_capability_level
AI_PACKAGE_INFO['ready_for_production'] = (
    ai_capability_level in ['intermediate', 'advanced'] and 
    len(AVAILABLE_AI_SERVICES) >= 2 and
    AI_SERVICES_STATUS['core_dependencies']
)

